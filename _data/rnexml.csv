issue,comment_id,user,created_at,updated_at,body,state,comments,title
1,22503698,cboettig,2013-08-12T15:56:57Z,2013-08-19T12:04:59Z,"@SChamberlain Good point, need to map out the development plan still.  Getting up to speed on S4 classes is probably the first hurdle; certainly it is for me.  Check out classes.R for the definitions -- you'll see that they just correspond to the various kinds of XML node definitions, with class ""slots"" corresponding to xml node attributes or values.  Class names correspond directly to the node names in the schema (e.g. `tree`, `meta`, `edge`, `node`, `otu`)...

Almost all the functions are written as coercion methods (""`setAs()`"", defining an `as` method for the class).  The basic strategy is we just coerce the entire XML document into an S4 class (made up of component S4 classes), e.g. see `nexml_read()`.  Then we have `setAs()` methods  that can coerce the relevant S4 objects into phylo objects, more that can coerce phylo objects into the S4 objects (e.g. `phylo$edge` is coerced into the S4 `edge` class in the process of coercing `phylo` into the the S4 `tree` class see ape.R)  

The cool thing is that once all the coercion methods are written, we have this really flexible, modular structure.  This lets us have very simple calls to make minimally valid NeXML while also letting us parse or build really rich NeXML.  You'll get the hang of it quickly, lemme know if you have questions on how this strategy works.  

The unit tests (`inst/tests`) give you a quick demo of how these methods work.  If you understand the logic there you're probably set.  


So, quick stab at some next steps, which should probably be made into there own issues:

- [ ]  I haven't written any roxygen yet, so that might be a way to get familiar with these while moving stuff forward.  
- [ ] Minor issue but not sure why my aliases, `write.nexml` and `read.nexml` aren't being registered

- [ ] In `setAs(""tree"", ""nexml"", function(from) ... )` (coercing tree to nexml), we need to generate the `<otus>` node still.

- [ ] Flushing out the class slots.  Lots of my class definitions are missing slots for optional attributes.  This doesn't break anything, we simply don't read that information out of the XML and into the S4 when we don't find a slot for it (we = `xmlToS4` method).  Ideally we'll want to support the full schema, so all classes should be expanded.  (The cool thing about the S4 approach is this is relatively easy to do without breaking anything).  

- [ ] Flushing out the remaining classes.  Lots of classes / XML node types not yet written.  Would be good to write these for some practice (@rvosa might be able to suggest best which ones to prioritize?  Or just look at the sample nexml files in `inst/examples/` to see any nodes we haven't defined ...)   In principle, once Duncan has the `XMLSchema` package robustly working, we can generate these classes, along with coercion methods to write them back to XML etc, automatically, which will save a lot of effort.  But since it's quite mechanical writing them by hand doesn't take very long.  

### fancier stuff for later milestones


- [ ] We'll probably want a standard set of top-level `<meta>` nodes with basic metadata information, e.g. creator, date, rights/license, etc (probably mostly expressed in Dublin core namespace.  the TreeBASE NeXML is a good template though it doesn't do all of this).  

We would use different strategies to add different parts of this: For instance, we would want things like author to be configurable through some global package settings, (e.g. `set(author=""Carl Boettiger <cboettig@gmail.com>"")`,
 while publication date we would generate on the fly (from `Sys.time()` probably), and we might be bold and include a `meta` license node in the nexml S4 prototype (e.g. the way we already add attribute `generator=""RNeXML""` to the nexml).

- [ ] Support for coercing more custom types.  For instance, we might want to coerce the publication metadata into an R `bibentry` object, coerce people nodes into R `person` objects, etc.  

- [ ] Support writing custom metadata annotations (a big task, strategy still to be thought out)",NA,NA,NA
1,22507556,sckott,2013-08-12T16:51:13Z,2013-08-12T16:51:13Z,"Cool, put those items you mentioned as separate issues. I will poke around and get familiar with the code first, then try to contribute some code. ",NA,NA,NA
7,22507776,cboettig,2013-08-12T16:54:24Z,2013-08-12T16:54:24Z,duplicate of #8 ;-),NA,NA,NA
6,22511233,cboettig,2013-08-12T17:44:23Z,2013-08-12T17:44:23Z,"Ah ha!  

I have been writing `tip.label` (e.g., the species name) to the `otu` attribute of `node` element.  The examples appear to create an id, such as `t1`, for these `otu` labels, and then define the `id` using the species name in the `otus` element.  

It is not entirely clear to me what the advantage of having `<node id = ""n1"" otu=""t1"">` and `<otu id = ""t1"" label = ""Species Name"">` is over simply having `<node id = ""n1"" otu = ""Species Name"">`, but there's probably a good reason and we should follow it.  


In coercing a NeXML tree into a phylo object, I currently therefore assign the node's otu value as the tip label. A convoluted approach would replace these otu species names with identifiers when writing the `otus` node.  

## Alternate approach, more logical

`phylo => tree` should ignore the tip labels and just generate tip ids in their place.  `phylo => nexml` would get the tip labels from `phy$tip.label` when generating the `otus` node, for use in the `<otu label` attribute.

`nexml => phylo` would then run `nexml=>tree`, and then update phy$labels from `otus` element.  

## potential bug

[ ]  Importantly, we probably generate a bug when non-tip nodes in the NeXML have otu attributes. This bug should be demonstrated and fixed.  Going from `phylo => tree`, we can use who has a tip label as an indication of what node is a tip.  But going from `tree => phylo` we should not assume anyone with an `otu` is a tip.  





",NA,NA,NA
14,22547873,rvosa,2013-08-13T07:36:16Z,2013-08-13T07:36:16Z,Do we expect people to alter the DOM tree a lot (i.e. are their risks of clashes if we use a simpler scheme)? Otherwise maybe tag name + a counter is more concise?,NA,NA,NA
14,22682377,cboettig,2013-08-15T02:59:47Z,2013-08-15T02:59:47Z,"@rvosa Yeah, I'm not sure -- still trying to wrap my head around this one.  Most users will probably only use the top-level API for writing an `ape::phylo` tree or list of trees (`ape:multiPhylo`) to NeXML, in which case we can number them as we go.  But the S4-Class-based interface we have so far also allows users to just coerce `ape::phylo` trees into the S4 `RNeXML::tree` class, which can then be inserted into NeXML later.  Perhaps we don't want users doing that, but this means they could modularly build up the DOM and we then have to watch out for collisions.  

Or in more concrete terms, I have this `setAs(""phylo"", ""tree"" ...)` subroutine for mapping phylo objects to the S4 object that mimics the schema.  Since the phylo object doesn't have an ID, I either have to generate one at this time, or otherwise add the id when adding the tree to an existing or new nexml/trees object.  Does that make sense?


In other news, the validator complains that UUIDs aren't valid id attributes: 

> ... is not a valid value of the atomic type 'xs:ID'

",NA,NA,NA
8,22682466,cboettig,2013-08-15T03:03:32Z,2013-08-28T20:36:52Z,"e12854078a2acd37e40f49e9c5fbee134c38575f now provides `id` attribute on `otus`, and references this `id` in the `otus` attribute of the `trees` element, e.g. 

```xml
  <otus id=""tax1"">
    <otu id=""t1""/>
    <otu id=""t3""/>
    <otu id=""t2""/>
    <otu id=""t5""/>
    <otu id=""t4""/>
  </otus>
  <trees id=""Trees"" otus=""tax1"">
```

Still need to use generic identifiers for ids (currently using taxon names) and add taxon names to the `otu` `label` attribute...",NA,NA,NA
14,22683684,hlapp,2013-08-15T03:50:02Z,2013-08-15T03:50:02Z,"
On Aug 14, 2013, at 10:59 PM, Carl Boettiger wrote:

> In other news, the validator complains that UUIDs aren't valid id attributes:
> 
That sounds like a validator bug.",NA,NA,NA
14,22693947,rvosa,2013-08-15T09:44:29Z,2013-08-15T09:44:29Z,"What do the UUIDs look like? The schema specifies that the type of @id is
xs:ID, which is a non-colonized name (NCName), so instance documents must
conform to the production rules of NCNames (probably most importantly:
start with a letter or an underscore). If they don't, I don't see how the
validator is at fault here.


On Thu, Aug 15, 2013 at 5:50 AM, Hilmar Lapp <notifications@github.com>wrote:

>
> On Aug 14, 2013, at 10:59 PM, Carl Boettiger wrote:
>
> > In other news, the validator complains that UUIDs aren't valid id
> attributes:
> >
> That sounds like a validator bug.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/14#issuecomment-22683684>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
14,22705449,hlapp,2013-08-15T14:16:11Z,2013-08-15T14:16:11Z,"
On Aug 15, 2013, at 5:44 AM, Rutger Vos wrote:

> What do the UUIDs look like? [...] instance documents must  conform to the production rules of NCNames (probably most importantly:  start with a letter or an underscore). If they don't, I don't see how the 
> validator is at fault here.

UUIDs can start with a digit.

@cboettig: I suggest that if you choose UUIDs, you put them in the form of a urn:uuid:<UUID> scheme. See http://www.ietf.org/rfc/rfc4122.txt",NA,NA,NA
6,22736686,hlapp,2013-08-15T22:52:28Z,2013-08-15T22:52:28Z,"
On Aug 12, 2013, at 1:44 PM, Carl Boettiger wrote:

> It is not entirely clear to me what the advantage of having <node id = ""n1"" otu=""t1"">and <otu id = ""t1"" label = ""Species Name""> is over simply having <node id = ""n1"" otu = ""Species Name"">, but there's probably a good reason and we should follow it.
> 

The OTU is in principle more than just an attribute of a node, even if for some (or many) trees treating it as such would not lose any information. But there may be metadata for an OTU that pertain to the OTU, and not the node, for example its relationship to an external identifier (for a taxon, a sequence, or a specimen).",NA,NA,NA
11,22736896,hlapp,2013-08-15T22:56:46Z,2013-08-15T22:56:46Z,"
On Aug 12, 2013, at 2:09 PM, Carl Boettiger wrote:

> On the other hand, speaking to ben bolker at ESA, phylobase uptake is low (though does have reverse dependencies), and more troublingly, NCL (Nexus Class Library) is kinda a weak point that has made maintenance challenging. I suspect the ideal solution given this issue is to support direct coercion into ape::phylo, and include phylobase as ""suggests"" only,

I agree, with both the reasons and the conclusions, as much as I'm a fan of phylobase. But I would hate to see uptake of NeXML in R be hampered by the problems of binding NCL into a rarely used R package.",NA,NA,NA
12,22737369,hlapp,2013-08-15T23:06:41Z,2013-08-15T23:06:41Z,"
On Aug 12, 2013, at 2:15 PM, Carl Boettiger wrote:

> nexml_read(""file.nexml"", type=""phylo"") vs type = character_matrix.

Or simply ""matrix""?

> We need to figure out what R object we want to coerce character matrices to, if any.

There are packages for molecular matrices. The best way to obtain tips for the most suitable ones is probably to ask on r-sig-phylo. I have seen several ones mentioned there in the past. 

For other matrices, either an R matrix (in that case, characters need to all be of the same type, either numeric or text), or R data frame. You could also ask on r-sig-phylo about favorable ways to handle that; there are lots of comparative trait analysis packages.

> Comparative methods, which dominate the phylogenetics R tools, have the notion of character data as well, but usually as phenotypic data that is not meant to be informative of the tree inference, has no notion of alignment, etc.

Not sure what you mean here - surely trees are inferred from non-molecular character data?",NA,NA,NA
14,22758721,rvosa,2013-08-16T10:27:51Z,2013-08-16T10:27:51Z,"IDs need to be non-colonized names, i.e. strings without colons. If I
understand your suggestion correctly, the UUIDs would contain colons, which
would be a no-no.


On Thu, Aug 15, 2013 at 4:16 PM, Hilmar Lapp <notifications@github.com>wrote:

>
> On Aug 15, 2013, at 5:44 AM, Rutger Vos wrote:
>
> > What do the UUIDs look like? [...] instance documents must conform to
> the production rules of NCNames (probably most importantly: start with a
> letter or an underscore). If they don't, I don't see how the
> > validator is at fault here.
>
> UUIDs can start with a digit.
>
> @cboettig: I suggest that if you choose UUIDs, you put them in the form of
> a urn:uuid:<UUID> scheme. See http://www.ietf.org/rfc/rfc4122.txt
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/14#issuecomment-22705449>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
14,22765254,hlapp,2013-08-16T13:17:13Z,2013-08-16T13:17:13Z,"
On Aug 16, 2013, at 6:27 AM, Rutger Vos wrote:

> IDs need to be non-colonized names, i.e. strings without colons. If I 
> understand your suggestion correctly, the UUIDs would contain colons, which 
> would be a no-no. 


So HTTP URIs can't be IDs?",NA,NA,NA
14,22865516,rvosa,2013-08-19T11:26:47Z,2013-08-19T11:26:47Z,"Not normally. However, IDs can become part of HTTP URIs when transforming documents to RDF as they are then made globally unique by prefixing them with either the location of the document or the value of xml:base of the nearest ancestor node that contains this attribute. (Note that I didn't just make this up or anything.)

I see where you're going with this line of questioning. If we want HTTP URIs as IDs (good id(ea)), use xml:base.",NA,NA,NA
12,22865961,rvosa,2013-08-19T11:37:38Z,2013-08-19T11:37:38Z,"I'm guessing you mean that people might do comparative analyses in R such that you have already have a tree (which was based on, say, a molecular marker) and you then have some other, smaller, set of data for which you want to study correlation between traits. 

To my mind it would be fine to use NeXML for both those data: the data from which the tree was inferred, the tree itself and data that you want to analyze comparatively can all live happily in the same document. 

I guess for that second data set you might have more to say about it because it's only a couple of columns of continuous or multistate data that you have collected for that study (hence your reference to phenoscape) - but that's fine too, just annotate the as you see fit:

* if you have something to say about a specific observation/measurement, annotate that matrix cell

* if you have something to say about a character (e.g. what do I mean by ""intercheliceral sclerite""), annotate the char element

* if you have something to say about how you organized a character in states (e.g. what do I mean by ""small"", ""medium"" or ""large""), annotate the state element(s)",NA,NA,NA
11,22866013,rvosa,2013-08-19T11:38:43Z,2013-08-19T11:38:43Z,Agreed.,NA,NA,NA
6,22866748,rvosa,2013-08-19T11:55:22Z,2013-08-19T11:55:22Z,"The label attribute is intended as a human-readable text string, which therefore could contain characters that make it unsuitable for using as an xml ID (example: spaces). It is not used for referencing between different elements. It is optional. The same label can occur multiple times in the DOM tree.

Multiple nodes (presumably from multiple trees) can refer to the same otu element, so it ought to be possible to give these different nodes different labels. 

For example, if you integrate trees from different publications (in a supertree analysis) and you want to retain the names that the authors originally stuck on their trees but you have also resolved synonyms across those trees (different authors used different names to refer to the same taxon), you can then have these nodes each have their own idiosyncratic source label but reference the ""normalized"" otu element, which might have the ""canonical"" name on it.

The otu element is intended to model a ""taxon"" (in a pretty loose sense), so that annotations having to do with crossreferences to taxonomies should go there. Nodes are simply nodes.

A slight qualifier to @hlapp's remark: I would not put sequence identifiers on an otu, I'd put it on a sequence. If you want to get the sequence ID that a node as based on, you'd then have to go from node to otu and find the sequence that references that same otu. Specimen is a bit more tricky, I guess it depends on how the specimen is used (to identify a holotype, as a source of character state observations, ...)",NA,NA,NA
8,22867085,rvosa,2013-08-19T12:03:15Z,2013-08-19T12:03:15Z,"Maybe no longer relevant, but I would do the following. When you encounter a tree around which you want to build a valid NeXML document:

* insert the tree in a ""trees"" element

* have the ""trees"" element reference an ""otus"" element

* for every distinct tip label that you encounter in the tree, create an ""otu"" element within the ""otus"" and have the node create an ID reference to that otu

I know that it would be valid to create an empty ""otus"" element and stick it in front of the ""trees"" element but it obviously goes against the spirit (i.e. tips in trees are instances of some sort of taxonomic unit). It's just that in XML schema you can't create optional, nested constraints, i.e. *if* a node has an otu attribute, then the value must reference the ID of an otu element nested inside the otus element that the trees container references. Such a constraint cannot be specified in XML schema, allowing implementors to play fast and loose with the intent. 

Dendroscope does this (it creates an empty otus element), and it drives me crazy :-)",NA,NA,NA
1,22867535,rvosa,2013-08-19T12:14:42Z,2013-08-19T12:14:42Z,"I hope I am not too late with this suggestion, but if it's not too weird to do this in S4 it might be an idea to try to reproduce the inheritance tree of the schema types exactly. As you can see for example here (http://nexml.org/nexml/html/doc/schema-1/trees/tree/inheritance/), all types basically inherit like this:

* http://nexml.org/nexml/html/doc/schema-1/meta/annotations/#Base
* http://nexml.org/nexml/html/doc/schema-1/abstract/#Annotated
* http://nexml.org/nexml/html/doc/schema-1/abstract/#Labelled
* http://nexml.org/nexml/html/doc/schema-1/abstract/#IDTagged

...at which point the basic plumbing of attributes (id, label, xml:base and friends) and optional child elements (meta) is in place. 

Below that point in the inheritance tree are the abstract types that one ought to program against (basically like Java interfaces) and below those are then the concrete subclasses. 

The concrete subclasses inherit from their abstract superclass by ""restriction"" (which means, leaving things out or limiting their value ranges) so that you should be able to deal with all eventualities if you've coded against the superclass.

If you can stomach to reproduce the inheritance tree like that you are less likely to introduce subtle incompatibilities (and hacks to fix them) down the line.",NA,NA,NA
1,22983380,cboettig,2013-08-20T22:38:00Z,2013-08-20T22:38:00Z,"great point , will make life much easier on the R end as well. Should be
straight forward. Thanks for the links, I don't read raw schema well so I
was mostly templating of the  example nexml.  Tips like this are very
helpful
---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Aug 19, 2013 5:14 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> I hope I am not too late with this suggestion, but if it's not too weird
> to do this in S4 it might be an idea to try to reproduce the inheritance
> tree of the schema types exactly. As you can see for example here (
> http://nexml.org/nexml/html/doc/schema-1/trees/tree/inheritance/), all
> types basically inherit like this:
>
>    - http://nexml.org/nexml/html/doc/schema-1/meta/annotations/#Base
>    - http://nexml.org/nexml/html/doc/schema-1/abstract/#Annotated
>    - http://nexml.org/nexml/html/doc/schema-1/abstract/#Labelled
>    - http://nexml.org/nexml/html/doc/schema-1/abstract/#IDTagged
>
> ...at which point the basic plumbing of attributes (id, label, xml:base
> and friends) and optional child elements (meta) is in place.
>
> Below that point in the inheritance tree are the abstract types that one
> ought to program against (basically like Java interfaces) and below those
> are then the concrete subclasses.
>
> The concrete subclasses inherit from their abstract superclass by
> ""restriction"" (which means, leaving things out or limiting their value
> ranges) so that you should be able to deal with all eventualities if you've
> coded against the superclass.
>
> If you can stomach to reproduce the inheritance tree like that you are
> less likely to introduce subtle incompatibilities (and hacks to fix them)
> down the line.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/1#issuecomment-22867535>
> .
>",NA,NA,NA
8,22983706,cboettig,2013-08-20T22:44:11Z,2013-08-20T22:44:11Z,"Gotcha, makes perfect sense.  EML had the exact same issue about matching
reference ids so they wrote an extra validator script to enforce this.  We
can at least be sure to follow the intended conventions in RNeXML.  Lemme
know of any similar rules we want to stick with that a schema validation
wouldn't catch

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Aug 19, 2013 5:03 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> Maybe no longer relevant, but I would do the following. When you encounter
> a tree around which you want to build a valid NeXML document:
>
>    -
>
>    insert the tree in a ""trees"" element
>    -
>
>    have the ""trees"" element reference an ""otus"" element
>    -
>
>    for every distinct tip label that you encounter in the tree, create an
>    ""otu"" element within the ""otus"" and have the node create an ID reference to
>    that otu
>
> I know that it would be valid to create an empty ""otus"" element and stick
> it in front of the ""trees"" element but it obviously goes against the spirit
> (i.e. tips in trees are instances of some sort of taxonomic unit). It's
> just that in XML schema you can't create optional, nested constraints, i.e.
> *if* a node has an otu attribute, then the value must reference the ID of
> an otu element nested inside the otus element that the trees container
> references. Such a constraint cannot be specified in XML schema, allowing
> implementors to play fast and loose with the intent.
>
> Dendroscope does this (it creates an empty otus element), and it drives me
> crazy :-)
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/8#issuecomment-22867085>
> .
>",NA,NA,NA
1,23222223,cboettig,2013-08-25T05:25:24Z,2013-08-25T05:25:24Z,"@rvosa I'm missing something in my reading of the schema documentation here (probably from not knowing much about XSD):  I'm not clear what attributes or children are permitted by a `base` class.  For example, I see `annotated` means that the element can have the attribute `about`, but don't see `base` as specifying anything.  

Likewise, I'm a bit confused about the meaning of the Abstract/Literal/Resource prefixes on the element definitions.  For instance, it looks like the element called `meta` defines attributes `href` and `rel` and extends class `Meta`, which simply extends `Base`.  But the `meta` nodes I use often have coming from `literalMeta` (like `property`) and other attributes like `id`, so it's not clear to me where this all is defined.  ",NA,NA,NA
1,23394171,cboettig,2013-08-28T06:34:41Z,2013-08-28T06:34:41Z,"### conceptual issues

@rvosa I'm starting to figure out some of the finer points of the schema design, but still lots of puzzles for me.  I see that ""Abstract"" types are there because schema lets you define types as restrictions of other types as well as extensions -- e.g. `AbstractEdge` can have edge lengths restricted to Integers in type `TreeIntEdge`.  

Not sure how to approach this detail in mapping to S4, since I don't think we have the notion of restriction in R classes (though I could be wrong about that).  Since we don't have XMLSchema working on the complexity of NeXML, it's also a bit tedious to write out the restrictions as separate classes, and tempting to simply use the abstract class in these places, since they contain all the slots necessary.  Will this create any problems I am not considering?  When reading NeXML, it shouldn't be a problem as we have slots for everything still, and I think the difference between things like and edge of integer lengths vs double lengths is stored in it's `xsi:type`, so the data isn't lost even if the S4 object treats all lengths as doubles?  

Somewhat more tricky in writing to NeXML while allowing users to set types.  Of course R's phylo objects don't strictly have the notion (though I suppose you could define a valid S3 ape tree with either integer or doubles as the edge lengths, since S3 doesn't care) so some open questions about how a user writes this information in.  


### smaller issues


Not clear how `AbstractRootEdge` is defined: does this still appear in the NeXML as `<edge target=""n2"" ... >` with no source, or does the XML node have a different name, like `<rootEdge target =`? How can I tell from the Documentation?  

Also have no idea what `Sets` are or how they are used.  
",NA,NA,NA
1,23395688,rvosa,2013-08-28T07:20:11Z,2013-08-28T07:20:11Z,"> conceptual issues
>
> @rvosa <https://github.com/rvosa> I'm starting to figure out some of the
> finer points of the schema design, but still lots of puzzles for me. I see
> that ""Abstract"" types are there because schema lets you define types as
> restrictions of other types as well as extensions -- e.g. AbstractEdgecan have edge lengths restricted to Integers in type
> TreeIntEdge.
>
> Not sure how to approach this detail in mapping to S4, since I don't think
> we have the notion of restriction in R classes (though I could be wrong
> about that). Since we don't have XMLSchema working on the complexity of
> NeXML, it's also a bit tedious to write out the restrictions as separate
> classes, and tempting to simply use the abstract class in these places,
> since they contain all the slots necessary. Will this create any problems I
> am not considering? When reading NeXML, it shouldn't be a problem as we
> have slots for everything still, and I think the difference between things
> like and edge of integer lengths vs double lengths is stored in it's
> xsi:type, so the data isn't lost even if the S4 object treats all lengths
> as doubles?
>

That's right. In fact, that is kind of what I tried to convey: write the
code against the abstract classes such that they can deal with whatever
concrete subclass hangs below that. In practice that's going to mean a bit
of if/else logic based on the xsi:type, which isn't the prettiest thing in
the world but should be fine.

>  Somewhat more tricky in writing to NeXML while allowing users to set
> types. Of course R's phylo objects don't strictly have the notion (though I
> suppose you could define a valid S3 ape tree with either integer or doubles
> as the edge lengths, since S3 doesn't care) so some open questions about
> how a user writes this information in.
>
I guess you'd have to decide at writing time what a tree is based on
checking what the branch lengths are and hope for consistency on the user's
end. The fallback option to me seems to be to use doubles unless everything
is an int.

>  smaller issues
>
> Not clear how AbstractRootEdge is defined: does this still appear in the
> NeXML as <edge target=""n2"" ... > with no source, or does the XML node
> have a different name, like <rootEdge target =? How can I tell from the
> Documentation?
>
It's called rootedge, and you can see this where concrete instances of this
class are invoked, for example where it is specified what element names
(""substructures"") can occur inside an IntTree:
http://nexml.org/nexml/html/doc/schema-1/trees/tree/#IntTree


>  Also have no idea what Sets are or how they are used.
>
Sets are collections of things of the same type. The general idea is as
follows:
- everything that is referenced must precede the reference. This is why otu
elements come before trees and characters.
- an attribute that references something else is named after the element
type it references.
- sometimes it is handy to be able to define a set of things (e.g. in some
analyses you might want to define taxon sets).

This is why, at the bottom of a ""container element"" there can be zero or
more elements called ""set"". For example:

<otus id=""container"">
    <otu id=""foo"" />
    <otu id=""bar"" />
    <otu id=""baz"" />
    <set id=""otuSet"" otu=""foo bar"" />
</otus>

So the otuSet defines a set that contains foo and bar.


-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
1,23447065,cboettig,2013-08-28T20:57:45Z,2013-08-28T21:04:22Z,"@rvosa Excellent, thanks for the pointers.  We now have S4 classes defined with inheritance up through the abstract types. This covers all the classes / elements we had before, e.g. most of those appearing in the inst/examples/trees.xml.  We also have methods to convert NeXML into S4 classes and back (all in R/classes.R), e.g.

```ruby
require(XML)
require(RNeXML)

# Read the XML
root <- xmlRoot(xmlParse(system.file(""examples"", ""trees.xml"", package=""RNeXML"")))

# Toggle between XML and S4 representations
parsed <- as(root, ""nexml"")
serialized <- as(parsed, ""XMLInternalNode"")
```

Most of the ape methods aren't affected, since the S4 objects have all the slots they used to have (plus others they were missing that they now get from inheritance).  Ape methods still need some tuning anyway (i.e. #8)


A few little things missing still:

- [ ] So far I haven't added `network`, since I'm not sure about the R implementation (@hlapp any insight here?  I realize the ""ape"" format can officially define networks, but suspect that it's not intended to and might lead to some unexpected behavior?  I know the ouch format supports only trees (since the structure is defined by each node listing it's ancestor rather than a 'source'/'target' structure....

- [ ] I'm not really clear what attributes belong to `Base`.  I've stuck `xsi:type` there because it seemed to make sense....

- [ ] I'm still confused about `set`. I don't see why I'd want to use this; maybe I need a more flushed-out example?  

I'm also not exactly sure how I tell if something is ""referenced"" anyway: I realize that `<node otu = ""t1""/>` ""references"" `<otu id=""t1""/>`, so that the `otu` element must appear first.  But what makes it a reference?  The fact that `node` has both an attribute matching the name of an element and the attribute has a value matching the attribute of an element of that name?  Or is it sufficient just to have any attribute whose value matches the id attribute of another element (e.g. does `<foo bar=""t1""/>` reference the `<otu id =""t1""/>` element?)


one more minor one: 

- [ ] It looks like NeXML supports multiple <trees> elements, each with multiple <tree> elements.  I can imagine this might be useful, e.g. if each <trees> represents a posterior distribution of trees, and we still want multiple different trees in the same file.  Just not sure how handle the R conversion. 

ape has a notion of multiPhylo (a list of phylo objects), which maps nicely to a single `trees` element.  Given multiple `trees` elements, we could return a list of of multiPhylo objects to preserve that structure? Or just concatenate into a longer multiPhylo (with warning?).  
",NA,NA,NA
5,23457550,cboettig,2013-08-28T23:45:58Z,2013-08-28T23:45:58Z,"inheritance strategy discussed in #1 pretty much takes care of this.  A few optional slots are still neglected (`set`, `network`) as discussed in #1 already.  ",NA,NA,NA
14,23457994,cboettig,2013-08-28T23:55:44Z,2013-08-28T23:55:44Z,"I was just using the uuid package, which generates uuids that look like: 

```
> UUIDgenerate()
[1] ""f7af80aa-dfb2-4134-aa82-db1c0e9e7980""
```

No colons, so I'm not sure why the validator (accessed with the R wrapper to `xmllib2`) is unhappy.

Regardless, not sure uuids were a good idea for this purpose anyhow. The current workflow doesn't give the user the same flexibility over the DOM directly, so we probably don't have to worry about a user creating two S4 ""tree"" objects and then sticking them in the same nexml with duplicated IDs.  

Instead, there is a method for `phylo->nexml` that creates the ids for otus as t1, t2..., nodes as n1, n2..., edges as e1, e2... etc (done).  A separate method for `multiPhylo -> nexml` will allow the user to add multiple trees while avoiding id conflicts (not written yet).  With a sensible top-level API I think we should be fine using these simple ids(?)",NA,NA,NA
6,23458067,cboettig,2013-08-28T23:57:27Z,2013-08-28T23:57:27Z,"Thanks both for the explanation. I think I have a much better handle on the logic of references now, and this approach (at least in regards to node and otu elements) is now implemented as discussed in #8 ",NA,NA,NA
2,23458175,cboettig,2013-08-29T00:00:11Z,2013-08-29T00:00:11Z,"Might wait until we know what the top-level API looks like, which really needs the documentation most.  (e.g. most users will probably be fine with just `read.nexml` and `write.nexml`, which should be rich enough to handle everything.  

The details of the class definitions and the coercions between XML and S4 are really for internal use, and are reasonably self-documenting anyway",NA,NA,NA
10,23736476,cboettig,2013-09-03T18:38:57Z,2013-09-03T18:38:57Z,"import doesn't get rid of this on install, for some reason.  Not sure if these notes are actually a problem, since they appear in other package installs as well that are already on CRAN (e.g. dataone), but still, an annoying message.  Anyway, doesn't seem to be an actual bug.  ",NA,NA,NA
13,23736500,cboettig,2013-09-03T18:39:17Z,2013-09-03T18:39:17Z,Will flush out a list of special cases in new issues we encounter them in testing (see #15).  ,NA,NA,NA
4,23736602,cboettig,2013-09-03T18:40:41Z,2013-09-03T18:40:41Z,Will address on an as needed basis through testing and community input.  Pretty simple to extend classes by hand anyhow.  ,NA,NA,NA
15,23745285,sckott,2013-09-03T20:43:38Z,2013-09-03T20:43:38Z,"No worries on the bugs. I have many to take care of myself. 

Right, makes sense on checking if trees are correct. 

Okay, will get to this later today hopefully. ",NA,NA,NA
15,23876461,sckott,2013-09-05T15:30:14Z,2013-09-05T15:30:14Z,"Forget to mention this issue, three commits are relavant here ada8def5cc5a2bf93c91b4dfc3ec83dfee87c1b2 , c949693bc85f44c12c493c00dd82827b55370903 , and ced59fb9f6b7b13d8d2df58f21ae5f7a3da40f45",NA,NA,NA
15,23883077,cboettig,2013-09-05T16:48:42Z,2013-09-05T16:48:42Z,"rock on! These look great.  

Are they all passing for you?  It appears that `test_that` tests cannot use variables defined inside other tests, so I moved the shared initializations out above the `test_that` calls in `test_inheritance.R`, and now most of those pass for me (using `test_dir(""inst/tests/"")`.  (Just pushed these).

The first inheritance test still fails, somehow I'm not writing `xsi:type` out to the `meta` node correctly, so that's something I have to fix.  ",NA,NA,NA
15,23883595,sckott,2013-09-05T16:55:20Z,2013-09-05T16:55:20Z,"Woops, thanks for fixing that. 

Right, that first inheritance test fails for me too. They aren't quite identical as you said. ",NA,NA,NA
1,23958412,cboettig,2013-09-06T18:05:36Z,2013-09-06T18:05:36Z,"We now have the inheritance-based implementation of classes following [the advice](https://github.com/ropensci/RNeXML/issues/1#issuecomment-22867535) of @rvosa from earlier in this thread, so I think we can close this issue.  I've moved the few remaining questions about references and sets to a separate thread.  ",NA,NA,NA
3,23964461,sckott,2013-09-06T19:43:55Z,2013-09-06T19:43:55Z,@cboettig not sure how aliases work I guess. What is the point of aliases if the alias isn't available to use as such? I must not understand what they do,NA,NA,NA
3,23965063,cboettig,2013-09-06T19:54:26Z,2013-09-06T19:54:26Z,"aliases give another name to a function as a convenience to the user.  For
example, `qplot` in ggplot is aliased as `quickplot` -- so you can call
`quickplot` in your code anywhere you call qplot.  (Perhaps because you
wanted the code to be more 'self-documenting' and found the name `qplot` to
be mysterious...). See
https://github.com/hadley/ggplot2/blob/8faa879b3d55877d9b9ef018a610178fc490428e/R/quick-plot.r
for
the roxygen documentation of qplot.

I thought it might be helpful to some users to have nexml_write be aliases
as write.nexml, mimicking the existing write.nexus naming convention.
 Perhaps I just need to put both the real function name and the alias in my
alias list??



On Fri, Sep 6, 2013 at 12:43 PM, Scott Chamberlain <notifications@github.com
> wrote:

> @cboettig <https://github.com/cboettig> not sure how aliases work I
> guess. What is the point of aliases if the alias isn't available to use as
> such? I must not understand what they do
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/3#issuecomment-23964461>
> .
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
3,23965120,sckott,2013-09-06T19:55:37Z,2013-09-06T19:55:37Z,"Okay, cool. Yeah, not sure how to make aliases work, but neither `write.nexml` nor `read.nexml` is there",NA,NA,NA
3,23968327,cboettig,2013-09-06T20:49:54Z,2013-09-06T20:49:54Z,"Aha!

So the `@aliases` tag doesn't do much - it just lets R know that two functions share the same documentation.  
You still need to define the alias function as a copy of the existing function manually,  e.g. add the line `read.nexml <- nexml_read`.  You also need to add both function names explicitly after the `@export`  ",NA,NA,NA
14,23968530,cboettig,2013-09-06T20:53:21Z,2013-09-06T20:53:21Z,"Okay, I think we're happy with our only locally unique ids for the moment. (Though still unsure what was wrong with the uuid above according to the validator...).  Anyway, closing this issue.  ",NA,NA,NA
19,23972930,sckott,2013-09-06T22:16:15Z,2013-09-06T22:16:15Z,"@cboettig That seems reasonable at small scale, but with huge xml files then we would be putting a lot of data into the users workspace without them realizing it. ",NA,NA,NA
18,23991105,rvosa,2013-09-07T09:22:36Z,2013-09-07T09:22:36Z,"Hi Carl,

not sure what your question is here. I don't know what term to use for
license, but most others can be done with Dublin Core and prism.

Rutger


On Fri, Sep 6, 2013 at 10:36 PM, Carl Boettiger <notifications@github.com>wrote:

> There's a variety of meta elements we might want to attach to the top of
> most nexml documents we write
>
>    -  Creator, with contact information
>    -  Title
>    -  Description
>    -  License declaration (e.g. CC0)
>    -  Timestamp
>    -  Information about where the file is released / published (e.g.
>    Github, Dryad, etc)
>    -  Journal citation information of an associated article
>
> Will give us some good practice writing RDFa style meta elements before
> we tackle more serious annotation. @rvosa <https://github.com/rvosa>
> @hlapp <https://github.com/hlapp> might you point to a good model NeXML
> files we can template off of for these? (e.g. the treebase nexmls are a
> good example of journal citation info, and a couple others. Not sure if
> I've seen a license example). Clearly this involves identifying the
> ontology for most terms here (though dublin core may cover most of it).
>
> Some of these (license, timestamp) we might consider adding by default(?).
>
> A good implementation will allow the user to pass R's native objects where
> relevant (e.g. person, citation) to be included.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/18>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
16,23991195,rvosa,2013-09-07T09:31:14Z,2013-09-07T09:31:14Z,">
> The fact that node has both an attribute matching the name of an element
> and the attribute has a value matching the attribute of an element of that
> name?
>

This.",NA,NA,NA
18,24005600,hlapp,2013-09-07T17:21:52Z,2013-09-07T17:21:52Z,"dcterms:rights

-hilmar

Sent with a tap.

On Sep 7, 2013, at 5:22 AM, Rutger Vos <notifications@github.com> wrote:

> Hi Carl, 
> 
> not sure what your question is here. I don't know what term to use for 
> license, but most others can be done with Dublin Core and prism. 
> 
> Rutger",NA,NA,NA
16,24024598,cboettig,2013-09-08T16:59:59Z,2013-09-08T16:59:59Z,Thanks!,NA,NA,NA
18,24025943,cboettig,2013-09-08T18:07:35Z,2013-09-20T20:24:43Z,"As noted in the commit log, I've taken a stab at each of these.  @hlapp @rvosa thanks for the pointers above.  It would probably be good if you could comment on the implementation (e.g. see here: https://github.com/ropensci/RNeXML/blob/31a69a37834f0c652dc49eeb2f13d1e91448eea5/inst/examples/meta_example.xml) 



In particular: 
- [x]  I've included license as a ReferenceMeta node with link to the license file.  (a) is that okay? and (b) should I still be writing a dc:terms LiteralMeta node associated with it?
- [x] This validates, but I suspect I should be doing something with `id` and possibly `about` here to clarify what these nodes are annotating, but I'm not sure what.  (Also not sure how to add id values in a clean workflow -- should I just check the document each time to find what integer my counter is up to??)
- [ ] How do I add a ""Contact"" node with the email address of the person to contact for questions about the data?  Any concerns about adding such a node (spam etc) I should be considering?


Also, an example R function call can be seen in the test:

https://github.com/ropensci/RNeXML/blob/31a69a37834f0c652dc49eeb2f13d1e91448eea5/inst/tests/test_meta.R

Anyone have thoughts on how this api call?  

thanks!",NA,NA,NA
15,24026708,cboettig,2013-09-08T18:48:48Z,2013-09-08T18:48:48Z,"@SChamberlain Thanks for writing the extra test cases.  Would you be interested in running some testing of trying to parse a bunch of nexml files (e.g. https://github.com/rvosa/supertreebase/tree/master/data/treebase ) and seeing if we get any errors?  

Similarly would be good to try and write a bunch of ape files into NeXML, if you have some lying around (or can grab from the nexus using the treebase api...)  

Such tests probably would never become part of our standard unit tests, but it would be good to have run a few more different files through the pipes just to see.  The unit tests all reuse the same handful of trees over and over...

",NA,NA,NA
15,24026762,sckott,2013-09-08T18:51:32Z,2013-09-08T18:51:32Z,"@cboettig Yep, will do both of those. ",NA,NA,NA
22,24035538,hlapp,2013-09-09T02:22:14Z,2013-09-09T02:22:14Z,Some of the motivation for the package is presumably in the Google Summer of Code project idea description?,NA,NA,NA
22,24036331,cboettig,2013-09-09T02:55:36Z,2013-09-09T02:55:36Z,"Indeed, I think Kseniia's project description is a great starting point for the motivation and potential here.  ",NA,NA,NA
22,24039242,sckott,2013-09-09T04:17:35Z,2013-09-09T04:17:35Z,"Good idea. And ask maintainers of specific packages like ape, etc., or perhaps r-sig-phylo will cover those folks",NA,NA,NA
21,24056337,rvosa,2013-09-09T09:16:31Z,2013-09-09T09:16:31Z,"It would be good to have annotations on the nodes that were 'anchored',
e.g. what the basis of the date was (fossil?), whether it's a lower or
upper limit or a range.",NA,NA,NA
20,24056452,rvosa,2013-09-09T09:18:27Z,2013-09-09T09:18:27Z,"I think the former is more immediately useful than the latter. For example,
if there are numerical annotations on all the nodes in a tree (like a
bootstrap value or posterior probability) it would probably be useful to
have this as a list in parallel with the list of nodes so that calculations
can be done over the list.",NA,NA,NA
18,24058375,rvosa,2013-09-09T09:48:10Z,2013-09-09T09:48:10Z,"> As noted in the commit log, I've taken a stab at each of these. @hlapp<https://github.com/hlapp>
> @rvosa <https://github.com/rvosa> thanks for the pointers above. It would
> probably be good if you could comment on the implementation (e.g. see here:
> https://github.com/ropensci/RNeXML/blob/31a69a37834f0c652dc49eeb2f13d1e91448eea5/inst/examples/meta_example.xml)
>
>
> In particular:
>
>    -  I've included license as a ReferenceMeta node with link to the
>    license file. (a) is that okay? and (b) should I still be writing a
>    dc:terms LiteralMeta node associated with it?
>
> I *think* it should be ok as is. I had no idea there were cc: vocabulary
terms but now that I see there are I think there is no need to duplicate
the annotation as a dcterms literal.


>    -  This validates, but I suspect I should be doing something with idand possibly
>    about here to clarify what these nodes are annotating, but I'm not
>    sure what. (Also not sure how to add id values in a clean workflow --
>    should I just check the document each time to find what integer my counter
>    is up to??)
>
> No, you don't have to. Without id or about in any of the containing
elements (in this case, just the root element) the RDFa annotations are
about the resource as a whole, i.e. the URI of the document. I think this
is correct. Here you can see how that pans out:

http://www.w3.org/2012/pyRdfa/extract?uri=https%3A%2F%2Fraw.github.com%2Fropensci%2FRNeXML%2F31a69a37834f0c652dc49eeb2f13d1e91448eea5%2Finst%2Fexamples%2Fmeta_example.xml&format=turtle&rdfagraph=output&vocab_expansion=false&rdfa_lite=false&embedded_rdf=true&space_preserve=true&vocab_cache=true&vocab_cache_report=false&vocab_cache_refresh=false


>    -  How do I add a ""Contact"" node with the email address of the person
>    to contact for questions about the data? Any concerns about adding such a
>    node (spam etc) I should be considering?
>
> I suppose you could use FOAF terms (http://xmlns.com/foaf/spec/) to
identify persons but I would hesitate to put someone's email in there.

>
>
> Also, an example R function call can be seen in the test:
>
>
> https://github.com/ropensci/RNeXML/blob/31a69a37834f0c652dc49eeb2f13d1e91448eea5/inst/tests/test_meta.R
>
> Anyone have thoughts on how this api call?
>
> thanks!
>
Maybe you don't need to hardcode all that many terms in there. Would it not
be handier to have an easy way to say which prefix goes with which
namespace and then specify the terms *with* their respective prefixes? This
is probably not the right solution at all but hopefully you can see what I
mean:

nexml_write(bird.orders, file=""meta_example.xml"",
              namespaces = c(
                     list(prefix=""cc"",uri=""http://creativecommons.org/ns#""),

list(prefix=""dcterms"",uri=""http://dublincore.org/documents/dcmi-terms/"")
              ),
              ""dcterms:title"" = ""My test title"",
              ""dcterms:description"" = ""A description of my test"",
              ""dcterms:creator"" = ""Carl Boettiger <cboettig@gmail.com>"",
              ""cc:license"" =
""http://creativecommons.org/publicdomain/zero/1.0/"",

)",NA,NA,NA
15,24101580,sckott,2013-09-09T18:14:45Z,2013-09-09T18:14:45Z,working on this now...,NA,NA,NA
15,24185023,sckott,2013-09-10T18:52:46Z,2013-09-10T18:52:46Z,"Hey @cboettig , the new tests I wrote in the `inst/tests/conversions` file run from a separate set of files here https://github.com/ropensci/RNeXML_testfiles 

The `conversions`  file does not run when you do `test_package(""RNeXML"")`, so that's good. 

Please do change the setup, or let me know what you want changed.  

Also note that tests still fail on the serializing and top level API tests. ",NA,NA,NA
18,25734785,cboettig,2013-10-04T22:37:59Z,2013-10-04T22:37:59Z,"I think I am leaning towards a hybrid approach in specifying the metadata, though I could probably be talked out of it.  I would like RNeXML to encourage the use of generic metadata such as in our list above without users having to know anything about namespaces. This has me leaning towards hard-coding the namespaces for the Dublin core elements as I show above.

Meanwhile we certainly want to support arbitrary addition of metadata.  As we already have defined an R class for `meta` elements, it seems the easiest/most natural way to support this is simply to ask the user to provide a list of `meta` nodes (either of ResourceMeta, for links, or of LiteralMeta type), like this:

```coffee
  history <- new(""meta"", 
      content = ""Mapped from the bird.orders data in the ape package using RNeXML"",
      datatype = ""xsd:string"", id = ""meta5144"", property = ""skos:historyNote"", 
      'xsi:type' = ""LiteralMeta"")
  modified <- new(""meta"",
                  content = ""2013-10-04"", datatype = ""xsd:string"", id = ""meta5128"",
                  property = ""prism:modificationDate"", 'xsi:type' = ""LiteralMeta"")
  website <- new(""meta"", 
                 href = ""http://carlboettiger.info"", 
                 rel = ""foaf:homepage"", 'xsi:type' = ""ResourceMeta"")
  nexml_write(bird.orders, 
              file = ""example.xml"", 
              additional_metadata = list(history, modified, website), 
              additional_namespaces = c(skos = ""http://www.w3.org/2004/02/skos/core#"",
                                        prism = ""http://prismstandard.org/namespaces/1.2/basic/"",
                                        foaf = ""http://xmlns.com/foaf/0.1/""))

 ```

This is certainly a bit more verbose and less elegant than the named string approach @rvosa proposes above, though it does support specifying `datatype` and `id` fields, etc.  This is supported in the latest commit e99ba7e, (with unit test as shown above).  

A third input option might be to support pure RDF / RDFa strings -- for instance, if a user has extracted a whole set of triples from somewhere else as RDF and wishes to write them in without too much fuss.  


While we could support multiple ways to input this data, I guess the challenge is to find right balance between an interface that flexible enough to meet the needs of a range of users without becoming too confusing.  





",NA,NA,NA
21,25735531,cboettig,2013-10-04T22:54:25Z,2013-10-24T19:33:42Z,"Extending the to-do list based on semantic objectives proposed in Kseniia's project description, with some comments from me on implementation:

- [x]  to convey links from trees to associated publications;

_I think I will just map R's `citation` class object into `prism` metadata, as done in TreeBASE.  Any preference for prism over Shotton's SPAR ontologies for this??_  

- [x] to convey links from terminal nodes (less importantly, internal nodes) to taxonomic identifiers (and other forms of alternative labeling);

_Native to NeXML already.  We should just add a function that will use Scott's `taxize` package to get TSN identifiers for species names (e.g. when extracted from an `ape::phylo$tip.label` and add the identifier to the `otu` node metadata_

- [ ] to convey reconciliation results (duplication, speciation, lateral transfer);

_Um, not so sure.  Can someone point me to examples of NeXML files that have such annotations?_

- [ ] to convey compound branch features such as lengths with uncertainties (a la DateLife), or multiple types of support values (bootstrap + posteriors).

_It seems like this would be most useful if we provided functions that could also operate on this data.  For now, this data would be read in to R and could be displayed, but as it is not part of the ape or phylo4 classes, no function could do anything with it.  Ideally I imagine providing a function that could ""draw a tree"" from the distribution implied by the branch uncertainty, providing an easy way for R programmers to integrate over this uncertainty using only existing tools. Also still need to figure out the best way to write annotations to branches.  Currently requires knowledge of the S4 structure._


",NA,NA,NA
20,25735943,cboettig,2013-10-04T23:03:18Z,2013-10-04T23:03:18Z,"Metadata extraction function wish-list: 

- [ ] Provide visual/plain text, concise summary of all metadata available (e.g. extract RDF -> turtle)
- [ ] A `citation` function providing the essential metadata needed to cite the nexml resource, including any publication involved.  
- [ ] otu summary: showing the species/otus involved.  
- [ ] Run a block of code for a method provided?
- [ ] sample from a distribution given branch-length uncertainty annotations?

We might illustrate counting trees, tips, taxa, etc, but this is most naturally done using existing approaches for existing formats rather than providing a dedicated function.  


Should probably break these into separate issues...",NA,NA,NA
21,25759813,hlapp,2013-10-06T00:17:06Z,2013-10-06T00:17:06Z,"Re: citation metadata, you might want to consider the BIBO vocabulary.",NA,NA,NA
21,25804698,rvosa,2013-10-07T12:36:04Z,2013-10-07T12:36:04Z,"Hi Carl,


>    -  to convey links from trees to associated publications; *I think I
>    will just map R's citation class object into prism metadata, as done
>    in TreeBASE. Any preference for prism over Shotton's SPAR ontologies for
>    this??*
>
> I don't care.

>
>    -  to convey links from terminal nodes (less importantly, internal
>    nodes) to taxonomic identifiers (and other forms of alternative labeling);
>    *Native to NeXML already. We should just add a function that will use
>    Scott's taxize package to get TSN identifiers for species names (e.g.
>    when extracted from an ape::phylo$tip.label and add the identifier to
>    the otu node metadata*
>
> Sounds great. I was a little worried at first when you said ""terminal
nodes"" but you clarify later that you mean metadata attached to the otu
element, which is probably the better place for taxonomic identifiers.

>
>    -  to convey reconciliation results (duplication, speciation, lateral
>    transfer); *Um, not so sure. Can someone point me to examples of NeXML
>    files that have such annotations?*
>
> Gene duplication and speciation events are usually mapped onto trees using
phyloxml or nhx (i.e. Chris Zmasek has developed this). In Bio::Phylo I've
added the option of reading and writing phyloxml and translating it to
nexml. The way I dealt with the events annotations was to make the terms as
they are used in phyloxml into semantic annotations whose namespace is ""
http://www.phyloxml.org/1.10/terms#"". I don't know if it's urgent to
replicate this functionality in R, though.

>
>    -  to convey compound branch features such as lengths with
>    uncertainties (a la DateLife), or multiple types of support values
>    (bootstrap + posteriors). _It seems like this would be most useful if we
>    provided functions that could also operate on this data. For now, this data
>    would be read in to R and could be displayed, but as it is not part of the
>    ape or phylo4 classes, no function could do anything with it. Ideally I
>    imagine providing a function that could ""draw a tree"" from the distribution
>    implied by the branch uncertainty, providing an easy way for R programmers
>    to integrate over this uncertainty using only existing tools
>
> My guess is that this might be the most important feature that R users
might take out of this. They're going to want to do numerical things so if
NeXML can offer them branch lengths (with intervals) and support values so
they can easily rip through them across a large tree or a set of trees I
think that would be great.

Secondly, by ""draw a tree"" I suppose you mean to simulate one (or one
million) within the interval that is specified in the annotation (prettier
still if that annotation also specifies what the underlying distribution
is, I guess).

With my monday morning eyes I first thought you were talking about
visualization - which would also be excellent. Is the current industry
standard to somehow convince figtree to show node bars which you then poke
at in illustrator? Anyway, visualization of NeXML annotations would be
great too - though kind of a separate story altogether.

>
>
> Also still need to figure out the best way to write annotations to
> branches. Currently requires knowledge of the S4 structure.
>
I have no good tips here. Other than for the Java API I haven't implemented
edge objects with annotations attached to them.

Rutger",NA,NA,NA
18,25805002,rvosa,2013-10-07T12:41:52Z,2013-10-07T12:41:52Z,"Would it be difficult/bug prone to try to hide some of this from the user?

For example, can we guess what the datatype is from the ""content"" (at
least, separate strings from some types of numbers and booleans)?

Also, I assume we can just decide what the xsi:type is on the basis of
there being a ""property"" argument (in which case xsi:type is always
LiteralMeta) or a ""rel"" argument (xsi:type=ResourceMeta).


On Sat, Oct 5, 2013 at 12:37 AM, Carl Boettiger <notifications@github.com>wrote:

> I think I am leaning towards a hybrid approach in specifying the metadata,
> though I could probably be talked out of it. I would like RNeXML to
> encourage the use of generic metadata such as in our list above without
> users having to know anything about namespaces. This has me leaning towards
> hard-coding the namespaces for the Dublin core elements as I show above.
>
> Meanwhile we certainly want to support arbitrary addition of metadata. As
> we already have defined an R class for meta elements, it seems the
> easiest/most natural way to support this is simply to ask the user to
> provide a list of meta nodes (either of ResourceMeta, for links, or of
> LiteralMeta type), like this:
>
>   history <- new(""meta"",
>       content = ""Mapped from the bird.orders data in the ape package using RNeXML"",
>       datatype = ""xsd:string"", id = ""meta5144"", property = ""skos:historyNote"",
>       'xsi:type' = ""LiteralMeta"")
>   modified <- new(""meta"",
>                   content = ""2013-10-04"", datatype = ""xsd:string"", id = ""meta5128"",
>                   property = ""prism:modificationDate"", 'xsi:type' = ""LiteralMeta"")
>   website <- new(""meta"",
>                  href = ""http://carlboettiger.info"",
>                  rel = ""foaf:homepage"", 'xsi:type' = ""ResourceMeta"")
>   nexml_write(bird.orders,
>               file = ""example.xml"",
>               additional_metadata = list(history, modified, website),
>               additional_namespaces = c(skos = ""http://www.w3.org/2004/02/skos/core#"",
>                                         prism = ""http://prismstandard.org/namespaces/1.2/basic/"",
>                                         foaf = ""http://xmlns.com/foaf/0.1/""))
>
> This is certainly a bit more verbose and less elegant than the named
> string approach @rvosa <https://github.com/rvosa> proposes above, though
> it does support specifying datatype and id fields, etc. This is supported
> in the latest commit e99ba7e<https://github.com/ropensci/RNeXML/commit/e99ba7e>,
> (with unit test as shown above).
>
> A third input option might be to support pure RDF / RDFa strings -- for
> instance, if a user has extracted a whole set of triples from somewhere
> else as RDF and wishes to write them in without too much fuss.
>
> While we could support multiple ways to input this data, I guess the
> challenge is to find right balance between an interface that flexible
> enough to meet the needs of a range of users without becoming too
> confusing.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/18#issuecomment-25734785>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
18,25832374,cboettig,2013-10-07T18:23:33Z,2013-10-07T18:23:33Z,"@rvosa Great point; added a small constructor function to simplify the call somewhat. This avoids calling ""new"" and avoids specifying `xsi:type`. 


```coffee
  history <- meta(content=""Mapped from the bird.orders data in the ape package using RNeXML"",
                  datatype=""xsd:string"",  id=""meta5144"", property=""skos:historyNote"")

  modified <- meta(content=""2013-10-04"", datatype=""xsd:string"", id=""meta5128"",
                  property=""prism:modificationDate"")

  website <- meta(href=""http://carlboettiger.info"", rel=""foaf:homepage"")

  nexml_write(bird.orders, 
              file = ""example.xml"", 
              additional_metadata = list(history, modified, website), 
              additional_namespaces = c(skos=""http://www.w3.org/2004/02/skos/core#"",
                                        prism=""http://prismstandard.org/namespaces/1.2/basic/"",
                                        foaf = ""http://xmlns.com/foaf/0.1/""))
```


Note that `nexml_write` has defaults for all arguments except the tree itself, so that a user can simply call 

```coffee
nexml_write(bird.orders)
```

with no other arguments. This will return the a character string of the nexml, with default license and pub date, and other metadata fields omitted. 

Always up for more suggestions to simplify the user calls, since that's something we want to get pretty solid before we get any users; while tuning the back end functionality can always continue without breaking the api. 
",NA,NA,NA
19,25848318,cboettig,2013-10-07T21:48:39Z,2013-10-07T21:48:39Z,"In general it would be useful to read in a nexml object that could be passed directly to functions based on ape trees without requiring coercion and dropping of metadata. 

I never understood why phylobase didn't do this -- but it appears that phylo4 objects do not inherit the phylo S3 class and cannot be passed to phylo functions without explicit coercion:  

```coffee
library(phylobase)
library(ape)
data(bird.orders)
bird.orders4 <- as(bird.orders, ""phylo4"") # make ape::phylo tree into phylobase::phylo4 S4 class
plot.phylo(bird.orders4) # attempting to use the S4 fails
```

Of course a `plot` function is defined for phylo4, but more interesting functions are not written for phylo4, so this is a huge handicap: consider: 

```coffee
 S <- c(10, 47, 69, 214, 161, 17, 355, 51, 56, 10, 39, 152,
             6, 143, 358, 103, 319, 23, 291, 313, 196, 1027, 5712)
bd.ext(bird.orders4, S)   # Fails again. Works with the S3 type 
```

Anyway, it appears this problem can be solved using `setOldClass`.   I've defined an the class `phyloS4` which inherits all methods for the S3 `phylo` class without having to explicitly declare those methods. In this way, we have the benefits of an S4 class while maintaining compatibility with all developers who only write functions based on the S3 class.  (as long as functions don't stupidly check the string identity `class(obj) == ""phylo""`, instead of using the proper class check `is(obj, ""phylo"")`....)


I can then build a new class, `nexmlTree` by extending this class.  Again my new class acts like an S3 `phylo` in any such functions, but adds a representation containing all the nexml data.  This approach doesn't minimize memory footprint, but usually that is not a concern for R users (otherwise coercion is always an option).  It does satisfy the need for an object that works with all existing functions while also containing any and all metadata we can express in nexml. 

See [R/extend_phylo.R](https://github.com/ropensci/RNeXML/tree/master/R/extend_phylo.R) for the defitition.  



",NA,NA,NA
23,25849367,hlapp,2013-10-07T22:03:57Z,2013-10-07T22:03:57Z,"
On Oct 7, 2013, at 3:04 PM, Carl Boettiger wrote:

> Can a <meta> element have child meta elements?


Yes.",NA,NA,NA
23,25849454,cboettig,2013-10-07T22:05:29Z,2013-10-07T22:05:29Z,"nice.  I must have missed that in the definition.  

Not sure how R feels about defining classes that contain themselves though... Any ideas?
Also, do we have `resource` and `typeof`?",NA,NA,NA
23,25869807,rvosa,2013-10-08T07:30:24Z,2013-10-08T07:30:24Z,"We don't have resource or typeof as ""native"" attributes (though I suspect
they are allowable on meta elements) but if you insist on having complex
rdf/xml structures you can nest those inside a meta element.

On Tuesday, October 8, 2013, Carl Boettiger wrote:

> nice. I must have missed that in the definition.
>
> Not sure how R feels about defining classes that contain themselves
> though... Any ideas?
> Also, do we have resource and typeof?
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/23#issuecomment-25849454>
> .
>


-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
18,25978039,rvosa,2013-10-09T14:58:29Z,2013-10-09T14:58:29Z,"Would it be possible to make the `datatype` argument optional, so that the API tries to guess if something is a string/number/etc.? Obviously this isn't always going to work (and in any case users may have their own reasons for wanting to coerce an annotation into some data type) but the most common use case is probably a string - it would be a hassle if you *have* to say so every time.",NA,NA,NA
18,25984311,cboettig,2013-10-09T16:10:24Z,2013-10-09T16:10:24Z,"Sure. It is optional now but default is to omit it, didn't know if that was
okay ( think the validator didn't complain...)

Sure, we can default to xs:string instead; or pick tge value based on the
class of the 'content' ( eg if it is a character string, integer, logical
etc)

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Oct 9, 2013 8:43 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> Would it be possible to make the datatype argument optional, so that the
> API tries to guess if something is a string/number/etc.? Obviously this
> isn't always going to work (and in any case users may have their own
> reasons for wanting to coerce an annotation into some data type) but the
> most common use case is probably a string - it would be a hassle if you *
> have* to say so every time.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/18#issuecomment-25978039>
> .
>",NA,NA,NA
18,25985146,rvosa,2013-10-09T16:20:22Z,2013-10-09T16:20:22Z,"The attribute does need to end up in the XML in order to be valid (i.e.
it's not optional in that sense) but I was wondering if it could be made an
optional argument in the call to generate the meta, so that the API can
help users in providing sensible defaults given the class of the 'content'.
It sounds like that's possible - though it means maintaining an internal
mapping between R class names and xs:* data type names.


On Wed, Oct 9, 2013 at 6:10 PM, Carl Boettiger <notifications@github.com>wrote:

> Sure. It is optional now but default is to omit it, didn't know if that
> was
> okay ( think the validator didn't complain...)
>
> Sure, we can default to xs:string instead; or pick tge value based on the
> class of the 'content' ( eg if it is a character string, integer, logical
> etc)
>
> ---
> Carl Boettiger
> http://carlboettiger.info
>
> sent from mobile device; my apologies for any terseness or typos
> On Oct 9, 2013 8:43 AM, ""Rutger Vos"" <notifications@github.com> wrote:
>
> > Would it be possible to make the datatype argument optional, so that the
> > API tries to guess if something is a string/number/etc.? Obviously this
> > isn't always going to work (and in any case users may have their own
> > reasons for wanting to coerce an annotation into some data type) but the
> > most common use case is probably a string - it would be a hassle if you
> *
> > have* to say so every time.
> >
> > —
> > Reply to this email directly or view it on GitHub<
> https://github.com/ropensci/RNeXML/issues/18#issuecomment-25978039>
> > .
> >
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/18#issuecomment-25984311>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
18,26358099,cboettig,2013-10-15T18:07:04Z,2013-10-15T18:07:04Z,"As documented in commit above, we now have test cases for validation on our added basic metadata ([inst/tests/test_meta.R](https://github.com/ropensci/RNeXML/blob/master/inst/tests/test_meta.R)), and a cleaner interface for doing so.  Think this closes this issue for basic metadata(?) 

(re-open with additional steps otherwise).  ",NA,NA,NA
19,26359031,cboettig,2013-10-15T18:17:56Z,2013-10-15T18:17:56Z,"Looking for feedback on this approach. 

It appears that phylobase didn't choose to extend the `phylo` class in a way that `phylo4` objects could be simply passed to existing functions designed for the S3 `phylo` objects.  This is possible, as I have now implemented with the tentatively named `nexmlTree` class, and describe here: http://carlboettiger.info/2013/10/07/nexml-phylo-class-extension.html 


On one hand, it seems to make sense that we want an object that both has the metadata attached to it, with methods that can operate to extract, display, and potentially compute on that metadata, but still works as a tree object in all existing functions.  

On the other hand, this makes a larger object, since it has all this metadata attached (possibly not a problem?). It can also introduce more potential trouble to have users using this object directly in their workflow, instead of converting to a vanilla `phylo` object and using that (for instance, as I describe in my linked notes, methods that check class with string matching instead of the built-in method will throw an error). 

Seems it is an important design choice whether we build methods around the extended class or have separate methods for working on RNeXML S4 object metadata and just convert that to an `ape::phylo` for tree methods? @SChamberlain @hlapp @rvosa thoughts? 

",NA,NA,NA
23,26364613,cboettig,2013-10-15T19:27:27Z,2013-10-15T19:27:27Z,"@rvosa sweet, that's a perfect solution for complex rdf structures.  I've added support for this to the meta class, works like this:

```coffee
  rdfa <- '<div typeof=""foaf:Person"" about=""http://carlboettiger.info#me"">
             <a rel=""foaf:account"" href=""https://twitter.com/cboettig"">twitter</a> 
             <a rel=""foaf:account"" href=""https://github.com/cboettig"">github</a>
           </div>'
  parsed <- xmlRoot(xmlParse(rdfa))
  arbitrary_rdfa <- meta(property=""eml:additionalMetadata"", content=""additional metadata"", children = parsed)
```

Note that we parse the arbitrary RDFa string as XML first, as the function expects `children` to be R's XML instead of just some arbitrary character string (e.g. the `rdfa` string).  

Then we can write and parse this as usual:

```coffee
  nexml_write(bird.orders, 
            file = ""example.xml"", 
            additional_metadata = list(arbitrary_rdfa), 
            additional_namespaces = c(foaf = ""http://xmlns.com/foaf/0.1/"", 
                                      eml = ""eml://ecoinformatics.org/eml-2.1.1""))
```
 
Test added, with schema validation, to `test_meta.R`
",NA,NA,NA
23,26364743,cboettig,2013-10-15T19:29:05Z,2013-10-15T19:29:05Z,"(As usual, let me know if this implementation is problematic -- I'm still not very solid on rdfa)",NA,NA,NA
24,26365218,sckott,2013-10-15T19:35:31Z,2013-10-15T19:35:31Z,"You can also play with a local version of the ITIS database if you want. See the taxize `sql` branch, and the itis.R file. I started to make local database call versions of each of their functions. ",NA,NA,NA
19,26367652,sckott,2013-10-15T20:08:16Z,2013-10-15T20:08:16Z,"> whether we build methods around the extended class or have separate methods for working on RNeXML S4 object metadata and just convert that to an ape::phylo for tree methods

Do you have a feeling for which is better?",NA,NA,NA
24,26373246,cboettig,2013-10-15T21:19:21Z,2013-10-15T21:19:21Z,Cool.  Could you give me a line of code that takes species (or higher taxanomy) names and returns TSNs?  ,NA,NA,NA
24,26374811,sckott,2013-10-15T21:39:58Z,2013-10-15T21:58:00Z,"### Download the ITIS SQLite database from dropbox to your machine

https://www.dropbox.com/s/gz1vvsu2d0qps19/itis2_sqlite.zip

This DB is 4 months old I think. I had to use a script to convert to a sqlite db, but we could update once the itis site is back up. 

### Install from sql branch

```coffee
install_github('taxize_', 'ropensci', 'sql')
library(taxize)
```

### Set path to database

```coffee
taxize:::taxize_options(localpath = ""~/Downloads/itis2.sqlite"")
```
### You can pass in one or more names to srchkey to get TSNs back. 

setting returnindex=TRUE gives you back your original search terms so you can parse easily if needed. 

```coffee
searchbyscientificname(srchkey=c(""oryza sativa"",""Chironomus riparius"",""Helianthus annuus"",""Quercus lobata""), locally=TRUE, returnindex=TRUE)
```

```
           querystring    tsn                        combinedName
1  Chironomus riparius 129313                 Chironomus riparius
2    Helianthus annuus  36616                   Helianthus annuus
3    Helianthus annuus 525928      Helianthus annuus ssp. jaegeri
4    Helianthus annuus 525929 Helianthus annuus ssp. lenticularis
5    Helianthus annuus 525930      Helianthus annuus ssp. texanus
6    Helianthus annuus 536095 Helianthus annuus var. lenticularis
7    Helianthus annuus 536096  Helianthus annuus var. macrocarpus
8    Helianthus annuus 536097      Helianthus annuus var. texanus
9       Quercus lobata  19370                      Quercus lobata
10      Quercus lobata 195111       Quercus lobata var. argillara
11      Quercus lobata 195112       Quercus lobata var. insperata
12      Quercus lobata 195113       Quercus lobata var. turbinata
13      Quercus lobata 195114         Quercus lobata var. walteri
14        oryza sativa  41976                        Oryza sativa
15        oryza sativa 566528             Oryza sativa var. fatua
16        oryza sativa 797955         Oryza sativa ssp. rufipogon
17        oryza sativa 801263          Oryza sativa var. elongata
18        oryza sativa 801264      Oryza sativa var. grandiglumis
19        oryza sativa 801265         Oryza sativa var. latifolia
20        oryza sativa 801266     Oryza sativa var. paraguayensis
21        oryza sativa 801267     Oryza sativa var. paraguayensis
22        oryza sativa 801268       Oryza sativa var. rubribarbis
23        oryza sativa 801269         Oryza sativa var. rufipogon
24        oryza sativa 801270          Oryza sativa var. savannae
25        oryza sativa 801271         Oryza sativa var. sundensis
```

Note that under the cover, these functions are using SQL queries. So you can go in and modify those sql queries if needed.",NA,NA,NA
24,26374816,cboettig,2013-10-15T21:40:04Z,2013-10-15T21:40:04Z,"@SChamberlain looks like when treebase does this, it returns several numbers: a tb:identifier.taxon code number,  a tb.identifer.taxonVariant code number, a ubio match and a uniprot match:

```coffee
 <meta content=""11788"" datatype=""xsd:long"" id=""meta5204"" property=""tb:identifier.taxon"" xsi:type=""nex:LiteralMeta""/>
      <meta content=""28081"" datatype=""xsd:long"" id=""meta5203"" property=""tb:identifier.taxonVariant"" xsi:type=""nex:LiteralMeta""/>
      <meta href=""http://purl.uniprot.org/taxonomy/22658"" id=""meta5202"" rel=""skos:closeMatch"" xsi:type=""nex:ResourceMeta""/>
      <meta href=""http://www.ubio.org/authority/metadata.php?lsid=urn:lsid:ubio.org:namebank:2651545"" id=""meta5201"" rel=""skos:closeMatch"" xsi:type=""nex:ResourceMeta""/>
      <meta href=""http://purl.org/phylo/treebase/phylows/study/TB2:S100"" id=""meta5200"" rel=""rdfs:isDefinedBy"" xsi:type=""nex:ResourceMeta""/>
```

(the last meta element refers to the file itself that defines the OTU, which I guess I should add). 

@rvosa is tb:identifer.taxon the same as the TSN code?  The namespace http://purl.org/phylo/treebase/2.0/terms# isn't resolving for me.  

I suppose it could be useful to have all of these identifiers if we can get them from taxize?  I guess the thinking is that at machine that knew one of these identifier vocabularies but not the others could still successfully discover the species covered.  Not sure if that is important or not.  

For the use case of metadata search over a large collection of NeXML files, I am also not sure if it would be worth considering adding other taxonomic hierarchy to the metadata, e.g. facilitating a search for all trees covering order ""Passeriformes"" without having to look up the order for every OTU in a large collection first.  EML files tend to take this approach (giving the full classification).  On the other hand, it is redundant and introduces the potential for errors, and a truly fast search should probably index the classification in a database (the way metcat does in EML I think; I guess TreeBase serves much the same function) rather than have to parse every XML file to begin with.  

Wish I knew more about these issues. Perhaps @rvosa or @hlapp have thoughts on whether it is generally better to make explicit metadata that is already implicit (e.g. given one species id number we can presumably find another algorithmically) or better to minimalist in this?  


",NA,NA,NA
24,26375387,cboettig,2013-10-15T21:48:11Z,2013-10-15T21:48:11Z,@SChamberlain Sweet!,NA,NA,NA
24,26376524,sckott,2013-10-15T22:03:51Z,2013-10-15T22:03:51Z,"We may want to think about speed. With very large trees acquiring TSNs could be quite slow if we are calling the ITIS web API.  Their API is particularly slow as they only allow one call at a time (e.g. you can't pass in 5 names in one query).

NCBI has their own identifiers, and their API is faster.  

Additionally, my understanding is that ITIS coverage is great if you are in North America, but not so much otherwise.   ",NA,NA,NA
24,26382156,hlapp,2013-10-15T23:41:36Z,2013-10-15T23:41:36Z,"Personally I would advise against using the TreeBASE vocabulary. The vocabulary is just that - one used by TreeBASE, and not anyone else. Eventually, this would all be covered by the MIAPA ontology, which draws many of its classes and properties from CDAO. The recommendation for TNRS matches is likely also going to be a CDAO property.

Furthermore, there is a TNRS vocabulary and example instance documents here:
https://github.com/phylotastic/ontologies",NA,NA,NA
19,26383059,hlapp,2013-10-16T00:00:48Z,2013-10-16T00:00:48Z,Not clear to me what the concrete consequences for users would be. Can you explicate?,NA,NA,NA
19,26383488,cboettig,2013-10-16T00:10:09Z,2013-10-16T00:10:09Z,"With separate objects, users would have to decide to read in a NeXML file as nexml (and later convert it), or read it in directly as ""phylo"" and later read it in again to do anything with the metadata.  e.g.: 

```coffee
tree <- nexml_read(""file.xml"", type=""phylo"") # object of class ""phylo""
plot(tree)
```

or 

```coffee
nexml_tree <- nexml_read(""file.xml"", type=""nexml"") # object of class ""nexml""
tree <- as(nexml_tree, ""phylo"")
plot(tree)
```
while to perform metadata functions they have to operate on the `nexml` object instead:

```coffee
summary(nexml_tree) 
citation(nexml_tree)
license(nexml_tree)
```

(those methods not yet written btw).  


In Option 2, with a combined interface, the user would use the same object for all purposes:

```coffee
tree <- nexml_read(""file.xml"")  # object of class ""nexmlTree""
plot(tree)
metadata(tree)
summary(tree)
license(tree)
```

etc.  Clearly the interface is cleaner in the later context.  The cost is larger object memory size and a chance that poorly written phylogenetics functions (at least ones that check class using strings) fail.  




",NA,NA,NA
19,26383646,cboettig,2013-10-16T00:13:49Z,2013-10-16T00:13:49Z,"(Um, note that `plot(tree)` is the ape method `plot.phylo`, I'm just using it to illustrate any existing method.  Could be a richer function like `bd.ext`, any function from `gieger`, `OUwie`, `phytools` etc.    Meanwhile the other 'metadata' functions would be the unique functions provided in RNeXML to handle the metadata.  I'm not sure quite what or how many such functions we'll have, but see ideas in #20)",NA,NA,NA
23,26400413,rvosa,2013-10-16T08:24:26Z,2013-10-16T08:24:26Z,"This is very fine. Just FYI, both the RDF/XML ""community"" at large and the
(ab)users of NeXML have accepted that the object of a triple can sometimes
be an essentially opaque bit of literal XML. For example, in the phenoscape
project they use literal bits of XML to define certain character states. I
don't think this is the most beautiful approach in the world because it is
hard to see how a generic reasoner would be able to do something sensible
with opaque XML but it is being done like this ""in the wild"" so you don't
have to feel too concerned about not being fully solid on rdfa: even
simple, well-formed XML is allowed.


On Tue, Oct 15, 2013 at 9:29 PM, Carl Boettiger <notifications@github.com>wrote:

> (As usual, let me know if this implementation is problematic -- I'm still
> not very solid on rdfa)
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/23#issuecomment-26364743>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
24,26400901,rvosa,2013-10-16T08:33:48Z,2013-10-16T08:33:48Z,"On Tue, Oct 15, 2013 at 11:40 PM, Carl Boettiger
<notifications@github.com>wrote:

> @SChamberlain <https://github.com/SChamberlain> looks like when treebase
> does this, it returns several numbers: a tb:identifier.taxon code number, a
> tb.identifer.taxonVariant code number, a ubio match and a uniprot match:
>

These things respectively mean the following:

* tb:identifier.taxon is the local primary key for that taxon inside
TreeBASE

* tb:identifier.taxonVariant is the local primary key for the ""taxon
variant"" inside TreeBASE (this could be, say, an alternate spelling that
maps to identifier.taxon in the database)

* When TreeBASE is given a new taxon label in an uploaded file, it queries
uBio for that label, so if you were to search uBio for the value of the
@label attribute of that element, the result in RDF form would be this URI.

* At time of implementation, the NCBI taxonomy only had ugly URIs (this has
now changed, NCBI now has pretty URIs such as
http://ncbi.nlm.nih.gov/taxonomy/9606) but it still has no RDF response.
UniProt does, so this URI is in lieu of an RDF response from NCBI.

I second Hilmar's suggestion not to use the treebase vocabulary. Sorry that
the URI doesn't resolve - perhaps it should at least point to this
spreadsheet: https://spreadsheets.google.com/pub?key=rL--O7pyhR8FcnnG5-ofAlw

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
24,26437334,cboettig,2013-10-16T17:02:07Z,2013-10-16T17:02:07Z,"@SChamberlain Good points about speed, etc. Um, also, looks like the example above is for species names (scientific names) only?  Or will it match higher orders?  What command would I use that would query both arbitrary taxonomic level and provide fuzzy matching (along with a confidence score, since we can include that in the metadata presumably, though I don't know what the RDFa property would be for that...)  

Can I get uniprot, ubio, and NCBI identifiers?  If NCBI is faster, perhaps we can just use that.  

@rvosa Thanks for the clarifications.  Presumably we can just construct the RDFa given the identifier even if the APIs are not returning RDF responses?  

@rvosa does it make more sense to provide the identifier in a ReferenceMeta or LiteralMeta (e.g. as full link or just identifier number?)  Or maybe just provide both?  

@all I'm guessing there is no definite answer on the explicit vs implicit metadata question. While we can certainly give the user control over what identifiers they want to include and not include as OTU metadata, I think we also want a sensible default that adds, say, one identifier automatically for users who are not familiar with the whole identifier concept to begin with.  maybe NCBI is the one to go with?  ",NA,NA,NA
20,26457772,cboettig,2013-10-16T21:00:58Z,2013-10-16T21:00:58Z,"Some methods are now provided to extract metadata. All could be improved, as I comment below.  


- [ ] `summary` currently just uses the `phylo` summary method.  Should print some basic metadata when available as well (author, title, date, license perhaps).  


- [ ] `get_metadata`: returns a named list of all top-level meta elements ""content"" or ""href"", named with their associated ""property"" or ""rel"", respectively.  Maybe a cleaner way to do this, but in does provide a consise way to access specific elements later, e.g. 

```coffee
nex <- nexml_read(""nexml.xml"")
meta <- get_metadata(nex)
meta[""dc:title""]
```
We might need to think about how we handle namespaces though. Considering providing explicit functions for the most common metadata.  

- [ ] `get_license` Just extracts any dc:rights or  license node.  Too slow since we do this by writing to XML and using XPath, rather than searching the S4 structure.  On the flip side, xpath search is more explicit and flexible -- e.g. it has an understanding of XML namespaces that we don't have as explicitly in S4.  Unclear if we really should be providing such functions for a single, arbitrary metadata line, but perhaps for the most common ones (that we write automatically, like creator, title, license, date).....  

- [ ] `get_citation` extracts any `dcterms:bibliographicCitation` node, (which is generated by the 'citation' option to `nexml_write` given an R bibentry class object. Also generates the various elements of the citation using dc:terms.  Should probably be changed to return a R bibentry object rather than just this text. 


Also thinking about naming these functions without the `get_` prefix, but need to deal with namespace collisions then...

- [ ] Perhaps metadata methods should be extended to work on the ""nexml.xml"" file directly without a call to nexml_read first?




",NA,NA,NA
19,26459110,cboettig,2013-10-16T21:13:21Z,2013-10-16T21:13:21Z,"Okay, I think we can just support both and let the user decide. The metadata methods (now implemented, see https://github.com/ropensci/RNeXML/issues/20#issuecomment-26457772 and commit 94996e684a2a6dd8dc8ac25d3eb7ac0d2c423d47 ) are written for the ""nexml"" class and inherited by the ""nexmlTree"" class.  By default, I support the second method; e.g. `tree <- nexml_read(""file.xml"")`  will read in an object of class ""nexmlTree"" that acts like a phylo object has all the metadata attached, with associated methods.  Users who would prefer a pure `phylo` object can coerce this or read it in as such, as shown above.  

Not sure if users will have any use for the raw `nexml` class, since the `nexmlTree` class has the added benefit of working in `phylo` methods.  Still, it is available as an object for any user or developer just needing an R S4 representation of a nexml document. 

I think this resolves this question. Re-open with outstanding issues, or feel free to add further questions or comments.  ",NA,NA,NA
24,26488234,rvosa,2013-10-17T08:53:43Z,2013-10-17T08:53:43Z,"I agree that it's not disastrous if the response on the other end of a URI
isn't RDF, though from a linked data POV it would be nicer. And I think it
is definitely better to use a URI instead of a local primary key in a DB.

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
20,26488514,rvosa,2013-10-17T08:58:38Z,2013-10-17T08:58:38Z,"This looks really great, though the namespaces thing would need some work:

nex <- nexml_read(""nexml.xml"")

meta <- get_metadata(nex)

meta[""dc:title""]




-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
24,26538383,cboettig,2013-10-17T18:53:42Z,2013-10-17T18:53:42Z,"Okay, I've added the method `addIdentifiers` which will add identifier meta annotations to the OTUs of a `nexml` object.  This method will be called by default with the NCBI identifiers by the `nexml_write` (can be turned off by giving an empty argument).  

@rvosa @hlapp Um, I couldn't figure out what `rel` to assign to these things (I have the dummy value ""ncbi:id"" at the moment).    What would you suggest?  

Currently we get something that looks like:

```xml
<otus id=""tax1"">
    <otu label=""Struthioniformes"" id=""t1"">
      <meta xsi:type=""ResourceMeta"" href=""http://ncbi.nlm.nih.gov/taxonomy/8798"" rel=""ncbi:id""/>
    </otu>
    ...
```

What other `meta` elements might we want to add here by default? For instance, would it be worth adding annotations stating that `Struthioniformes` is an order? (e.g. Darwin core?).  My thinking is on one hand it would be nice to showcase the metadata we can add (e.g. in the manuscript) to provide useful additional data at no additional effort, but on the other hand this should clearly be use-motivated and not just gratuitous annotation.  (The challenge perhaps being mostly in forseeing the use.  For instance, many parsers might not be as smart as they could be, and therefore benefit from more being made explicit that was already implicit).  Advice on this issue much appreciated.  



I see that TreeBase trees include a `meta` element connecting this `otu` to its nexml file, e.g.

```xml
<meta href=""http://purl.org/phylo/treebase/phylows/study/TB2:S100"" id=""meta5200"" rel=""rdfs:isDefinedBy"" xsi:type=""nex:ResourceMeta""/>
```
Should we be doing similarly?  In general our nexml files won't have a URI.  Also, I think I understand the logic of this being related to the ability to reference this otu from another file, but can't we do that without explicitly including such a meta element?  I mean, a machine parsing the whole nexml file could obviously generate this line by itself, so I guess it is to allow the otu element to stand alone.  But doesn't that become kind of a recursive problem?  (e.g. what's the criteria by which a nexml element would need such a line?) 




",NA,NA,NA
24,26551613,cboettig,2013-10-17T20:49:54Z,2014-03-22T15:28:07Z,"I see... so presumably we could be providing RDFa such as @hlapp illustrates in the [TNRS repo](https://github.com/phylotastic/ontologies/blob/master/tnrs/tnrs-instance-1otu.ttl) annotating each `<otu>`

Looks like @hlapp has a handy image showing how much information that crams in: 

![](https://raw.github.com/phylotastic/ontologies/master/tnrs/tnrs-instance-1otu.png)

wow.  Do we want to include all these triples as annotations to each otu?  

@sckott I think taxize can provide all the data shown there, though we'd have to generate the meta tagas manually?  

@all for my single NCBI tag, `<meta xsi:type=""ResourceMeta"" href=""http://ncbi.nlm.nih.gov/taxonomy/8798"" rel=""ncbi:id""/>` I added `ncbi:http://ncbi.nlm.nih.gov/taxonomy` to the namespaces so that the XML validates.  The `rel` attribute becomes rather redundant to the `href` attribute this way, but I guess that is okay?  (I see the same namespace is used in the tnrs example above...)
",NA,NA,NA
26,26551729,hlapp,2013-10-17T20:51:15Z,2013-10-17T20:51:15Z,"@cboettig a piece of input that ontologies and vocabularies greatly depend on to be (or become) useful is use-cases - for what kinds of things are terms needed but don't seem to readily exist already. This project would be in a great position to provide such input, and I wouldn't expect that process to be one-off but iterative. So if you can document (on a wiki page?) on an on-going basis which terms you feel you need but can't readily locate, that'd be highly useful.

I would expect the great majority of these to fall under the MIAPA ontology:
https://github.com/miapa/miapa/

The ontology is published on the web under a resolving canonical URI:
http://purl.obolibrary.org/obo/miapa.owl

By definition, as an application ontology MIAPA imports (reuses) terms from CDAO, EDAM, SWO, and other ontologies as needed to cover a domain of application, namely annotation of a phylogenetic analysis result (as opposed to a domain knowledge, such as comparative data analysis for CDAO).

The TNRS ontology is published on the web under a resolving canonical URI:
http://phylotastic.org/terms/tnrs.rdf

Is this making sense?",NA,NA,NA
24,26553206,hlapp,2013-10-17T21:09:05Z,2013-10-18T00:12:52Z,"Re: do you really want all these triples for each OTU: only if you want to preserve full provenance of how the taxon ID assignment was made. So applying taxize to a NeXML object should probably result in that (at least optionally), because presumably taxize at some point has all the information in its hands to fill out those metadata, and the alternative is to throw it all away (not so good for reproducibility in the sense of ability to track provenance of all data).

Generally speaking, good functions, and thus good programs don't have side effects. I.e., if I give an input object with all the above metadata to a method that doesn't do anything with taxon ID assignments, the corresponding metadata should reappear in the output unharmed.

That said, if the use-case justifies it, you can also stick a taxon ID directly on an OTU. The MIAPA ontology makes the following recommendation for that:

```XML
<!-- http://rs.tdwg.org/ontology/voc/TaxonConcept#toTaxon -->
<owl:ObjectProperty rdf:about=""http://rs.tdwg.org/ontology/voc/TaxonConcept#toTaxon"">
    <rdfs:comment>For MIAPA reporting, recommended as the property relating an OTU to a taxonomic concept (an entry in a taxonomy, such as an NCBI taxonomy reference) that has been obtained through taxonomic name or other kinds of name resolution or reconciliation procedures.</rdfs:comment>
</owl:ObjectProperty>
```",NA,NA,NA
26,26553711,cboettig,2013-10-17T21:15:48Z,2013-10-21T23:24:47Z,"@hlapp I think I'm getting it.  So it sounds like MIAPA can largely be my interface into the other ontologies. I agree 100% on use cases.  I hope to develop a few illustrative use cases as part of the vignette/manuscript for this repository (inst/doc/manuscript.Rmd).  Maintaining an ongoing collection of these in package examples (inst/examples) or the repository's wiki sounds like a splendid idea.  

Some exposition on my current wish-list: 

Many of the phylogenetic methods in R that I am familiar with require ultrametric trees.  Some of these are time-calibrated using fossils, others just using heuristic methods. It would be most valuable to annotate that a tree has been time-calibrated and what the units (and possible uncertainty, which may be a branch-level annotation) are on the branch lengths.  It would also be useful to annotate the method in which a tree has been time-calibrated, as well as the method with which it has been generated.  (Imagine a user wants to select from a library of nexml files only those trees produced by MrBayes, or exclude trees generated by phylomatic, or access only truly time calibrated trees).  In some cases the mechanism of the calibration might be documented -- e.g. if tree was made ultrametric with the R function 'chronopl', and what parameter value was used for that calibration).  

I haven't been able to stumble across the ontological vocabulary for any of this, e.g. one might hope to express this as:

```xml
<meta property=""phylogeny-from"" content=""MrBayes"" datatype = ""xsd:string"" xsi:type=""LiteralMeta"">
<meta href=""path/to/Script/for/MrBayes/run"" rel=""script"" xsi:type=""ResourceMeta"">
<meta property=""ultrametric"" content=""true"" datatype = ""xsd:boolean"" xsi:type=""LiteralMeta"">
<meta property=""calibration-method"" content=""ape::chronopl"" datatype = ""xsd:string"" xsi:type=""LiteralMeta"">    
<meta property=""calibration-method-parameter"" content=""lambda"" datatype = ""xsd:string"" xsi:type=""LiteralMeta"">
<meta property=""calibration-method-parameter-value"" content=""1.2"" datatype = ""xsd:long"" xsi:type=""LiteralMeta"">

```
etc etc.  Clearly these triples could be much more logically constructed ; but I'm not trying to propose an onotology, just looking for existing terms.  Just haven't found them.  


I'm not familiar with any handy tool to visualize owl ontologies, but searching the MIAPA ontology.

",NA,NA,NA
24,26555494,cboettig,2013-10-17T21:39:42Z,2013-10-17T21:39:42Z,"Thanks for this, I certainly see your point about documenting the provenance of how we come up with ids if we are going to go and add them programmatically.  

The use-cases motivating me to add ids in the first place (others may have other use cases) is primarily: 

1. Provide a check on the labels themselves.  We provide a warning if we cannot find an id and suggest the user double-check the spelling and use of the names they have provided.  (clearly this does not need to involve actually writing the id to the data file if it just an error check).  

other reasons:

2. Provide an identifier for users of the tree.  This signals that the otu labels are reliable (e.g. free from spelling errors) and provides an alternate way to identify the otus involved.  By making id data more readily available, users of the tree might be more likely to make use of this information (e.g. in matching against species names in other work) than if they have to look up these id numbers for themselves from the labels.  

I suppose there is no reason not to include the full provenance, (other than memory perhaps, since R holds the nexml file in working memory at least in the way we do things currently), though it is probably less likely to be of immediate use to the end-user.  


If I understand your suggestion about how to add a taxon ID directly to an OTU, you suggest the `rel` tag should be ""http://rs.tdwg.org/ontology/voc/TaxonConcept#toTaxon"", correct? Is there anything other than the `href` itself that would indicate that this is an NCBI id number, (and perhaps further, that this id number is an 'identifer', a la things that EDAM calls identifiers?)  



For encoding this into the NeXML, I suppose we can either render this as nested `meta` elements or just stick and RDF version of something like this:  https://github.com/phylotastic/ontologies/blob/master/tnrs/tnrs-instance-1otu.ttl as a child node to a single meta element (if I understand #23 correctly).  Perhaps the former is better, I don't know.  ",NA,NA,NA
24,26557456,sckott,2013-10-17T22:10:30Z,2013-10-17T22:10:30Z,"@cboettig 

> I think taxize can provide all the data shown there, though we'd have to generate the meta tagas manually?

Yes, most of it I think. We do have functions interacting with TNRS, NCBI, and Tropicos. Are there other sources we need to pull from?",NA,NA,NA
24,26557463,hlapp,2013-10-17T22:10:39Z,2013-10-17T22:10:39Z,"
On Oct 17, 2013, at 5:39 PM, Carl Boettiger wrote:
> If I understand your suggestion about how to add a taxon ID directly to an OTU, you suggest therel tag should be ""http://rs.tdwg.org/ontology/voc/TaxonConcept#toTaxon"", correct?
> 
Yes.
> Is there anything other than the href itself that would indicate that this is an NCBI id number
> 
No. But something like ncbi:id isn't really different in that respect - there is no computable semantics within ""ncbi:"" or ""id"" that would somehow tell a machine that this is pointing to an NCBI id number. You'd have to hard-code that semantics into your program, which is really the same as looking at the base of the object URI and determining that it belongs to NCBI's domain.

(Note that with the full provenance you wouldn't have to do even that - you could look at the source TNRS to see where it came from.)

That said, if it tuns out as an important use-case to have separate properties for each possible taxon ID source, we can create subproperties. Note, however, that a proliferation of properties really only takes us back to the days of byzantine and idiosyncratic relational schemas where nobody could just agree on how much to normalize things that conceptually are really n-n relationships. The consequence of that is that applications need to understand a bazillion different properties, when instead we could have just inspected the object if we truly needed to know what flavor of a thing it is.
> , (and perhaps further, that this id number is an 'identifer', a la things that EDAM calls identifiers?)
> 

The object value in this case has to be a URI, because it's an entity, not a literal. The object may resolve to RDF, or it may not; in the latter case (or to save a common network roundtrip) we may choose to say more things about it (such as what label it has) directly in the metadata. ",NA,NA,NA
26,26558213,hlapp,2013-10-17T22:22:19Z,2013-10-17T22:23:20Z,"We worked on provenance annotation a lot during the Phylotastic II hackathon. One example in graphical depiction is here: http://www.evoio.org/wiki/File:PetersGraphic.jpg

![petersgraphic](https://f.cloud.github.com/assets/51458/1356584/b1d7c060-377a-11e3-9900-646136ef5cd4.jpg)

The corresponding OWL file is here: https://github.com/miapa/miapa/blob/master/examples/peters_miapa-annotation.owl

One way to navigate OWL files is to use on OWL ontology editor, for example Protege.

For indicating an ultrametric tree, if an ultrametric tree is a subtype of tree, it would be a class in CDAO, and the tree instance in NeXML would instantiate it (rdfs:type).",NA,NA,NA
24,26611912,cboettig,2013-10-18T16:57:46Z,2013-10-18T16:57:46Z,"@hlapp Thanks.  It's a treat to be able to draw on your expertise as  I try to wrap my head around semantics better.  

### conceptual

 Yeah, I realize `ncbi:id` wasn't accomplishing anything, I just didn't know any valid term that did have ontological meaning; sounds like `rel=""tc:toTaxon""` serves this purpose adequately. 

If I understand correctly, ideally the associated `href` would point to an RDF resource rather than HTML.  I think you're saying that we can make up for this somewhat by adding child LiteralMeta elements that provide more information instead?  I'm not quite sure what these would be, perhaps you could provide some example?  

I think you're also saying that having a bunch of subproperties is not ideal, since it is unlikely an application understands all of them?  


### practical

Okay, understanding things better but I'm still on the fence as to how we should annotate OTUs to best achieve the 3 use case objectives I mentioned above.  (Open to learning about other use cases too).  _Which of the 3 options below would you recommend we pursue at this stage?_

#### Option 1 

simply gives a link to the NCBI taxon definition using the property (rel) `tc:toTaxon`:

```xml
<otus id=""tax1"">
    <otu label=""Struthioniformes"" id=""t1"">
      <meta xsi:type=""ResourceMeta"" href=""http://ncbi.nlm.nih.gov/taxonomy/8798"" rel=""tc:toTaxon""/>
    </otu>
```

I think this is somewhat analgous to the level of annotation TreeBase provides.  

#### Option 2 

is to add some further annotation to option 1 (not sure what exactly), but not the full provenance. 

#### Option 3

 is to include the full provenance.  Not quite sure how that would be expressed.  

Below, using the example from the TNRS repo I've converted the turtle to RDFa with meta elements, but these aren't valid nex:meta elements since they use `about` and `typeof`.  Perhaps this would be better to simply use RDF as the child node, though RDFa extraction tools would then miss it...  

While I appreciate the value of having the provenance rather than just displaying the NCBI link in option 1 (with no record to understand where it came from it is arguably worse than just having the taxon `label` attribute in the `<otu` element), the provenance looks pretty verbose.  Are other NeXML serializers adding OTU annotations in this way?  

```xml
<otus id=""tax1"">
    <otu label=""Struthioniformes"" id=""t1"">
      <meta xmlns:rdf=""http://www.w3.org/1999/02/22-rdf-syntax-ns#""
     xmlns:rdfs=""http://www.w3.org/2000/01/rdf-schema#""
     xmlns=""http://www.w3.org/1999/xhtml""
     xmlns:obo=""http://purl.obolibrary.org/obo/""
     xmlns:tc=""http://rs.tdwg.org/ontology/voc/TaxonConcept#""
     xmlns:dc=""http://purl.org/dc/elements/1.1/""
     xmlns:dcterms=""http://purl.org/dc/terms/""
     xmlns:tnrs=""http://phylotastic.org/terms/tnrs.rdf#""
     xmlns:xsd=""http://www.w3.org/2001/XMLSchema#""
     class=""rdf2rdfa"">
   <meta class=""description"" about=""http://phylotastic.org/terms/tnrs-instance.rdf#otu5""
        typeof=""obo:CDAO_0000138"">
      <meta property=""rdfs:label"" content=""Panthera tigris HQ263408""/>
      <meta rel=""tnrs:resolvesAs"">
         <meta class=""description"" typeof=""tnrs:NameResolution"">
            <meta property=""tnrs:matchCount"" content=""2""/>
            <meta rel=""tnrs:matches"">
               <meta class=""description"" typeof=""tnrs:Match"">
                  <meta property=""tnrs:acceptedName"" content=""Panthera tigris""/>
                  <meta property=""tnrs:matchedName"" content=""Panthera tigris""/>
                  <meta property=""tnrs:score"" content=""1.0""/>
                  <meta rel=""tc:toTaxon"" resource=""http://www.ncbi.nlm.nih.gov/taxonomy/9694""/>
                  <meta rel=""tnrs:usedSource"">
                     <meta class=""description"" about=""http://www.ncbi.nlm.nih.gov/taxonomy""
                          typeof=""tnrs:ResolutionSource"">
                        <meta property=""dc:description"" content=""NCBI Taxonomy""/>
                        <meta property=""tnrs:hasRank"" content=""3""/>
                        <meta property=""tnrs:sourceStatus"" content=""200: OK""/>
                        <meta property=""dc:title"" content=""NCBI""/>
                     </meta>
                  </meta>
               </meta>
            </meta>
            <meta rel=""tnrs:matches"">
               <meta class=""description"" typeof=""tnrs:Match"">
                  <meta property=""tnrs:acceptedName"" content=""Megalachne""/>
                  <meta property=""tnrs:matchedName"" content=""Pantathera""/>
                  <meta property=""tnrs:score"" content=""0.47790686999749""/>
                  <meta rel=""tc:toTaxon"" resource=""http://www.tropicos.org/Name/40015658""/>
                  <meta rel=""tnrs:usedSource"">
                     <meta class=""description"" about=""http://tnrs.iplantcollaborative.org/""
                          typeof=""tnrs:ResolutionSource"">
                        <meta property=""dc:description""
                             content=""The iPlant Collaborative TNRS provides parsing and fuzzy matching for plant taxa.""/>
                        <meta property=""tnrs:hasRank"" content=""2""/>
                        <meta property=""tnrs:sourceStatus"" content=""200: OK""/>
                        <meta property=""dc:title"" content=""iPlant Collaborative TNRS v3.0""/>
                     </meta>
                  </meta>
               </meta>
            </meta>
            <meta rel=""dcterms:source"">
               <meta class=""description""
                    about=""http://phylotastic.org/terms/tnrs-instance.rdf#request""
                    typeof=""tnrs:ResolutionRequest"">
                  <meta property=""tnrs:submitDate"" content=""Mon Jun 11 20:25:16 2012""/>
                  <meta rel=""tnrs:usedSource"" resource=""http://tnrs.iplantcollaborative.org/""/>
                  <meta rel=""tnrs:usedSource"" resource=""http://www.ncbi.nlm.nih.gov/taxonomy""/>
               </meta>
            </meta>
            <meta property=""tnrs:submittedName"" content=""Panthera tigris""/>
         </meta>
      </meta>
   </meta>
</meta>
</otu>
```",NA,NA,NA
27,26887695,rvosa,2013-10-23T08:20:16Z,2013-10-23T08:20:16Z,"So the interface is necessarily that phylo/multiPhylo is returned, or could
it, for consistency's sake, be a vector with zero or more multiPhylo's,
always?


On Wed, Oct 23, 2013 at 2:18 AM, Carl Boettiger <notifications@github.com>wrote:

> nexml can contain a single <tree> node inside the <trees> node, multiple
> <tree> nodes in a single <trees> node, or even multiple <trees> nodes.
> The first two cases map naturally onto a ""phylo"" object and a ""multiPhylo""
> object, defined as classes in ape. In order to preserve the associations,
> we map the third case (multiple <trees> nodes) to a list of multiPhylo
> objects, which isn't something immediately reconizable as a phylogenetic
> tree class....
>
> Consequently, we make this mapping automatically when asked to coerce a
> nexml file into a phylo, even though this means technically not returning
> the requested class (ask for phylo and get multiPhylo). We should
> probably handle that differently.
>
> For instance, this current creates a problem when coercing a nexml file
> with multiple <trees> nodes into a nexmlTree class (because this includes
> a conversion to phylo. Because nexmlTree is the defaul read-in format
> now, this can cause reading in of such nexml files to fail.
>
> Obviously it would be nice for a user to convert nexml to the ape classes
> without having to know how many trees are in the nexml file. Need to figure
> out the best way to do this.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/27>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
27,26924917,cboettig,2013-10-23T17:24:33Z,2013-10-23T17:24:33Z,"@rvosa Right, we could always return a list vector with one or more `multiPhylo`s, but this makes the interface quite cumbersome.  Instead of being able to do things like:

```coffee
tree <- read.nexml(""S100.xml"")
plot(tree)
bd.time(tree, 0,1)
```
You would have to explicitly subset twice (once to escape the list of trees, and again to get the `phylo` from the `multiPhylo`:

```coffee
tree <- read.nexml(""S100.xml"")
plot(tree[[1]][[1]])
bd.time(tree[[1]][[1]], 0,1)
```

which will definitely trip up a user who knows that there is only one tree in the nexml.  Partly this is a problem with `ape`, since `multiPhylo` doesn't inherit the methods of `phylo`, making the second set of `[[` necessary (and making it is a relatively useless class).  Adding the extra layer of a list of multiphylos makes the problem worse.  

I don't like having functions whose return type changes based on internals of the data input, e.g. currently `read.nexml(""S100.xml"", ""phylo"")` might return a `list`, a `multiPhylo`, or a `phylo` object depending the how the nexml is structured, which is clearly bad programming.  

Not sure what the right solution is here.  

In contrast to `ape`, the R base class for bibliographic entries, `bibentry`, can be either a single entry or a list of multiple `bibentry` objects, such that the associated methods work in the same way whether the object has one or multiple entries:

```coffee
a = citation(""ouch"") # contains citations to 2 papers
format(a, ""text"")      # formats both 
format(a[[1]], ""text"") # same call formats just one
```

",NA,NA,NA
15,27020717,cboettig,2013-10-24T19:05:43Z,2013-10-25T04:40:40Z,"Okay, tested parsing and conversion on all 3586 NeXML files provided in the [supertreebase](https://github.com/rvosa/supertreebase/tree/master/data/treebase) repo.  

Results:

```coffee
conversion failed:       read failed:            success 
                65                  2               3519 
```

Not too bad, as we are parsing 98% successfully, which I believe is higher than the success rate in parsing the `nexus` files provided by treebase into R (should recompute those numbers).  Still, I think there is no good reason why we should be failing on any of these files, so this needs investigation. 

 Need to understand what happened in the failing cases.  (The 3586 count excludes the nexml files that won't parse `xmlParse`, mostly because they are empty files).  The 2 read fails therefore parse, but still trigger `read.nexml` to fail:

```coffee
> read_failed
[1] ""S12760.xml"" ""S13111.xml""
```

- [x] Need to investigate what is going wrong here (and then add this situation as a unit test case).  

More problematic are the conversions to ape, where 

```coffee
> conversion_failed
 [1] ""S10327.xml"" ""S10334.xml"" ""S10366.xml"" ""S10436.xml"" ""S10464.xml""
 [6] ""S104.xml""   ""S10548.xml"" ""S10562.xml"" ""S10589.xml"" ""S10644.xml""
[11] ""S10648.xml"" ""S10679.xml"" ""S10689.xml"" ""S10772.xml"" ""S10810.xml""
[16] ""S10968.xml"" ""S10995.xml"" ""S11021.xml"" ""S11155.xml"" ""S11178.xml""
[21] ""S11267.xml"" ""S11459.xml"" ""S11618.xml"" ""S11647.xml"" ""S11786.xml""
[26] ""S11911.xml"" ""S12022.xml"" ""S12093.xml"" ""S12101.xml"" ""S12147.xml""
[31] ""S12173.xml"" ""S12233.xml"" ""S12300.xml"" ""S12336.xml"" ""S12410.xml""
[36] ""S12523.xml"" ""S12536.xml"" ""S12630.xml"" ""S12773.xml"" ""S12786.xml""
[41] ""S12880.xml"" ""S13140.xml"" ""S13461.xml"" ""S13664.xml"" ""S13805.xml""
[46] ""S2087.xml""  ""S235.xml""   ""S236.xml""   ""S237.xml""   ""S239.xml""  
[51] ""S240.xml""   ""S241.xml""   ""S242.xml""   ""S243.xml""   ""S244.xml""  
[56] ""S245.xml""   ""S246.xml""   ""S247.xml""   ""S248.xml""   ""S249.xml""  
[61] ""S250.xml""   ""S251.xml""   ""S252.xml""   ""S382.xml""   ""S696.xml"" 
```

- [ ] Need to figure out what's going on here


While 3586 is a decent sample size, all these nexml files were created by the same serializer, so they aren't quite independent samples.  @hlapp @rvosa Is there any other large collection of nexml files, or other popular serializer of nexml that we should be including as a test case? 


Further, this test is not particularly deep, as it checks only that conversions run without error.  Should obviously include more validation.  @SChamberlain updates to the [test script](https://github.com/ropensci/RNeXML/blob/master/inst/tests/treebase_test.R) are welcome -- test isn't run by `test_that` at the moment since it needs the whole 2.5 Gigs of supertreebase data that obviously aren't in the R package, see comments at top of file.  ",NA,NA,NA
15,27049289,sckott,2013-10-25T01:31:49Z,2013-10-25T01:31:49Z,"Good news on mostly successful parsing!  Makes sense to do the test script the way you did it.  

I'll poke around and see if I an find another set of nexml files, though @hlapp and @rvosa probably have some ideas",NA,NA,NA
15,27050921,hlapp,2013-10-25T02:03:48Z,2013-10-25T02:03:48Z,"
On Oct 24, 2013, at 9:31 PM, Scott Chamberlain wrote:

> I'll poke around and see if I an find another set of nexml files, though @hlapp and @rvosaprobably have some ideas
> 
I'm not aware of any other sources.",NA,NA,NA
15,27051091,sckott,2013-10-25T02:07:18Z,2013-10-25T02:07:18Z,"Okay, maybe we can create some ourselves @cboettig ?",NA,NA,NA
28,27061680,cboettig,2013-10-25T04:40:10Z,2013-10-25T04:40:10Z,"ape considers a tree to be rooted if it has an edge defined as the root (actually if it has anything in phy$root.edge), or as long as the node numbered 1 higher then the tip nodes (integers 1 to n are given to tip nodes in the ape definition) is not the source for strictly more than 2 other nodes.  Seems like a strange definition to me, anyone have an intuitive explanation?  

NeXML has the optional node attribute `root`.  So it is not clear to me (a) what we should do when an `ape::phylo` has a `root.edge` defined, or when we should write this attribute.  Currently this attribute is ignored when converting to/from `ape::phylo` (though accessible in the S4 nexml R object).  @hlapp @rvosa @SChamberlain Any advice for how to better handle these seemingly different notions?  


My current testing show that trees considered rooted by `ape` are still rooted when converted to nexml (S4 representation) and back, or serialized to output nexml file and read back in:

```coffee
library(RNeXML)
is.rooted(bird.orders) # TRUE
is.rooted(as(as(bird.orders, ""nexml""), ""phylo"")) # TRUE
write.nexml(bird.orders, ""tmp.xml"")
is.rooted(read.nexml(""tmp.xml"", ""phylo"")) # TRUE
```
so at least that is not an issue.  Suppose I should replicate this test with an unrooted (in the ape::phylo sense) tree.  

",NA,NA,NA
15,27062696,cboettig,2013-10-25T04:54:04Z,2013-10-25T04:54:04Z,"@SChamberlain yeah.  Not crucial perhaps but it would be good to get some sample NeXML files from each of the major tools that write NeXML (e.g. python, perl, ruby libs, though maybe @rvosa has a couple such nexml files lying around already).  Actually I think there were a few from various sources in the Kseniia's inst/examples directory that I removed, https://github.com/shumelchyk/RNeXML/tree/0b6788e6b3f554d0f0598ca6a6499b3dcdb67859/tests/examples may as well check those.  

Given that NeXML can be validated against its schema it probably doesn't matter so much what tool makes the NeXML.  We know/check that we're writing valid nexml from R, and can assume/check that the input nexml files are valid, so the only weak link is in converting the nexml to ape, etc, as I discovered in the bug in #29.  

",NA,NA,NA
28,27099283,sckott,2013-10-25T15:00:05Z,2013-10-25T15:00:05Z,"This seems to work correctly:

```coffee
data(bird.orders)
phy <- unroot(bird.orders)
is.rooted(phy) # FALSE
is.rooted(as(as(phy, ""nexml""), ""phylo"")) # FALSE
write.nexml(phy, ""tmp.xml"")
is.rooted(read.nexml(""tmp.xml"", ""phylo"")) # FALSE
plot(read.nexml(""tmp.xml"", ""phylo"")) # not rooted
```",NA,NA,NA
28,27102238,cboettig,2013-10-25T15:35:38Z,2013-10-25T15:35:38Z,"Nice. Can you paste this in as an additional unit test in test_ape.R?

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Oct 25, 2013 8:00 AM, ""Scott Chamberlain"" <notifications@github.com>
wrote:

> This seems to work correctly:
>
> data(bird.orders)phy <- unroot(bird.orders)is.rooted(phy) # FALSEis.rooted(as(as(phy, ""nexml""), ""phylo"")) # FALSEwrite.nexml(phy, ""tmp.xml"")is.rooted(read.nexml(""tmp.xml"", ""phylo"")) # FALSEplot(read.nexml(""tmp.xml"", ""phylo"")) # not rooted
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/28#issuecomment-27099283>
> .
>",NA,NA,NA
28,27102287,sckott,2013-10-25T15:36:08Z,2013-10-25T15:36:08Z,Sure thing,NA,NA,NA
15,27131653,cboettig,2013-10-25T22:48:23Z,2013-10-25T22:48:23Z,"Fixing #29 reduced us from 65 conversion failures to 32. 


- S10366.xml contains a single `<tree>` element which has only `meta` element children - no nodes or edges.  Guess we should throw an explicit error in this case, and suggest converting to / reading in as nexml instead of `nexmlTree` or `phylo` to access metadata?  

- S10436.xml contains several `<tree>` elements, one of which has only `meta` elements.  In this case, we should be able to skip this tree in conversion to `phylo` and parse the remaining trees into a multiPhylo list.  
",NA,NA,NA
27,27132118,cboettig,2013-10-25T22:59:21Z,2013-10-25T22:59:21Z,"Ah, so part of the problem is in order to get our `nexmlTree` class to act like the S3 phylo class, we explicitly define it as a `phylo`, not a `multiPhylo`.   This is kinda a fundamental problem introduced by trying to have an object behave both as a phylo, representing at most 1 tree, and a nexml object, representing 0 or more trees.  Might have to rethink this class a bit...

",NA,NA,NA
15,28330144,rvosa,2013-11-12T20:29:09Z,2013-11-12T20:29:09Z,"Sorry to be late to the party, but aren't there files created by phenex that could be used for testing? Maybe @hlapp or @balhoff know?",NA,NA,NA
30,28330307,rvosa,2013-11-12T20:31:15Z,2013-11-12T20:31:15Z,"So why actually is it ""wrong"" for a tree element to not have nodes or edges, but to have metadata? I think the schema allows that, and I don't see anything ontologically wrong with it. It just means we know things *about* the tree, but not its topology.",NA,NA,NA
27,28331782,rvosa,2013-11-12T20:49:09Z,2013-11-12T20:49:09Z,"I don't know if this is helpful or not, but when I was ""designing"" Bio::Phylo I made it do what I thought was the obvious thing based on the input data. E.g. if an input file is newick format, return a tree block. If phylip, a matrix. And so on. 

It turned out that this was a terrible idea, especially because Bio::Phylo's reading interface accepts a fairly wide variety of data formats that can have various permutations of zero or more trees and tree blocks, character matrices and/or taxa. 

So later on I added two features: 1) a ""project"" object that is a container for all the contents in a file, so I always get the same container back provided I pass in an extra argument that asks for this; 2) special 'parse_matrix' and 'parse_tree' functions that explicitly return the one matrix or tree that is expected to be contained in the input file. 

It turns out that I use the option to read in the contents as a ""project"" probably 75% of the time, and the parse_matrix and parse_tree functions the other 25%. This is probably because the ""project"" object (also roughly equivalent to a NeXML infoset) has a special method ""get_items"" that you can pass in class identifiers (named constants) so you can say project.get_items(TREE) and get a flat list of all the trees, regardless whether they were from multiple tree blocks in a nexus file, a single ToLWeb tree, or whatever. 

This was a fairly functional solution. My original design I nearly never use. Let this be a warning ;-)",NA,NA,NA
33,28332448,sckott,2013-11-12T20:57:21Z,2013-11-12T20:57:21Z,"I am, what about you @cboettig ?",NA,NA,NA
33,28332466,cboettig,2013-11-12T20:57:30Z,2013-11-12T20:57:30Z,"@rvosa go for it. It would be great if you can entice anyone to fiddle with it and uncover bugs, suggest features, or identify where the interface feels really clunky.  Obviously include a word to the wise that the package isn't really stable yet though... ",NA,NA,NA
27,28334219,cboettig,2013-11-12T21:17:27Z,2013-11-12T21:17:27Z,"@rvosa definitely helpful case to think about.  I guess the analogy is that we really don't want a functional that returns a ""phylo"" sometimes (e.g. when there is one tree) and a ""multiphylo"" other times, depending on how many trees are in the given input file.  Your experience seems to suggest to me that our `nexml_read` function should always return one of our `S4` nexml objects, which corresponds directly to the schema definition, and then provide methods such as:


```coffee
nex <- nexml_read(""nexml_data.xml"")
get_items(nex, ""tree"") # return a flat list of phylo objects (a single multiphylo), 
get_items(nex, ""trees"") # return a list of multiphylo objects (keeps multiple `<trees>` elements separate)
get_tree(nex) # an alias for `get_items(nex, ""tree"")`
get_items(nex, ""metadata"")   # get top-level metadata
get_items(nex, ""metadata"", ""otu"")   # metadata that is child element to any otu nodes
```

What do you think of such an interface?  


It is slightly annoying that we could no longer do something like:

```coffee
nex <- nexml_read(""nexml_data.xml"")
plot(nex) # or some other method defined only for ape::phylo
```

I think the fact that the `phylobase::phylo4` object could not be used in functions that took an `ape::phylo` object as an argument was a barrier to it's adoption.  Then again, the advantage of RNeXML is the external XML format, which `phylobase` didn't have.  Internally, I suspect most users will continue to use `ape` trees so I suppose it is okay if the workflow is always `nexml_read` followed by a coercion into a `phylo` format...

",NA,NA,NA
30,28334700,cboettig,2013-11-12T21:23:53Z,2013-11-12T21:23:53Z,"Yeah, of course you are correct.  The only sense in which this is an error is that it is wrong to ask for an `ape::phylo` representation of such a tree, because it is not a valid `ape::phylo` object.  

We avoid this issue entirely by following the strategy I outline in #27 (based on your suggestions), which keeps the steps of parsing the XML and coercing into phylo separate.  We have always been able to read such trees in into our `nexml` S4 format, but the way I've had the API `nexml_read` tries to coerce to phylo by default (unless asking for `nexml`). 

There will still be the case of a user asking to convert one of these `nexml` objects into a `phylo` object when some  `tree` elements have no nodes/edges, in which case dropping those trees with a warning seems reasonable?",NA,NA,NA
27,28334877,cboettig,2013-11-12T21:25:49Z,2013-11-12T21:25:49Z,"To take this one step further: perhaps `get_tree(nex)` should take an optional argument as to what format should be returned?  I suspect 99% of users will be trying to get an ape tree out of the thing, but no reason why we couldn't support returning the S4 `tree` structure (metadata and all), or other existing formats such as `ouch`, as options...",NA,NA,NA
27,28347526,cboettig,2013-11-13T00:02:41Z,2013-11-13T00:02:41Z,"Okay, for the moment I'm depricating the nexmlTree class that acts a `phylo` object and a `nexml` object, because it doesn't also act as a `multiPhylo` object (and basically tries to be too clever and is therefore confusing).  

We now have a `get_item` based interface (with aliases such as `get_tree` as well).  There are also coercion methods, e.g. `as(nexml, ""multiphylo"")`, so a user can write whatever they find most intuitive.  I settled for options for `tree`, `trees`, and `flat_trees`, since I wasn't comfortable discarding the heirarchical trees structure without an explicit request to do so. `get_trees` returns a multiphylo of multiphylos, always.  `get_item(nexml, ""flat_trees"")` returns a flattened multiphylo.

",NA,NA,NA
15,28347862,hlapp,2013-11-13T00:08:54Z,2013-11-13T00:09:17Z,The NeXML files generated by Phenoscape are in the https://github.com/phenoscape/phenoscape-data repo.,NA,NA,NA
30,28349822,rvosa,2013-11-13T00:37:36Z,2013-11-13T00:37:36Z,"Yeah, that seems reasonable.",NA,NA,NA
27,28350010,rvosa,2013-11-13T00:40:14Z,2013-11-13T00:40:14Z,"Yup, this sounds nice and consistent.",NA,NA,NA
15,28358827,balhoff,2013-11-13T02:56:15Z,2013-11-13T02:56:15Z,"Specifically, look under ""Curation Files"". The only caveat I can think of is that some values for ""id"" attributes start with an integer, which is not valid for XML. Something I didn't realize earlier and need to go through and fix.",NA,NA,NA
33,28366502,cboettig,2013-11-13T05:32:04Z,2013-11-13T05:32:04Z,"updated readme to reflect some minor changes in the interface, in case it's helpful for the blog post.  

",NA,NA,NA
15,28379962,rvosa,2013-11-13T09:24:37Z,2013-11-13T09:24:37Z,"Hi Jim! Thanks for the feedback, nice to see this tagging of user names
works so well. GitHub is good. Hope you're well, btw!

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
12,28492854,cboettig,2013-11-14T15:30:12Z,2013-11-14T15:30:12Z,"So taking another look at character matrix data.  I don't have a clear use-case in mind so the translation is less obvious to me.  

I see that we could easily map the `<matrix>` element into an R matrix, rows into rows, cells into cells, but I'm not quite sure on the particulars.  For instance, how we handle all the different cell types (AbstractCell vs DnaCell, etc etc).  

Also not sure if we would then de-reference (or whatever you call it) the states and otus, such that we have, say, species names as the row names and state names as the column names or whatever, rather than their reference ids numbers.  

Again since I'm not as familiar with this data structure or R workflow it might be destined for, I'm not so clear on how to implement it.  ",NA,NA,NA
15,28493388,cboettig,2013-11-14T15:35:31Z,2013-11-14T15:35:31Z,"@rvosa @balhoff Thanks!  At this time we haven't implemented the character matrix side of NeXML (see #12), mostly because I'm unfamiliar with the R packages typically used in this context (I believe bioconductor has quite a few, but I'm mostly familiar only with the [cran phylogenetics](http://cran.r-project.org/web/views/Phylogenetics.html) tools which largely work only with the phylogeny data...  

Beyond just extracting the character matrix as an R matrix, not sure what the sensible thing to do is for the associated phenoscape metadata.  Any example use case / work flows would be appreciated.  

For the moment, we can parse the phenoscape file but RNeXML will drop the `<characters>` node, since we don't even have an S4 version of that part of the schema implemented.  Of course we can just keep it in R's XML representation, which is in some ways more useful since we can at least then navigate the tree with xpath expressions.   ",NA,NA,NA
20,28494738,cboettig,2013-11-14T15:50:30Z,2013-11-14T19:28:06Z,"Figuring out the right thing to do for the metadata parsing is quite tricky.  In particular, it is difficult to be both flexible and user friendly.  For instance, as you point out in the example above, the user doesn't want to bother with namespaces they've never heard of -- e.g. it would make way more sense to most users to call `meta[""title""]` than `meta[""dc:title""]`.    

I suppose we could strip the prefixes from all the default namespaces, (might cause some trouble in overlap between terms in prism and dublin core?  perhaps we could resolve that as well), which would alleviate some of this problem.  While in general resolving the namespace definitions is obviously important, I suspect most RNeXML users don't care that the the title is actually a `dc:title`, etc.  Any reason why that is a bad idea?  

It seems like it would certainly be a bad idea to apply the same solution to namespaces beyond a few default ones known to RNeXML, so we would still be needing a solution for the more general metadata.  This is the crux of the problem, that it is hard to do something intelligent with data without knowing anything about it before hand (Or perhaps there's already some clever linked-data solution to this?)


Currently, the NeXML gets mapped into R's S4 objects, so all meta nodes are available by subsetting the S4 object at least, e.g. `nexml@trees[[1]]@meta[[1]][""property""]` is the `property` of the first meta node node annotation to the first trees node.  While this syntax is perhaps intuitive to most R users, it is pretty clumsy, particularly when we want to find the node that has a given property instead.  

It is infinitely easier to use XPath expressions to navigate metadata, particularly when dealing with namespaces and complex queries.  R has great XPath tools available through the XML package.  Unfortunately, most R users won't be familiar with XPath, and this means using R's xml, rather than our S4, representation of the NeXML data as our underlying data structure..
",NA,NA,NA
20,28600385,rvosa,2013-11-15T20:22:30Z,2013-11-15T20:22:30Z,"I don't think I agree that the prefixes could/should be stripped and that most users don't care for them. I think namespaces are crucial, and once people are working in their own little ecosystem of relevant vocabularies they will actually prefer to be dealing with dc:*, cdao:*, dwc:*, phen:* etc. There is really not ever going to be a universally agreed upon default namespace for anything, including 'title', it is part of the semweb workflow to acknowledge this and to see everything as scoped within some vocabulary/context. In fact, many of the larger ontology projects go entirely the other way and use opaque identifiers for terms (GO:367472, and so on), which to my mind is the more general case that should be made easy. One thing that's going to be important though is the ability to reconstruct which prefix goes with which namespace URI: for valid curies there is no reason to expect that their prefix is going to be constant, so users who want to write portable code will have to be able to look up the prefix for a given vocab namespace, and use that variable prefix to construct curies.",NA,NA,NA
12,28600660,rvosa,2013-11-15T20:26:33Z,2013-11-15T20:26:33Z,Can we come up with an interesting use case perhaps? Like a comparative analysis of a continuous and a discrete character? That would kind of guide the issue of managing the references between taxa and multiple character state matrices.,NA,NA,NA
34,28601080,rvosa,2013-11-15T20:32:34Z,2013-11-15T20:32:34Z,"It does more checks than that: basically the same reference checking as for eml. To do the validation you can POST a data file to the web service at http://www.nexml.org/nexml/phylows/validator (the name of the parameter for the file is 'file'), and then check the HTTP response code: if validation failed the response value is 400.",NA,NA,NA
20,28634811,hlapp,2013-11-16T20:18:16Z,2013-11-16T20:18:16Z,"
On Nov 15, 2013, at 3:22 PM, Rutger Vos wrote:

> I don't think I agree that the prefixes could/should be stripped and that most users don't care for them. 


I too disagree with the notion that namespaces should be stripped. Doing so only complicates everything else: all of a sudden, it is no longer clear what you mean by ""title"", and so now we have to think about ways to still say what you mean after the fact, and need to teach people that yes, you don't need to care about namespaces, but then again, you probably should. It kind of catapults us back into the nasty world of taxonomy where we use labels as identifiers, while full well knowing that they cannot be unique, and pretend to ourselves that this is the path to happiness.

That said, I do think there's something to be said about not asking to define (by URI) each and every namespace each and every time someone writes a script. The package could make use of http://prefix.cc to standardize on namespaces, sparing users the effort of defining them when they're well known anyway. For example, here's the one for Darwin Core: http://prefix.cc/dwc.",NA,NA,NA
20,28668290,cboettig,2013-11-18T00:04:45Z,2013-11-18T00:44:21Z,"@rvosa @hlapp Thanks both for weighing in here.  Of course we aren't stripping the prefixes when performing the original parsing into the ""nexml"" S4 object, which corresponds 1:1 with the NeXML schema; so this is only a question of how the user queries that metadata.  Currently we have a `metadata` function that simply extracts all the metadata at the specified level (nexml, otus, trees, tree, etc) and returns a named character string in which the name corresponds to the `rel` or `property` and the value corresponds to the `content` or `href`, e.g.:

```coffee
birds <- read.nexml(""birdOrders.xml"")
meta <- get_metadata(birds) 
```

prints the named string with the top-level (default-level) metadata elements as so: 

```coffee
> meta 
##                                             dc:date 
##                                        ""2013-11-17"" 
##                                          cc:license 
## ""http://creativecommons.org/publicdomain/zero/1.0/""
```
Which we can subset by name, e.g.  `meta[""dc:date""]`.   This is probably simplest to most R users; though exactly what the namespace prefix means may be unclear if they haven't worked with namespaces before.  (The user can always print a summary of the namespaces and prefixes in the nexml file using `birds@namespaces`).  

This approach is simple, albeit a bit limited.  


For instance, the R user has a much more natural and powerful way to handle these issues of prefixes and namespaces using either the XML or rrdf libraries.  For instance, if we extract meta nodes into RDF-XML, we could handle the queries like so:

```coffee
xpathSApply(meta, ""//dc:title"", xmlValue)
```

which uses the namespace prefix defined in the nexml; or 

```coffee
xpathSApply(meta, ""//x:title"", xmlValue, namespaces=c(x = ""http://purl.org/dc/elements/1.1/""))
```
defining the custom prefix `x` to the URI, or by sparql query,

```coffee
library(rrdf)
sparql.rdf(ex, ""SELECT ?title WHERE { ?x <http://purl.org/dc/elements/1.1/title> ?title })
```

Obviously the XPath or SPARQL queries are more expressive / powerful than drawing out the metadata from the S4 structure directly.  On the other hand, because both of these approaches use just the distilled metadata, the original connection between metadata elements and the structure of the XML tree is lost unless stated explicitly.  An in-between solution is to use XPath on the nexml XML instead, though I think we cannot make use of the namespaces in that case, since they appear in attribute values rather than structure.  



Anyway, it's nice to have these options in R, particularly for more complex queries where we might want to make some use of the ontology as well.  On the other hand, simple presentation of basic metadata is probably necessary for most users.  

",NA,NA,NA
12,28719382,cboettig,2013-11-18T17:33:56Z,2013-11-18T17:33:56Z,"Yeah, that sounds like an ideal use case for this context.  

Would be great to have a simple example with a continuous trait and a discrete trait for each otu in the tree.  Can you point me to an example nexml as a starting place? (Otherwise I can probably construct one -- just have to wrap my head around the nexml logic for `character` element appropriately, e.g. what nodes I need and how the inheritance works.  

This inheritance tree is probably a good starting point for me: http://nexml.org/nexml/html/doc/schema-1/characters/continuous/inheritance/

Not sure how discrete characters fit into that inheritance structure.  I guess I write the code against just the abstract classes anyway, as with the trees?  
",NA,NA,NA
20,28789317,rvosa,2013-11-19T13:25:41Z,2013-11-19T13:25:41Z," I am certainly deformed by having played around with curies in the past
but to me both ""dc:date"" and ""cc:license"" seem perfect. Certainly much
better than ""date"" (what, the fruit?) and ""license"" (to kill?), especially
if the common namespaces use conventional prefixes, as @hlapp suggests.

But the SPARQL query that you're showing - that would be so awesome to
have, wow! Wouldn't the extracted RDF still have the subject's ID, though?
So in principle you could still match up the NeXML DOM node with the
extracted triple, right?",NA,NA,NA
20,28816879,cboettig,2013-11-19T18:15:15Z,2013-11-19T18:15:15Z,"@rvosa Excellent point -- I had failed to add `about` attributes (#35) 

I guess that's not strictly a violation of the standard to omit this, since it passes the check, but still something we want to be sure not to omit.  ",NA,NA,NA
20,28817314,cboettig,2013-11-19T18:19:57Z,2013-11-19T18:19:57Z,"Okay, sounds like we will support both the simple extraction as character vectors named with property and prefix, and then optionally provide the triplestore representation for users to SPARQL query the metadata if they so desire.  For the manuscript it would be nice to have an example SPARQL query that is easy to understand intuitively but still does some logical inference. Any suggestions for a good example?
",NA,NA,NA
20,28828744,rvosa,2013-11-19T20:18:05Z,2013-11-19T20:18:05Z,"I think in R it would be especially cool to do some sort of statistics over
a set of DOME nodes that are annotated with the same predicate and value.
Can we come up with a use case to compute a posterior over something, for
example?",NA,NA,NA
12,28838185,rvosa,2013-11-19T21:36:29Z,2013-11-19T21:36:29Z,I sent a pull request that adds an additional example file.,NA,NA,NA
12,28934164,cboettig,2013-11-20T21:43:29Z,2013-11-20T21:53:00Z,"@rvosa I'm a bit foggy on the inheritance rules for some of the characters schema, in particular I cannot figure out where `<cell>` nodes are defined.  From where do they get their ""char"" and ""state"" attributes?  

So far I've implemented nodes as follows; please highlight any mistakes:

- `characters`, inherits TaxaLinked and contains one ""format"" node followed by one ""matrix"" node.  
- `format`, inherits ""Annotated"", contains a `<states>` node and 1 or more `char` nodes,
- `char`, inherits ""IDTagged"" **EDIT** provides attribute ""states"".  Or does it inherit them from someone else?
- `matrix`, inherits ""Annotated"", contains 1 or more ""row"" nodes
- `row` inherits ""TaxonLinked"", contains 0 or more `cell` nodes, 0 or more `seq` nodes (?)
- `states`, inherits ""IDTagged"", contains one or more states,
- `state`, inherits ""IDTagged"", includes the additional attribute ""symbol"",
- `uncertain_state_set`, inherits ""state"", contains two or more `member` nodes (??)
- `polymorphic_state_set`, inherits ""state"", contains two or more `member` nodes (??)
- `member`, no idea.  Guess it inherits the attribute ""state"" from whoever ""cell"" inherits ""state"" from?
- `cell`, no idea. Perhaps it inherits base and provides the attributes ""char"" and ""state""?  
- `seq` no idea.  Appears not to have attributes?  contains a text string?  

**EDIT**: I think these are all the nodes I see in the example file.  What additional definitions will we need to get started?  ",NA,NA,NA
38,29073079,rvosa,2013-11-22T13:45:20Z,2013-11-22T13:45:20Z,"All your assumptions are correct. For example, when I convert a nexus file to nexml, the states (0/1) in the matrix end up as the values of the symbol attribute. For labels, you have to watch out a little bit to ensure that i) they are optional and not guaranteed to be unique (so don't use them as some sort of key or ID) ii) the label of the row or node should take precedence over the label of the otu, if both are available. You can imagine, for example, that the rows in an alignment have a label such as Genus_species_genbank_accession, while the otu is just Genus_species. We would like to retain both, in their relevant locations.",NA,NA,NA
37,29073458,rvosa,2013-11-22T13:51:35Z,2013-11-22T13:51:35Z,"I think the merging and splitting, at least as an optional behaviour, would be really good to have. In designing nexml there's been some discussion about whether there should be a ""mixed"" type, but in the end it might be too confusing to deal with: you'd have multiple states elements linked to different columns each with their own alphabets. Note that this is still somewhat possible for categorical ""standard"" data (so you can restrict different columns to different numbers of states and different annotations, though the symbols would always be integers), but otherwise we don't mix things. Users would therefore have to merge as you suggest if they want to do a comparative analysis. It would be nice if this common task was available.

I didn't really understand your point about multiple trees blocks.",NA,NA,NA
38,29091922,cboettig,2013-11-22T17:27:50Z,2013-11-22T17:27:50Z,"@rvosa Great, thanks.  I added labels the `char` elements in your example [comp_analysis.xml](https://github.com/ropensci/RNeXML/blob/c5332dc9d214c691d77609158dc23e6a2f2dbe4c/inst/examples/comp_analysis.xml) file, after which we can do:

```coffee
f <- system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML"")
nex <- read.nexml(f)
get_characters(nex)
```

and get back: 

```coffee
         log snout-vent length reef-dwelling
taxon_8             -3.2777799             0
taxon_9              2.0959433             1
taxon_10             3.1373971             0
taxon_1              4.7532824             1
taxon_2             -2.7624146             0
taxon_3              2.1049413             0
taxon_4             -4.9504770             0
taxon_5              1.2714718             1
taxon_6              6.2593966             1
taxon_7              0.9099634             1
```

Note that 

- the state symbols (`0`, `1`) have been substituted for the state ids
- the otu labels `taxon_n` have been substituted for the otu numbers on the row elements, (as rownames)
- the char ids (colnames) have been substituted for the char labels.

As you point out, it sounds like we should be a bit careful when substituting labels.  Currently, if no label is available, I keep the id number (otu id or char id) instead.  Perhaps that behaviour is undesirable though, since it means the function is sometimes returning the char id and sometimes returning a label?

- [ ] Should we be using the label on the `row` itself (which I guess might read `species_genus_accession`) instead of the label on the corresponding `otu` for the rownames above?  

- [ ] Or should we always return both the `row` label and the corresponding `otu` label as separate columns (even when one or both labels are absent or they are the same)?  On one hand, this behavior seems the most consistent, but on the other, it's not likely to be convenient to most users (after all, we already have the extreme end of consistent but not convenient representation of the data as the S4 object).  



@hlapp @balhoff Is my use of `char` node's  `label` attribute consistent with the phenoscape expectation of where to find a 'human readable' column name?  One might imagine that the columns should instead be labeled with abbreviation codes (e.g. `LSVL` instead of `log snout-vent length`, since spaces and dashes can be somewhat troublesome in column names), and then have the abbreviation defined in full elsewhere?  This is the convention in the Ecological Metadata Language (EML); that columns are labeled by a short ""attributeName"" and defined by a longer ""attributeDefinition"" text string.

",NA,NA,NA
38,29095837,balhoff,2013-11-22T18:16:03Z,2013-11-22T18:16:03Z,@cboettig yes we use the label attribute for a human readable column name.,NA,NA,NA
39,29101643,sckott,2013-11-22T19:27:57Z,2013-11-22T19:27:57Z,"@cboettig  Hey, looking at now",NA,NA,NA
39,29102803,karthik,2013-11-22T19:41:11Z,2013-11-22T19:41:38Z,"Some quick thoughts.

`arrange()` in plyr can help get the order right.

You can do a `rbind.fill` if need be to get non-overlapping rows together.

Then you can recast with reshape's `dcast` which will fill in all available values for any taxon and drop in NAs for the rest.

`ldply` only works if everything is nice and symmetric.",NA,NA,NA
39,29106470,sckott,2013-11-22T20:27:47Z,2013-11-22T20:27:47Z,"woops, forgot to mention in commit message Does this (https://github.com/ropensci/RNeXML/commit/859d87c9bd8e6ca48c7c5df50b78a6f7a9011a1b) work? @cboettig ",NA,NA,NA
40,29109808,rvosa,2013-11-22T21:13:22Z,2013-11-22T21:13:22Z,Nice use case. Do you have an example EML file?,NA,NA,NA
39,29110839,sckott,2013-11-22T21:30:46Z,2013-11-22T21:30:46Z,"Okay, see most recent commit:  https://github.com/ropensci/RNeXML/blob/5a5701ed69841c34d7797cf0d77b62e62b6fd536/R/characters.R#L53-L76 (p.s. sorry, forgot to mention issue again!)",NA,NA,NA
40,29111504,cboettig,2013-11-22T21:42:52Z,2013-11-22T21:42:52Z,"@rvosa Not one that includes a tree off the top of my head, but it's pretty easy to find examples that have character trait data across a range of species just by searching KNB.  For instance, here's a kinda cool example for carnivorous plant species: https://knb.ecoinformatics.org/knb/metacat?action=read&qformat=knb&sessionid=0&docid=knb-lter-hfr.168.3 

For instance, the first CSV file includes a continuous trait (growth rate) and a discrete trait (habitat) for a range of species, with some species having multiple observations and others not.  

One of the awesome things about KNB is that it indexes all the metadata, so it is possible to query for data matching a particular attribute or species.  Unfortunately, there's no semantics around those attributes, so you just have to hope the data creator describes the trait with some of the same words that you do.  I was poking around the phenoscape project website and papers this morning and the project is kinda mind-blowing the scope and depth of expression there.",NA,NA,NA
39,29111848,cboettig,2013-11-22T21:48:46Z,2013-11-22T21:48:46Z,@SChamberlain perfect. rock on.,NA,NA,NA
39,29112074,sckott,2013-11-22T21:51:56Z,2013-11-22T21:51:56Z,"hmmm, doesn't work for lists > 2, sorry, fixing",NA,NA,NA
39,29112287,cboettig,2013-11-22T21:55:08Z,2013-11-22T21:55:08Z,@SChamberlain good catch.  Can you throw some test_that tests for it into test_characters.R when it's running?,NA,NA,NA
39,29112673,sckott,2013-11-22T22:00:51Z,2013-11-22T22:00:51Z,yep,NA,NA,NA
43,29188764,rvosa,2013-11-25T09:54:03Z,2013-11-25T09:54:03Z,">
> So, I just wanted to make sure that we were handling this third case
> appropriately. We could instead add a new otus block in this case with all
> the otus for the characters, which would mean duplicate entries of certain
> otus. I'm not sure just how problematic that would be?
>
My sense is that it would be better to create a new otus node, with
possibly duplicate otus, than to automagically fold newly encountered
labels into an existing otus node without any user intervention. We can't
know ahead of time why people have an existing otus node (or multiples of
them) so it's not very polite to just start poking around in them. What
would be nice is to then, separately, have some sort of merge_by_name()
method that does the merging, perhaps with some additional intelligence
(e.g. ignore suffixes that look like accession numbers).

>  Because a characters node must refer to a single otus node for reference
> (I think), there's no point in checking for matches across multiple otussets, or writing only the unmatched otu labels into a separate otus node. I
> assume it's no trouble to have more otu nodes in an otus block than any one
> trees or characters block actually needs?
>

Yes, it's OK to have non-referenced otus blocks, as many as you like, and
non-referenced otu nodes in a block.",NA,NA,NA
42,29188981,rvosa,2013-11-25T09:57:49Z,2013-11-25T09:57:49Z,How useful is phylobase's readNexus()?,NA,NA,NA
43,29242977,cboettig,2013-11-25T21:16:50Z,2013-11-25T21:16:50Z,"@rvosa Thanks, that makes sense.  Will modify the function such that we will still use an existing `otus` block if it has all the taxa of interest (as we might often expect when adding a character matrix to a file containing a phylogeny), but will create an entirely new `otus` block if any taxa in the character matrix are unmatched.  

Obviously this same issue comes up when adding trees to an existing nexml file (I just hadn't written that method yet -- so far our methods only support creating a new nexml object/file given a tree).  Naturally I will follow the same rule of thumb -- create a new `otus` block if any of the taxa are unmatched. 

Still, I cannot help feel that this may not produce the behavior the user expects in certain circumstances.  Imagine a user adds a tree and then the corresponding character matrix to the same nexml file, and the matrix includes a few species not on the tree.  This will result in two separate otus blocks with 99% the same contents, which is probably not the desired structure.  In particular, I worry that this makes annotating the otu nodes difficult. It may also make it harder for a machine to recognize that the matrix and phylogeny cover the same otus (e.g. must explicitly check the matches, rather than just the otus attribute of each block.)  

A user iteratively adding a set of characters and/or trees could wind up with lots of mostly duplicated otus blocks.  Perhaps we must let the user toggle this behavior in the function call?  We would still need a default option (or have a more confusing function).  


",NA,NA,NA
42,29249547,hlapp,2013-11-25T22:32:34Z,2013-11-25T22:32:34Z,"Phylobase uses NCL for that. This is great on the one hand (using a known reference parser implementation rather than reinventing one), but getting NCL to compile and the package to link to is has been a repeated source of trouble, so I'm hesitant about recommending it.",NA,NA,NA
42,29254724,cboettig,2013-11-25T23:48:44Z,2013-11-25T23:48:44Z,"@rvosa Thanks for reminding me about the phylobase version, certainly sounds like a promising alternative for R users to extract character data. As @hlapp says, we didn't want to introduce a hard dependency on phylobase since it occasionally disappears from CRAN due to complications from the NCL, but in this context we could add it to our SUGGESTS or ENHANCES list instead and merely point to it as a way R users can extract character data in the nexus format.  

Unfortunately I haven't had any luck parsing my [example nexus character file](https://github.com/ropensci/RNeXML/blob/4894724c859b486e82aa4383fd2b2f0e4ead91f1/inst/examples/mbank_X962_11-22-2013_1534.nex) that a I downloaded from the MorphoBank repo.  

Though this is not really an RNeXML issue, I thought showing the serializing of character data from MorphoBank into NeXML might be a good example.  ",NA,NA,NA
36,29269296,cboettig,2013-11-26T05:57:09Z,2013-11-26T05:57:09Z,"This is working now by the way. 

We can load the library, parse the NeXML file and extract both the characters and the phylogeny.  

```coffee
library(RNeXML)
nexml <- read.nexml(system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML""))
traits <- get_characters_list(nexml)
tree <- get_tree(nexml)
```

(Note that `get_characters` would return both discrete and continuous characters together in the same data.frame, but we use `get_characters_list` to get separate data.frames for the continuous `characters` block and the discrete `characters` block).  

We can then fire up `geiger` and fit, say, a Brownian motion model the continuous data and a Markov transition matrix to the discrete states:  

```coffee
library(geiger)
fitContinuous(tree, traits[[1]])
fitDiscrete(tree, traits[[2]])
```

Will add this to the vignette examples too.  ",NA,NA,NA
42,29276801,rvosa,2013-11-26T09:08:48Z,2013-11-26T09:08:48Z,"By the way, you could also pipe the nexus through the nexus2nexml web
service and then read it as nexml :)


On Tue, Nov 26, 2013 at 12:48 AM, Carl Boettiger
<notifications@github.com>wrote:

> @rvosa <https://github.com/rvosa> Thanks for reminding me about the
> phylobase version, certainly sounds like a promising alternative for R
> users to extract character data. As @hlapp <https://github.com/hlapp>says, we didn't want to introduce a hard dependency on phylobase since it
> occasionally disappears from CRAN due to complications from the NCL, but in
> this context we could add it to our SUGGESTS or ENHANCES list instead and
> merely point to it as a way R users can extract character data in the nexus
> format.
>
> Unfortunately I haven't had any luck parsing my example nexus character
> file<https://github.com/ropensci/RNeXML/blob/4894724c859b486e82aa4383fd2b2f0e4ead91f1/inst/examples/mbank_X962_11-22-2013_1534.nex>that a I downloaded from the MorphoBank repo.
>
> Though this is not really an RNeXML issue, I thought showing the
> serializing of character data from MorphoBank into NeXML might be a good
> example.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/42#issuecomment-29254724>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
36,29276972,rvosa,2013-11-26T09:11:13Z,2013-11-26T09:11:13Z,"Wow!


On Tue, Nov 26, 2013 at 6:57 AM, Carl Boettiger <notifications@github.com>wrote:

> This is working now by the way.
>
> We can load the library, parse the NeXML file and extract both the
> characters and the phylogeny.
>
> library(RNeXML)nexml <- read.nexml(system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML""))traits <- get_characters_list(nexml)tree <- get_tree(nexml)
>
> (Note that get_characters would return both discrete and continuous
> characters together in the same data.frame, but we use get_characters_listto get separate data.frames for the continuous
> characters block and the discrete characters block).
>
> We can then fire up geiger and fit, say, a Brownian motion model the
> continuous data and a Markov transition matrix to the discrete states:
>
> library(geiger)fitContinuous(tree, traits[[1]])fitDiscrete(tree, traits[[2]])
>
> Will add this to the vignette examples too.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/pull/36#issuecomment-29269296>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
43,29277272,rvosa,2013-11-26T09:15:40Z,2013-11-26T09:15:40Z," I think it's OK to ask for user intervention when integrating data. It's
how I do it in Bio::Phylo for the exact same use case - but I can also
appeal to a higher authority here: it's also how it's done in mesquite. If
we discover it's a frequent PITA (I doubt it) then it can always be changed.",NA,NA,NA
44,29277349,rvosa,2013-11-26T09:17:05Z,2013-11-26T09:17:05Z," @hlapp, isn't this a job for the MIAPA ontology?",NA,NA,NA
44,29318968,hlapp,2013-11-26T18:39:09Z,2013-11-26T18:39:09Z,"Metadata are generally about positively stating or asserting facts, not the absence of them. We developed a provenance documentation recommendation at the 2nd Phylotastic Hackathon, using W3C's PROV and MIAPA. You could of course use OWL to assert that some instance that is not of type cdao:Tree prov:wasDerivedFrom the trait matrix. But it'd probably be more powerful to assert instead what exactly was derived from it. See issue #26.",NA,NA,NA
44,29324537,bomeara,2013-11-26T19:38:00Z,2013-11-26T19:38:00Z,"I think it's ok to just have the comparative data with the tree with no special need to note that the tree came from a different dataset. For example, one popular sample dataset in R is the geospiza one from Geiger: it has a tree, and various bird measurements, but I don't think anyone expects that the bird tree came from the included data.",NA,NA,NA
44,29330852,cboettig,2013-11-26T20:28:36Z,2013-11-26T20:28:36Z,"@bomeara Thanks, that's good to hear!  Of course the geiger case, that data isn't being read in as a nexus file, so there is isn't the same assumption.  Have you seen anyone read in or write out comparative trait data in nexus format?  Does your group tend to store character data in xlsx/csv formats, or nexus, or something else?  

I'd like to make the case that in comparative phylogenetics we should start publishing the relevant trait data along with the phylogenies in a single nexml file, as it would facilitate reproducibility, metadata annotation, and data exchange across different platforms and software.  I don't think many comparative methods people are using nexus files for their trait data at the moment though (perhaps/hopefully I'm wrong), so wondering if this will seem confusing to people.  

@hlapp excellent point about documenting where the tree did come from.  Perhaps I can parse that down into some simple user commands for common cases, even if it captures only the general notion (e.g. used ""MrBayes"" vs ""simulated bd tree in R"") and not the whole provenance.  ",NA,NA,NA
42,29335171,cboettig,2013-11-26T21:21:47Z,2013-11-26T21:21:47Z,"@rvosa That's a great idea.  Um, can you point me to the nexus2nexml web service endpoint and documentation?  Not seeing a link to it on the nexml.org homepage...",NA,NA,NA
44,29348234,hlapp,2013-11-27T00:00:38Z,2013-11-27T00:00:38Z,@cboettig Could you perhaps also file an issue on the MIAPA ontology tracker (referring back to this issue) about needing a term indicating that a matrix is trait data for comparative analysis?,NA,NA,NA
42,29348475,hlapp,2013-11-27T00:03:13Z,2013-11-27T00:03:13Z,"@cboettig @rvosa this is a useful service for testing etc, but I'm not sure it's a good idea to make important functions of the library dependent on an online connection and a website that I'm not sure is built for a lot of traffic.",NA,NA,NA
42,29350477,cboettig,2013-11-27T00:28:38Z,2013-11-27T00:28:38Z,"@hlapp Thanks for the heads up.  I don't think this is a core function RNeXML, as we're obviously focused on the nexml side and there are already the two nexus parsers available for R already; it's just a pity that they aren't as robust as one might hope (but that's part of the motivation for nexml after all).  I guess we can just point users to phylobase::readNexus() for reading in nexus character data.  As far as I can tell, ape::read.nexus is the popular solution for reading in nexus phylogenies in R, which we can then write out to nexml.  As I've speculated in #44, I think most R users read in comparative trait data from csv/excel formats instead of nexus anyway, so I don't see this as getting heavy use.  ",NA,NA,NA
44,29352539,bomeara,2013-11-27T01:13:24Z,2013-11-27T01:13:24Z,"Note that DNA data could be comparative trait data. For example, I could make a tree from the usual phylogenetic markers and then use it to reconstruct a venom gene sequence down the tree. I'd try to deal with this as simply as possible: metadata that a tree is made from COI, 28S, and ef1a and that the comparative traits are venom genes. 

As far as comparative data formats, I think xls may be most common (sigh), followed by csv and nexus (perhaps Mesquite-flavored nexus: title, multiple taxa blocks, etc). ",NA,NA,NA
44,29353750,cboettig,2013-11-27T01:40:47Z,2013-11-27T01:40:47Z,"@bomeara thanks! perhaps that low adoption is part due to problems with nexus parsers for character data in R?  (e.g. problems I've run into parsing morphobank nexus files as mentioned in #42).  

At least that is something we could overcome in having both tree and character in NeXML.  For instance, a user with comparative trait data could serialize that data for easy exchange and archiving with this RNeXML package as it stands:  

```coffee
library(RNeXML)
library(geiger)
data(geospiza)

nexml <- add_trees(geospiza$phy)
nexml <- add_character_data(geospiza$dat)
write.nexml(nexml, ""geospiza.xml"") 
```

Which generates [geospiza.xml](https://github.com/ropensci/RNeXML/blob/4872c3fdb9e7af2cb38a474576852b55efc65e13/inst/examples/geospiza.xml) nexml.  This would keep the traits and tree together in a single file (to which more annotations/metadata could easily be added) that one could deposit on Dryad etc.  

",NA,NA,NA
42,29379728,rvosa,2013-11-27T12:10:10Z,2013-11-27T12:10:10Z,"You can POST a file to http://nexml.org/nexml/phylows/nex2xml (parameter
name 'file')

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
42,29423913,cboettig,2013-11-27T22:02:38Z,2013-11-27T22:02:38Z,"Cool that seems to work, but it doesn't seem to be able to parse this morphobank nexus file: https://github.com/ropensci/RNeXML/blob/master/inst/examples/mbank_X962_11-22-2013_1534.nex probably something weird with the file since none of the parsers can do anything with it.  ",NA,NA,NA
14,29428306,cboettig,2013-11-27T23:17:46Z,2013-11-27T23:17:46Z,"It appears that strings starting with a number were not valid ids (and uuids often start with numbers).  

To address this, all functions that assign ids use the internal method `nexml_id()`, which can create local numbers using a given character prefix; e.g. edges use ""nexml_id(""e"") to get ids like e1, e2, etc, using an internal counter.  The counters start at 1 and increase each time the id of a given prefix is used in that R session, unless reset with `reset_id_counter()`.  This local counter scheme is used by default.

The command `options(uuid=TRUE)` will make RNeXML use uuids for all id attributes instead.  To avoid the validation error, these are prepended with `uuid-`.  This option can be issued per session or put in the user's .Rprofile as persistent configuration.   `options(uuid=FALSE)` sets the behavior back to the local identifiers.

`test_global_ids.R` provides a unit test that we generate valid nexml when using the global (uuid) id scheme.  

",NA,NA,NA
42,29444544,rvosa,2013-11-28T07:27:42Z,2013-11-28T07:27:42Z,"Yup, it's probably the way the charlabels/statelabels construct is used.

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
42,29534968,bomeara,2013-11-29T19:50:20Z,2013-11-29T19:50:20Z,"phylobase hasn't been booted off CRAN for quite some time now, and developers have responded fairly quickly (at least compared to many phylogenetics CRAN packages) in the past when it has been booted. That said, C++ code in R (the NCL) does introduce another point of failure, with the benefit being NCL's flexible Nexus handling. I'd personally go with phylobase for reading nexus files rather than creating another parser.",NA,NA,NA
39,29541557,cboettig,2013-11-29T23:38:11Z,2013-11-29T23:38:11Z,@SChamberlain looks good.  I fixed the `get_characters_matrix` subroutine so that the example `characters.xml` is also working.  Feel free to close this issue when you're ready.  ,NA,NA,NA
20,29561092,cboettig,2013-11-30T21:09:30Z,2013-11-30T21:09:30Z,"@rvosa Could you expand a bit on what you think might be a useful SPARQL metadata example to illustrate?  I was thinking something very simple to start: e.g. would it be possible to declare species scientific names, or genus, etc, on the otus, and then write a sparql query that would just return all those species belonging to some higher taxonomic level?  

An example such as that would be easy to understand but still illustrate the ability for the computer to infer something not actually specified in the data (e.g. we haven't explicitly declared the higher taxonomic classification in the metadata).  



Poking around a bit I saw some nice examples on the darwin core google-code repo: https://code.google.com/p/tdwg-rdf/wiki/SparqlReasoning, https://code.google.com/p/darwin-sw/wiki/SparqlExamples but a bit complex/abstract.  Not having experience working with sparql myself, I think at this stage the goal would be mostly to illustrate the concept of reasoning outside the explicit data (from within R) rather than actually teach the query language.  ",NA,NA,NA
31,29567809,cboettig,2013-12-01T05:33:22Z,2013-12-01T05:33:22Z,"Fixed:

```coffee
f <- system.file(""examples"", ""trees.xml"", package=""RNeXML"")
nex <- read.nexml(f)
trees <- get_trees(nex)
write.nexml(trees=trees)
```
(state argument name explicitly, so as not to be confused with nexml object or character object).

OR

```coffee
write.nexml(trees[[1]])
```

(we can coerce this because it has class 'multiPhylo' instead of 'list')

OR 

```coffee
f <- system.file(""examples"", ""trees.xml"", package=""RNeXML"")
trees <- as(read.nexml(f), ""multiPhylo"")
write.nexml(trees)
```

(explicitly convert to a multiPhylo to begin with).  


Tests added in `test_toplevel_api.R`",NA,NA,NA
37,29567820,cboettig,2013-12-01T05:34:21Z,2013-12-01T05:34:21Z,Addressed in #39 ,NA,NA,NA
39,29567824,cboettig,2013-12-01T05:34:49Z,2013-12-01T05:34:49Z,"@SChamberlain closing for now, reopen if there's still any outstanding issues here.  ",NA,NA,NA
12,29567873,cboettig,2013-12-01T05:39:12Z,2013-12-01T05:39:12Z,"Overall this issue has now been parceled out and addressed in #36, #37, #38, #39, #42, #44.

I'm still not quite sure I got the inheritance map worked out perfectly, (see comments above), but we seem to be able to handle valid character matrices for the most part now. Since the general strategy is in place through the `add_characters`, and `get_characters` functions, I think we can close this one.   Details will be followed up in additional issues.  ",NA,NA,NA
49,29615964,rvosa,2013-12-02T13:07:44Z,2013-12-02T13:07:44Z,"I think it is quite rare so you can probably get away with not having it
now. On the other hand, how are IUPAC single character ambiguity codes now
handled?


On Sun, Dec 1, 2013 at 6:41 AM, Carl Boettiger <notifications@github.com>wrote:

> We parse polymorphic states into the S4 version fine, but do not convert
> them into a matrix.
>
> I think StandardCells types with polymorphisms could cause get_charactersto error. Not clear what the return data-type should be for the
> polymorphic/uncertain character state anyhow.
>
> Not sure that this is a high priority, not sure how common this is in
> character data (e.g. vs just having a single explicit uncertain state).
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/49>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
20,29616156,rvosa,2013-12-02T13:10:46Z,2013-12-02T13:10:46Z,"I think that's a great example. You mean something like: the annotations
just give the species URIs but we can run a query to get all the species
within a genus? I don't really know what ontology you would use for that,
though. Maybe @hlapp has suggestions?",NA,NA,NA
48,29616327,rvosa,2013-12-02T13:13:35Z,2013-12-02T13:13:35Z,"I was not away of Yet Another Newick Hack but there you have it. I guess
you could either do this as multiple annotations on the ""edge"" element, or
by introducing an unbranched internal node for each stretch of mapped
character state.",NA,NA,NA
48,29641164,cboettig,2013-12-02T17:58:40Z,2013-12-02T17:58:40Z,"Note: this discussion continues on the [nexml-discuss](http://sourceforge.net/mailarchive/forum.php?thread_name=2802E5E9-B687-4D04-A5F9-6EB08A2B7AEF%40nescent.org&forum_name=nexml-discuss), where it might reach a broader audience.  

Sounds like there's a good case for not modifying the topology.  Meanwhile, notes to myself on how this might be done, with some outstanding questions to resolve, based on the discussion on the listserve.  

> Perhaps an edge that changed from state 1 to state 2 might be annotated as:  

```xml
<states>
  <state id=""s1"" label=""description of state"">
  <state id=""s2"" label=""description of alternative state"">
  ...
  <edge id=""e1"" source=""n1"" target=""n2"" about=""#e1"" length=""6.4"">
    <meta property=""x:order"" content=""1""  xsi:type=""nex:LiteralMeta"" id = ""m1"" about=""#m1"">
      <meta property=""x:length"" content=""3.4"" xsi:type=""nex:LiteralMeta"" id = ""m2"" />
      <meta property=""x:hasState"" content=""s1"" xsi:type=""nex:LiteralMeta"" id = ""m3"" />
    </meta>
   <meta property=""x:order"" content=""2""  xsi:type=""nex:LiteralMeta"" id = ""m4""  about=""#m4"">
      <meta property=""x:length"" content=""3.0"" xsi:type=""nex:LiteralMeta"" id = ""m5""/>
      <meta property=""x:hasState"" content=""s2"" xsi:type=""nex:LiteralMeta"" id = ""m6""/>
    </meta>
  </edge>
```

- [ ] Obviously I have just made up the properties `x:`.  How would I go about establishing a formal namespace for such properties? 

- [ ] Clearly several alternative annotations could be proposed here.  For instance, could either declare `start`, `stop`, and `state` times for each section, instead?   

- [ ] Also, not sure if my nesting of meta elements is appropriate. Perhaps they should all be wrapped in a `meta` declaring something like `hasStochasticCharacterMapping`.  


",NA,NA,NA
20,29642194,cboettig,2013-12-02T18:10:08Z,2013-12-02T18:10:08Z,"@rvosa Yeah, exactly.  Or within an order, etc -- e.g. ""give me all the frogs (order:Anura) in this nexml"".  

I was wondering if such a thing could be done in Darwin Core, but perhaps resolving that kind of query with RDF is harder than it sounds?  Would need a triplestore of all species ids and higher classification, and concepts that genus is `childOf` family is `childOf` order etc?  

It might be more straight forward to query a service that provides the higher classification and then search directly against that, but that doesn't really illustrate any semantic reasoning...",NA,NA,NA
20,29648539,hlapp,2013-12-02T19:23:13Z,2013-12-02T19:23:13Z,"You would just need a corresponding species taxonomy ontology, such as NCBI:
http://www.obofoundry.org/cgi-bin/detail.cgi?id=ncbi_taxonomy

Or the VTO: https://code.google.com/p/vertebrate-taxonomy-ontology/
(canonical URI http://purl.obolibrary.org/obo/vto.owl)

We do this in the Phenoscape KB all the time.",NA,NA,NA
20,29648854,cboettig,2013-12-02T19:26:26Z,2013-12-02T19:26:26Z,@hlapp _very_ cool.  Might take a bit to wrap my head around this -- Can you point me to an example nexml file that contains such meta elements (or just RDF) and maybe an example sparql query? ,NA,NA,NA
20,29649440,hlapp,2013-12-02T19:32:49Z,2013-12-02T19:32:49Z,"
On Dec 2, 2013, at 2:26 PM, Carl Boettiger wrote:

> @hlapp very cool. Might take a bit to wrap my head around this -- Can you point me to an example nexml file that contains such meta elements (or just RDF) and maybe an example sparql query?
> 
The Phenoscape NeXML data files (I sent pointer previously) use the TTO and VTO ontologies for OTU designations. The RDF for the KB is fairly large and thus loaded directly into the triple store. I'll leave it to @balhoff to point to specific examples in the codebase, but note that such SPARQL queries will be necessarily very specific to the use case at hand. If you were wondering how to leverage OWL reasoning in SPARQL, many triple stores will support rdf:subClassOf reasoning, and some also support SPARQL 1.1 property paths (recursion over transitive properties).",NA,NA,NA
48,29657547,cboettig,2013-12-02T21:07:48Z,2013-12-02T21:07:48Z,"Cool, I really like @mtholder's suggestion on the mailing list; it more clearly reflects the logic of NeXML elements and helps me think about how (a typical user) would (most sensibly) extend nexml (as compared to hacking the newick format yet again).  

Perhaps this use-case might be a nice one to illustrate in the manuscript as an example of how an R user might go about defining a meaningful extension to nexml?  ",NA,NA,NA
20,29661530,cboettig,2013-12-02T21:52:13Z,2013-12-02T21:52:13Z,"@hlapp thanks.  I see the use of VTO on the OTUs in the phenoscape examples files you mentioned earlier, e.g. 
https://github.com/phenoscape/phenoscape-data/blob/master/Curation%20Files/completed-phenex-files/gardiner_1984.xml#L8 (though I cannot resolve the linked resource in the browser?) 

So just to make sure I understand: based on that meta element I should in principle be able to write a sparql query that tells me that the otus include some Palaeonisciformes fish?  By specific to the use case, you mean that such a query would be specific to, say, the VTO ontology vs the NCBII one?  Thanks all for bringing me up to speed on this.  

Also, if there's a more obvious example or use case to illustrate OWL/SPARQL reasoning for a researcher unfamiliar with these concepts, always happy to hear other suggestions.  ",NA,NA,NA
20,29662782,hlapp,2013-12-02T22:05:21Z,2013-12-02T22:05:21Z,"
On Dec 2, 2013, at 4:52 PM, Carl Boettiger wrote:

> (though I cannot resolve the linked resource in the browser?)
> 
Yes, individual term identifiers don't resolve right now. We have to register to ontology with Ontobee to make that work.
> So just to make sure I understand: based on that meta element I should in principle be able to write a sparql query that tells me that the otus include some Palaeonisciformes fish?
> 
Yes.
> By specific to the use case, you mean that such a query would be specific to, say, the VTO ontology vs the NCBII one?
> 
That, and that how are different ways of representing the hierarchy (class hierarchy, hierarchy of individuals by a transitive property, or a mixture), as well as connecting it to data. The SPARQL queries will differ quite a lot between them, yet achieve the same thing. ",NA,NA,NA
38,29680293,hlapp,2013-12-03T03:14:21Z,2013-12-03T03:14:21Z,"
On Nov 22, 2013, at 12:27 PM, Carl Boettiger wrote:

> @hlapp @balhoff Is my use of char node's label attribute consistent with the phenoscape expectation of where to find a 'human readable' column name? One might imagine that the columns should instead be labeled with abbreviation codes (e.g. LSVLinstead of log snout-vent length, since spaces and dashes can be somewhat troublesome in column names), and then have the abbreviation defined in full elsewhere? This is the convention in the Ecological Metadata Language (EML); that columns are labeled by a short ""attributeName"" and defined by a longer ""attributeDefinition"" text string.
> 
I don't think there's a convention stating that the char node label needs to be a short string or conversely can't be one. In Phenoscape this is just taken from the character matrix. Systematists don't ever call a character ""LSVL"" as far as I've seen. But that doesn't mean that other sources for matrices can't be using a short name that's expanded elsewhere.

If there is only one form, I'd suggest using rdfs:label. If there are two, a short form serving as column label and a long form giving a human-readable definition, I'd suggest to use refs:label for whatever is supposed to be the column label, and dc:description for whatever its explanation is.",NA,NA,NA
23,29684938,cboettig,2013-12-03T05:36:51Z,2013-12-03T05:36:51Z,"Hmm, the validator doesn't appear to like these additional elements.  This minimal example isn't valid: 

```xml
<nex:nexml xmlns:nex=""http://www.nexml.org/2009"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns=""http://www.nexml.org/2009"" xmlns:foaf=""http://xmlns.com/foaf/0.1/"" xmlns:eml=""eml://ecoinformatics.org/eml-2.1.1"" xmlns:xhtml=""http://www.w3.org/1999/xhtml"" version=""0.9"" generator=""RNeXML"">
  <meta xsi:type=""LiteralMeta"" id=""m10"" property=""eml:additionalMetadata"">
    <xhtml:div typeof=""foaf:Person"" about=""http://carlboettiger.info#me"">
      <a rel=""foaf:account"" href=""https://twitter.com/cboettig"">twitter</a>
      <a rel=""foaf:account"" href=""https://github.com/cboettig"">github</a>
    </xhtml:div>
  </meta>
</nex:nexml>
```

schema validation says: 

```
[1] ""Element '{http://www.w3.org/1999/xhtml}div': No matching global element declaration available, but demanded by the strict wildcard.""
```

Not sure what I missed, but I get the same error for XML extensions on some example phenoscape files.  ",NA,NA,NA
23,29689286,rvosa,2013-12-03T07:43:22Z,2013-12-03T07:43:22Z,"Mmmm... Strange. What happens if you omit the xhtml: prefix from the
element? I know that might be wrong but I'm curious what the validator says.

-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
23,29718416,cboettig,2013-12-03T15:23:36Z,2013-12-03T15:23:36Z,"Same error, just without the namespace in front of the div

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Dec 2, 2013 11:43 PM, ""Rutger Vos"" <notifications@github.com> wrote:

> Mmmm... Strange. What happens if you omit the xhtml: prefix from the
> element? I know that might be wrong but I'm curious what the validator
> says.
>
> --
>
> Dr. Rutger A. Vos
> Bioinformaticist
> Naturalis Biodiversity Center
> Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
> Netherlands
> Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
> http://rutgervos.blogspot.com
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/23#issuecomment-29689286>
> .
>",NA,NA,NA
50,30039671,cboettig,2013-12-06T23:44:06Z,2013-12-06T23:44:06Z,"Done, see `nexml_methods.R`.  Suggestions for improvement welcome.  

Example:

```coffee
f <- system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML"")
read.nexml(f)
```

```
A nexml object representing:
 	 1 phylogenetic trees 
 	 4 meta elements 
 	 2 character matrices 
 	 10 taxonomic units 
 Taxa: 	 taxon_1, taxon_2, taxon_3, taxon_4, taxon_5, taxon_6 ... 

 NeXML generated by Bio::Phylo::Project v.0.56 using schema version: 0.9 
 size: 296.2 Kb 
```


- [ ] Consider adding author/title/citation information to the display?  

- [ ] Currently `show` just calls `summary` (analogous to the S3 `print` method in `ape::phylo`).  Any suggestions / reasons for a separate `show` method

Literally showing all the data would probably just be messy in any format, users wanting to see the nexml can look at the file (or `cat(write.nexml(nexml))` to see in the R console).   ",NA,NA,NA
50,30124969,rvosa,2013-12-09T11:38:35Z,2013-12-09T11:38:35Z,Would it be possible to indicate how many trees per tree block?,NA,NA,NA
50,30154337,cboettig,2013-12-09T17:48:15Z,2013-12-09T17:48:15Z,"Summary now prints number of trees by block:  

```
A nexml object representing:
 	 2 phylogenetic tree blocks, where: 
 	 block 1 contains 2 phylogenetic trees
	 block 2 contains 2 phylogenetic trees 
 	 2 meta elements 
 	 0 character matrices 
 	 92 taxonomic units 
 Taxa: 	 Struthioniformes, Tinamiformes, Craciformes, Galliformes, Anseriformes, Turniciformes ... 

 NeXML generated by RNeXML using schema version: 0.9 
 size: 1.1 Mb
```

With only one block it will still show the same layout as above, just saying `1 phylogenetic tree`, `block 1 contains`...    @rvosa this was a great suggestion, particularly since we provide different functions to handle different ways of converting the trees blocks into phylo objects, e.g. preserving always the block structure: `get_trees_list()`,  or automatically collapsing length 1 lists with `get_trees` (so that a single tree in a single block is a ""phylo"" and not a 'list of multiPhylo.  These functions are the same if there are multiple blocks with multiple trees.)  We also have `get_flat_trees` which combines all blocks into a single multiPhylo list.  So it's great that the user can now see the internal NeXML structure nicely summarized to help choose the appropriate format.  

 I'm definitely open to suggestions for tweaking this summary display further.  ",NA,NA,NA
53,31165146,cboettig,2013-12-24T09:35:04Z,2013-12-24T09:35:04Z,"fixed, tests coming",NA,NA,NA
48,31188409,cboettig,2013-12-25T00:39:04Z,2013-12-25T00:39:04Z,"```xml
<characters id=""m1"">
  <format>
    <states id=""ss1"">
      <state id=""s1""/>
      <state id=""s2""/>
   </states>
   <char id=""cr1"" states=""ss1"" label=""reef-dwelling""/>
</characters>
...
<tree>
  ...
  <edge id=""e1"" source=""n1"" target=""n2"">
    <meta>
      <simmap:reconstructions> 
        <simmap:reconstruction character=""cr1"">
           <simmap:stateChange id=""sc1"" length=""0.4"" state=""s2""/>
           <simmap:stateChange id=""sc2"" length=""0.5"" state=""s1""/>
       </simmap:reconstruction>
     </simmap:reconstructions>
```

A few minor changes from Mark's (@mtholder) suggestion.  Mark annotates the node state, but it seems strange to do this in a meta element child to an edge.  I've also dropped the attribute `edge = e1` from the `simmap:stateChange` node, since this annotation is a child of the edge element `e1` already -- perhaps I should keep it anyway?  (When phenoscape annotates a `state` element with a meta doesn't appear to explicitly reference the state id)

One limitation is that this format doesn't explicitly state the order in which the changes occur.  The order is of course implicit in the ordering of the `stateChange` elements, but I believe that's not quite consistent with NeXML design principles (e.g. that data should be explicit, not encoded in structure)?  Happy for more feedback on this.  ",NA,NA,NA
23,31188433,cboettig,2013-12-25T00:40:52Z,2013-12-25T00:40:52Z,@rvosa did we ever resolve why the schema appears to object to arbitrary XML nodes as children to the `meta` element?  Same objections as above occur on phenoscape files for me.  ,NA,NA,NA
23,31724098,rvosa,2014-01-07T09:39:07Z,2014-01-07T09:39:07Z,I don't know how this came to be but for some reason the current version of the schema on github does not have free-form xml as a permissible value of a meta element (see: https://github.com/nexml/nexml/blob/master/xsd/meta/annotations.xsd#L70-L72). This is against the spirit of the annotation system but it's why the validations are failing.,NA,NA,NA
23,31750304,hlapp,2014-01-07T16:04:51Z,2014-01-07T16:04:51Z,"@cboettig Shouldn't it be ResourceMeta instead of LiteralMeta in your example? Does that still result in an error?

cc @balhoff - does this mean the Phenoscape NeXML files are outside the spec?

We should fix that, presumably by fixing the spec. I've filed issue nexml/nexml#9.",NA,NA,NA
23,31752594,rvosa,2014-01-07T16:27:48Z,2014-01-07T16:27:48Z,"No, literal, opaque XML is a ""resource"", AFAIK.


On Tue, Jan 7, 2014 at 5:04 PM, Hilmar Lapp <notifications@github.com>wrote:

> @cboettig <https://github.com/cboettig> Shouldn't it be ResourceMeta
> instead of LiteralMeta in your example? Does that still result in an error?
>
> cc @balhoff <https://github.com/balhoff> - does this mean the Phenoscape
> NeXML files are outside the spec?
>
> We should fix that, presumably by fixing the spec. I've filed issue
> nexml/nexml#9 <https://github.com/nexml/nexml/issues/9>.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/23#issuecomment-31750304>
> .
>



-- 

Dr. Rutger A. Vos
Bioinformaticist
Naturalis Biodiversity Center
Visiting address: Office A109, Einsteinweg 2, 2333 CC, Leiden, the
Netherlands
Mailing address: Postbus 9517, 2300 RA, Leiden, the Netherlands
http://rutgervos.blogspot.com",NA,NA,NA
23,31757466,balhoff,2014-01-07T17:16:23Z,2014-01-07T17:16:23Z,An XML literal is a literal. It should be a value inside of a LiteralMeta. @hlapp I have always thought the Phenoscape NeXML files were valid; I will look into this further.,NA,NA,NA
23,31760842,cboettig,2014-01-07T17:51:06Z,2014-01-07T17:51:06Z,"I get the same error regardless whether I use a `ResourceMeta` or `LiteralMeta`.  (I picked `LiteralMeta` based on the phenoscape example.)  Interestingly, the online validator is fine with either choice; it's my xmllint validation against http://nexml.org/2009/nexml.xsd that is failing.  



p.s. It's not obvious to me how this would be done as a `ResourceMeta`.  Just using `rel` and omitting the `href`? 

```xml
  <meta xsi:type=""ResourceMeta"" id=""m10"" rel=""eml:additionalMetadata"">
    <xhtml:div typeof=""foaf:Person"" about=""http://carlboettiger.info#me"">
    ...
```",NA,NA,NA
23,31764990,hlapp,2014-01-07T18:34:33Z,2014-01-07T18:34:33Z,@cboettig yes that's what I had in my mind but as @balhoff points out I was mistaken in that.,NA,NA,NA
23,31765106,balhoff,2014-01-07T18:35:45Z,2014-01-07T18:42:50Z,"I tested a Phenoscape file [gardiner_1984.xml](https://github.com/phenoscape/phenoscape-data/blob/master/Curation%20Files/completed-phenex-files/gardiner_1984.xml) in Oxygen, using the version of NeXML I had checked out already on my machine (I figured this is what I tested with originally). It was SVN revision 1406 from 2010-10-22. There were two issues I needed to fix for the file to validate in Oxygen. Some elements had id values beginning with a digit; I modified these to begin with a letter. I also needed to provide a schema location for PhenoXML in addition to NeXML for Oxygen to be completely happy. This makes sense I guess.

As soon as I can I will check the latest version of NeXML to see if anything is different.",NA,NA,NA
23,31777161,balhoff,2014-01-07T20:42:34Z,2014-01-07T20:42:34Z,"@cboettig I looked back at the error you reported. (""[1] ""Element '{http://www.w3.org/1999/xhtml}div': No matching global element declaration available, but demanded by the strict wildcard."") That is the same error I was getting until I provided the location of the schema for the other namespace to the validator. Can you try providing the xhtml schema to the validator? I did it via the 'xsi:schemaLocation' attribute in the doc.",NA,NA,NA
23,31778866,cboettig,2014-01-07T21:02:14Z,2014-01-07T21:02:14Z,"@balhoff Thanks, that sounds promising!  Not working for me yet; but I'm probably just getting the syntax wrong somewhere. 

Here's my whole text xml, which gives me the exact same error.  

```xml
<nex:nexml xmlns:nex=""http://www.nexml.org/2009"" 
                   xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" 
                   xmlns=""http://www.nexml.org/2009"" 
                   xmlns:foaf=""http://xmlns.com/foaf/0.1/""      
                   xmlns:eml=""eml://ecoinformatics.org/eml-2.1.1"" 
                   xmlns:xhtml=""http://www.w3.org/1999/xhtml"" 
                   version=""0.9"" generator=""RNeXML"" 
                   xsi:schemaLocation=""http://www.w3.org/1999/xhtml http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd"">
  <meta xsi:type=""LiteralMeta"" id=""m10"" property=""eml:additionalMetadata"">
    <xhtml:div typeof=""foaf:Person"" about=""http://carlboettiger.info#me"">
      <a rel=""foaf:account"" href=""https://twitter.com/cboettig"">twitter</a>
      <a rel=""foaf:account"" href=""https://github.com/cboettig"">github</a>
    </xhtml:div>
  </meta>
</nex:nexml>
```

@balhoff  Is this what you were suggesting I try? Or was I supposed to put the `xsi:schemaLocation` somewhere else? 


This raises some other questions for me that aren't connected to the validation issue directly, but still confuse me:

- How would I also have the nexml schema location specified? (Also, not clear on the syntax for `xsi:schemaLocation` -- why two links?  

- Why does nexml use `xsi:schemaLocation=""http://www.nexml.org/2009 ../xsd/nexml.xsd""` with the relative file path, etc? Why not just use `xsi:schemaLocation=""http://www.nexml.org/2009.nexml.xsd""` ?",NA,NA,NA
23,31780415,balhoff,2014-01-07T21:19:42Z,2014-01-07T21:19:42Z,"@cboettig my understanding is that within xsi:schemaLocation you have a list of alternating pairs. First a URI identifier for a namespace, then a URL for the location of the file. You can put any number of namespaces into the attribute value. So try this:

```
xsi:schemaLocation=""http://www.nexml.org/2009 ../xsd/nexml.xsd http://www.w3.org/1999/xhtml http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd"">
```",NA,NA,NA
23,31780572,balhoff,2014-01-07T21:21:22Z,2014-01-07T21:21:22Z,It seems clear that it ought to be a best practice for files that embed XML literals using foreign schemas to provide a useful value in xsi:schemaLocation for all schemas. I will try to add this to the Phenoscape data files.,NA,NA,NA
23,31781602,balhoff,2014-01-07T21:31:04Z,2014-01-07T21:31:04Z,@cboettig the relative file path you used for the nexml schema will be a local relative path on your system (at least that is the result I'm getting). You could use this URL instead: http://www.nexml.org/2009/nexml.xsd,NA,NA,NA
23,31782446,balhoff,2014-01-07T21:39:17Z,2014-01-07T21:39:17Z,"This validates in Oxygen for me:

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<nex:nexml xmlns:nex=""http://www.nexml.org/2009"" 
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" 
    xmlns=""http://www.nexml.org/2009"" 
    xmlns:foaf=""http://xmlns.com/foaf/0.1/""      
    xmlns:eml=""eml://ecoinformatics.org/eml-2.1.1"" 
    xmlns:xhtml=""http://www.w3.org/1999/xhtml"" 
    version=""0.9"" generator=""RNeXML"" 
    xsi:schemaLocation=""http://www.nexml.org/2009 http://www.nexml.org/2009/nexml.xsd http://www.w3.org/1999/xhtml http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd"">
    <meta xsi:type=""LiteralMeta"" id=""m10"" property=""eml:additionalMetadata"">
        <div xmlns=""http://www.w3.org/1999/xhtml"">
            <a rel=""foaf:account"" href=""https://twitter.com/cboettig"">twitter</a>
            <a rel=""foaf:account"" href=""https://github.com/cboettig"">github</a>
        </div>
    </meta>
</nex:nexml>
```",NA,NA,NA
23,31782684,balhoff,2014-01-07T21:41:05Z,2014-01-07T21:41:05Z,"Oh, I forgot, I had to remove ```typeof=""foaf:Person"" about=""http://carlboettiger.info#me""``` Is there an extension to XHTML that is needed?",NA,NA,NA
23,31782897,cboettig,2014-01-07T21:42:55Z,2014-01-07T21:42:55Z,"@balhoff Thanks for the explanations, that all makes sense.  

Weird, your example does not validate for me in xmllint.  

```
$ xmllint --schema http://www.nexml.org/2009/nexml.xsd baloff.xml 
```
Gives the error:

```
<?xml version=""1.0"" encoding=""UTF-8""?>
<nex:nexml xmlns:nex=""http://www.nexml.org/2009"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns=""http://www.nexml.org/2009"" xmlns:foaf=""http://xmlns.com/foaf/0.1/"" xmlns:eml=""eml://ecoinformatics.org/eml-2.1.1"" xmlns:xhtml=""http://www.w3.org/1999/xhtml"" version=""0.9"" generator=""RNeXML"" xsi:schemaLocation=""http://www.nexml.org/2009 http://www.nexml.org/2009/nexml.xsd http://www.w3.org/1999/xhtml http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd"">
    <meta xsi:type=""LiteralMeta"" id=""m10"" property=""eml:additionalMetadata"">
        <div xmlns=""http://www.w3.org/1999/xhtml"">
            <a rel=""foaf:account"" href=""https://twitter.com/cboettig"">twitter</a>
            <a rel=""foaf:account"" href=""https://github.com/cboettig"">github</a>
        </div>
    </meta>
</nex:nexml>
baloff.xml:11: element div: Schemas validity error : Element '{http://www.w3.org/1999/xhtml}div': No matching global element declaration available, but demanded by the strict wildcard.
baloff.xml fails to validate
```
",NA,NA,NA
23,31783285,balhoff,2014-01-07T21:46:14Z,2014-01-07T21:46:14Z,"I wonder if you need ```xhtml:div``` instead. I added the xmlns attribute to make the ```<a>``` tag work without a prefix, and found I could also remove the prefix from the ```div```. Can you try putting it back? I note that the root ```nexml``` element has a prefix although its children don't.",NA,NA,NA
23,31783929,cboettig,2014-01-07T21:53:40Z,2014-01-07T21:53:40Z,"Same error with `xhtml:` explicit on the `divs` (or the divs and `<a>`'s).  

Note that even without explicit `xhtml:` prefixes the validator is identifying the the right namespace for div (The error is `{http://www.w3.org/1999/xhtml}div`, whereas it incorrectly uses the nexml namespace if the xhtml prefix is omitted in my earlier version).  

As @rvosa points out, it does appear that the schema itself is saying I cannot have arbitrary annotation (https://github.com/nexml/nexml/blob/master/xsd/meta/annotations.xsd#L70-L72), so I suspect xmllint is doing the correct thing(?)  Can't explain why oxygen and the online validator don't complain though. Maybe we have different versions of the schema somehow?  ",NA,NA,NA
23,31784476,balhoff,2014-01-07T22:00:02Z,2014-01-07T22:00:02Z,"I am using the schema version at http://www.nexml.org/2009/nexml.xsd. The highlighted lines you linked to are only for ResourceMeta. LiteralMeta has:

```xml
<xs:sequence>
  <xs:any minOccurs=""0"" maxOccurs=""unbounded""/>
</xs:sequence>
```

It seems like you're getting the same error as when the schema was not provided. Could xmllint be ignoring the additional schema location?",NA,NA,NA
23,31784823,balhoff,2014-01-07T22:03:56Z,2014-01-07T22:03:56Z,"I don't think xmllint uses schemalocation, so it may be difficult to pass multiple schemas to its validator. Feature request goes back to 2004: https://bugzilla.gnome.org/show_bug.cgi?id=157205",NA,NA,NA
23,31784828,cboettig,2014-01-07T22:04:00Z,2014-01-07T22:04:00Z,"@balhoff Brilliant, yes, this just seems to be an xmllint issue all along:  http://stackoverflow.com/questions/17002324/xmllint-validate-an-xml-file-against-two-xsd-schemas-envelope-payload",NA,NA,NA
23,31786701,hlapp,2014-01-07T22:27:30Z,2014-01-07T22:27:30Z,@balhoff @cboettig **wow** I applaud you for your detective work!!,NA,NA,NA
23,31825567,rvosa,2014-01-08T11:59:41Z,2014-01-08T11:59:41Z,"Indeed, as do I.

Also, I need to correct what I said earlier: literal XML is indeed
LiteralMeta (as Jim said), not ResourceMeta.

Because of this mistake, I was looking in the wrong location in the schema
for permission to place free form XML inside a meta. This *is* allowed
(just like Oxygen says), based on this line in the schema:
https://github.com/nexml/nexml/blob/master/xsd/meta/annotations.xsd#L89 -
which is identical to the one hosted on nexml.org.",NA,NA,NA
23,31888991,cboettig,2014-01-08T23:46:27Z,2014-01-08T23:46:27Z,"Thanks everyone for helping resolve this.

I have one last related question: @balhoff 's comments suggest that arbitrary XML is only valid when I can also provide the corresponding schema in `xsi:schemaLocation`.  The online validator doesn't seem to care about this but apparently Oxygen does. Who do we believe?

I ask about this primarily because I'm writing up a little section to describe how an R user can extend NeXML when necessary using `simmap` as an example (See #48) and adding a few XML lines describing the mapping (based mostly on Mark Holder's suggestions; I certainly welcome input on the syntax I've chosen).  

Does the Oxygen complaint mean that I need to write a schema file to define my xml elements?  

I was thinking I would just write a little text file defining the handful of elements I introduce for the simmap definition, because that would be easier for me and the average R comparative methods developer than writing a schema.  I'm struggling a bit with this section because I want it to look easy (to avoid the R developer reverting to more newick hacks!) but also explicit.  

Feel free to comment on this thread or over on the simmap thread #48 ",NA,NA,NA
23,31899482,hlapp,2014-01-09T03:15:43Z,2014-01-09T03:15:43Z,"I think it's important to stress that XML schema-based documents _can_ be validated, but they don't have to be. All well-behaved readers, I think, will by default not validate (in part, for example, because that could create quite a performance hit).

To validate a strict XML schema instance, the schema _must_ obviously be provided. That doesn't mean that an instance document that doesn't, or that doesn't for all of its namespaces, is invalid.

So no, you don't have to formulate an XSD for XML embedded in NeXML. If you don't, you just _necessarily_ won't be able to validate the document. Yes, that takes away an advantage that NeXML documents would otherwise have. But there has to be some cost to not specifying which schema part of your instance document is expected to adhere to. So you can do it, at the cost of losing the ability to validate. But that doesn't mean it's invalid NeXML. (It may be; you just can't use an XML validator to find out.)

One could create a custom validator that strips out the embedded XML (which should not alter the intactness or integrity of the part defined by the NeXML XSD), and then validates the rest. If that validation passes, it still doesn't tell you though whether the original document was valid or not - it's simply impossible to know in the absence of a schema definition.",NA,NA,NA
23,31920589,rvosa,2014-01-09T11:01:32Z,2014-01-09T11:01:32Z,"Hilmar is of course right, but perhaps in the case of exemplar documents
meant to showcase that everything is copacetic you do want to specify all
available, relevant schemata.


On Thu, Jan 9, 2014 at 4:15 AM, Hilmar Lapp <notifications@github.com>wrote:

> I think it's important to stress that XML schema-based documents *can* be
> validated, but they don't have to be. All well-behaved readers, I think,
> will by default not validate (in part, for example, because that could
> create quite a performance hit).
>
> To validate a strict XML schema instance, the schema *must* obviously be
> provided. That doesn't mean that an instance document that doesn't, or that
> doesn't for all of its namespaces, is invalid.
>
> So no, you don't have to formulate an XSD for XML embedded in NeXML. If
> you don't, you just *necessarily* won't be able to validate the document.
> Yes, that takes away an advantage that NeXML documents would otherwise
> have. But there has to be some cost to not specifying which schema part of
> your instance document is expected to adhere to. So you can do it, at the
> cost of losing the ability to validate. But that doesn't mean it's invalid
> NeXML. (It may be; you just can't use an XML validator to find out.)
>
> One could create a custom validator that strips out the embedded XML
> (which should not alter the intactness or integrity of the part defined by
> the NeXML XSD), and then validates the rest. If that validation passes, it
> still doesn't tell you though whether the original document was valid or
> not - it's simply impossible to know in the absence of a schema definition.
>",NA,NA,NA
23,31960631,cboettig,2014-01-09T18:18:24Z,2014-01-09T18:18:24Z,"Thanks both for perspectives, reflects my understanding here as well.
 While I don't expect most users to validate (after all, since we're
generating nexml programmatically one will have to make some effort to mess
up the validation), but in the same vein I don't want to intentionally
produce invalid nexml when it can be avoided.

I recognize that it's probably better not to view validation as a black or
white thing anyway, after all the validator reply does say the rest of the
nexml is valid, and only the XML block lacks a definition in the schema,
which is perfectly true.  I suppose could potentially wrap a bit more
helper material around the R nexml_validate function that would make this
clear to the user.

Alternatively, I could write the extension for simmap (#48) entirely in
RDFa meta elements instead?   On one hand it is more verbose that way, but
on the other hand the R interface side can be constructed without having to
say assume the user is too familiar with XML or even RDFa, since we have
already introduced and have functions to construct meta elements....




On Thu, Jan 9, 2014 at 3:01 AM, Rutger Vos <notifications@github.com> wrote:

> Hilmar is of course right, but perhaps in the case of exemplar documents
> meant to showcase that everything is copacetic you do want to specify all
> available, relevant schemata.
>
>
> On Thu, Jan 9, 2014 at 4:15 AM, Hilmar Lapp <notifications@github.com
> >wrote:
>
> > I think it's important to stress that XML schema-based documents *can* be
>
> > validated, but they don't have to be. All well-behaved readers, I think,
> > will by default not validate (in part, for example, because that could
> > create quite a performance hit).
> >
> > To validate a strict XML schema instance, the schema *must* obviously be
>
> > provided. That doesn't mean that an instance document that doesn't, or
> that
> > doesn't for all of its namespaces, is invalid.
> >
> > So no, you don't have to formulate an XSD for XML embedded in NeXML. If
> > you don't, you just *necessarily* won't be able to validate the document.
>
> > Yes, that takes away an advantage that NeXML documents would otherwise
> > have. But there has to be some cost to not specifying which schema part
> of
> > your instance document is expected to adhere to. So you can do it, at the
> > cost of losing the ability to validate. But that doesn't mean it's
> invalid
> > NeXML. (It may be; you just can't use an XML validator to find out.)
> >
> > One could create a custom validator that strips out the embedded XML
> > (which should not alter the intactness or integrity of the part defined
> by
> > the NeXML XSD), and then validates the rest. If that validation passes,
> it
> > still doesn't tell you though whether the original document was valid or
> > not - it's simply impossible to know in the absence of a schema
> definition.
> >
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/23#issuecomment-31920589>
> .
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
23,31983691,rvosa,2014-01-09T22:25:42Z,2014-01-09T22:25:42Z,">
> Alternatively, I could write the extension for simmap (#48) entirely in
> RDFa meta elements instead? On one hand it is more verbose that way, but
> on the other hand the R interface side can be constructed without having
> to
> say assume the user is too familiar with XML or even RDFa, since we have
> already introduced and have functions to construct meta elements....


To my mind this is much better because NeXML readers are supposed to at
least be able to deal with the syntax of meta elements and somehow expose
their predicates and values in a reasonably accessible way. Or, put another
way, if you did the simmap extension in RDFa/meta I know I can access it
with object methods in java, javascript and perl (and probably python),
whereas with opaque XML I'd have to grok the element tree by hand.",NA,NA,NA
48,31992065,cboettig,2014-01-10T00:25:10Z,2014-01-10T00:26:19Z,"Given @hlapp and @rvosa's comments in issue #23, we probably want to consider using a `meta` based format to define the simmap representation.  

I think this is the straight-forward translation into RDFa meta based on the XML-based description I have above:

```xml
    <edge id=""e1"" source=""n1"" target=""n2"" length=""0.9"">
      <meta property=""simmap:reconstructions"" id = m1>
        <meta property=""simmap:reconstruction"" id = m2>
          <meta property=""nex:char"" content = ""cr1"" id = m3>
            <meta property=""simmap:stateChange"" id = m4>
              <meta property = nex:length"" content=""0.4"">   
              <meta property = ""nex:state"" content = ""s2""/>
             </meta>
           </meta>
           <meta property=""simmap:stateChange"">
             <meta property = nex:length"" content=""0.5"">
             <meta property = ""nex:state"" content = ""s1""/>
            </meta>
          </meta>
        </meta>
      </meta>
    </edge>
```
(would have ids and xsi-types on all meta elements)

Note that I've claimed that `state`, `length` and `char` properties are defined in the nexml namespace, but probably that's not kosher?  How should that be done properly?  


Naturally this extension would have to come with a definition of new terms.  If I understand correctly, while ideally that would be an OWL ontology, it would be permissible just to have a plain text definition like:

------------------------

### simmap definitions


- `simmap:reconstruction` : A mapping of a character state onto an edge of the phylogeny.  The state may change along the length of the edge, as indicated by the `stateChange` child element.  
- `simmap:stateChange`:  An element indicating the character state given by the reconstruction and the duration (length) the edge was in this state.  `stateChange` elements are given sequentially in the order or the state changes from root to tip. (Note that stochastic character mapping is not well-defined for an unrooted tree.) The sum of all lengths in a reconstruction of an edge should equal the length of the edge itself.  
-  ....

(add more text for additional attributes, explanatory diagram)


-------------------------------------

Is it poor form that I use the order of meta elements to indicate the order of the state changes?  

",NA,NA,NA
48,32324251,cboettig,2014-01-15T00:44:15Z,2014-01-15T00:44:15Z,"@hlapp @rvosa Can a `meta` element have both child nodes and a `content` value?  (e.g. my `meta property=""nex:char""` element in the RDFa version [above](https://github.com/ropensci/RNeXML/issues/48#issuecomment-31992065)?  If not, not sure how to do this to avoid re-listing the character id every time I list the state id.  ",NA,NA,NA
48,32372538,hlapp,2014-01-15T15:40:53Z,2014-01-15T15:40:53Z,"> Can a meta element have both child nodes and a content value? (e.g. my meta property=""nex:char"" element in the RDFa version above?

The schema doesn't seem to prohibit it, but [the documentation says no](https://github.com/nexml/nexml/blob/master/xsd/meta/annotations.xsd#L92-93):

>  Metadata annotations in which the object is a literal value. If the @content attribute is used,  then the element should contain no children. 

I'm not following yet why you have to have this. Can you perhaps give an example, such as what you think you'd be forced to do but don't want to?",NA,NA,NA
48,32373141,hlapp,2014-01-15T15:46:32Z,2014-01-15T15:46:32Z,"> Is it poor form that I use the order of meta elements to indicate the order of the state changes?

Yes. Wouldn't it be possible to add a `seq` or `ordering` or other property to indicate order? Or use the same mechanism that NeXML uses for ordering characters, but now that I think about it I'm not sure how it does that.",NA,NA,NA
48,32461084,rvosa,2014-01-16T11:27:11Z,2014-01-16T11:27:11Z,"Characters are sort of ordered. They have id attributes, which datum cells
then reference - so in that context they are actually unordered in the
sense that the location of the char element among its siblings is
meaningless. But, if there are no datum cells (i.e. with compact seq
elements) the convention is that the order in which tokens appear in the
seq corresponds with the order in which char elements are defined. Note
that char elements can also, optionally, have an integer attribute to
specify codon position. Maybe you can take this as precedent for an integer
property to store order?",NA,NA,NA
48,32556509,cboettig,2014-01-16T22:59:40Z,2014-01-16T22:59:40Z,"@hlapp @rvosa Thanks for the feedback.  Yeah, would like this example to be solid as possible if we're to use it as an exemplar how-to. Here's an example of the current version:  



```xml
 <edge id=""e1"" source=""n1"" target=""n2"" length=""0.9"">
      <meta property=""simmap:reconstructions"" id = ""m1"">
        <meta property=""simmap:reconstruction"" id = ""m2"">
          <meta property=""nex:char"" content = ""cr1""/>
          <meta property=""simmap:stateChange"" id = ""m4"">
            <meta property=""simmap:order"" content = ""1""/>
            <meta property = nex:length"" content=""0.4""/>   
            <meta property = ""nex:state"" content = ""s2""/>
           </meta>
           <meta property=""simmap:stateChange"">
             <meta property=""simmap:order"" content = ""2""/>
             <meta property = nex:length"" content=""0.5""/>
             <meta property = ""nex:state"" content = ""s1""/>
           </meta>
         </meta>
      </meta>
    </edge>
```
(namespace definitions, id and about tags would be added automatically too, just omitted above).  

I've explicitly added the property `simmap:order` to indicate the ordering of the state changes explicitly (and not rely on the ordering of the elements).  I've also moved the `nex:char` property to be sister rather than parent to `simmap:stateChange`.  My thinking is that `nex:char` is annotating `simmap:reconstruction`, stating that this particular reconstruction is a reconstruction of the given character.  I think this fixes most of my concerns.  I have also added code that converts this to/from the simmap format used by the `phytools` R package.  

@hlapp @rvosa one outstanding concern I have is if I'm okay using `nex:length`, `nex:char`, and `nex:state` as I do above, rather than defining new terms for these explicitly in the simmap context.  I'm not sure if they are semantically identical concepts or not, e.g. `simmap:length` is the length of time an edge spends in a particular state, while nex:length is the length of an `<edge>`.  
",NA,NA,NA
48,32612570,rvosa,2014-01-17T15:02:30Z,2014-01-17T15:02:30Z,"Would it be an idea to try to generate the output using the API for nested
semantic annotation and just look at what that looks like? I am also (as
you are) doubtful whether it is a good idea to re-use the nex:* names for
ever-so-slightly different concepts.


On Thu, Jan 16, 2014 at 11:59 PM, Carl Boettiger
<notifications@github.com>wrote:

> @hlapp <https://github.com/hlapp> @rvosa <https://github.com/rvosa>Thanks for the feedback. Yeah, would like this example to be solid as
> possible if we're to use it as an exemplar how-to. Here's an example of the
> current version:
>
>  <edge id=""e1"" source=""n1"" target=""n2"" length=""0.9"">
>       <meta property=""simmap:reconstructions"" id = ""m1"">
>         <meta property=""simmap:reconstruction"" id = ""m2"">
>
>           <meta property=""nex:char"" content = ""cr1""/>
>
>           <meta property=""simmap:stateChange"" id = ""m4"">
>
>             <meta property=""simmap:order"" content = ""1""/>
>             <meta property = nex:length"" content=""0.4""/>
>
> <meta property = ""nex:state"" content = ""s2""/>
>            </meta>
>
>            <meta property=""simmap:stateChange"">
>              <meta property=""simmap:order"" content = ""2""/>
>              <meta property = nex:length"" content=""0.5""/>
>
>              <meta property = ""nex:state"" content = ""s1""/>
>            </meta>
>          </meta>
>       </meta>
>
>     </edge>
>
> (namespace definitions, id and about tags would be added automatically
> too, just omitted above).
>
> I've explicitly added the property simmap:order to indicate the ordering
> of the state changes explicitly (and not rely on the ordering of the
> elements). I've also moved the nex:char property to be sister rather than
> parent to simmap:stateChange. My thinking is that nex:char is annotating
> simmap:reconstruction, stating that this particular reconstruction is a
> reconstruction of the given character. I think this fixes most of my
> concerns. I have also added code that converts this to/from the simmap
> format used by the phytools R package.
>
> @hlapp <https://github.com/hlapp> @rvosa <https://github.com/rvosa> one
> outstanding concern I have is if I'm okay using nex:length, nex:char, and
> nex:state as I do above, rather than defining new terms for these
> explicitly in the simmap context. I'm not sure if they are semantically
> identical concepts or not, e.g. simmap:length is the length of time an
> edge spends in a particular state, while nex:length is the length of an
> <edge>.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/48#issuecomment-32556509>
> .
>",NA,NA,NA
48,32628459,hlapp,2014-01-17T17:52:15Z,2014-01-17T17:52:15Z,"> one outstanding concern I have is if I'm okay using nex:length, nex:char, and nex:state as I do above, rather than defining new terms for these explicitly in the simmap context.

I think that's a bad idea. Not only as you see is the semantic match not clear, but there also is no nex vocabulary. It's a schema, and XML Schema per se actually don't have semantics.",NA,NA,NA
55,37054963,hlapp,2014-03-07T18:52:19Z,2014-03-07T18:52:19Z,"BioPerl supports phyloxml. I believe Biopython does too.


On Fri, Mar 7, 2014 at 1:50 PM, Carl Boettiger <notifications@github.com>wrote:

> @rvosa <https://github.com/rvosa> @hlapp <https://github.com/hlapp> Is
> there some Perl or something we could wrap to convert phyloxml into nexml,
> such that R users could read in that format as well?
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/55>
> .
>



-- 
Hilmar Lapp -:- lappland.io",NA,NA,NA
56,37081870,cboettig,2014-03-08T00:17:23Z,2014-03-08T00:17:23Z,"Done. Icon should now appear at the top of the README showing build passing. 
https://github.com/ropensci/RNeXML",NA,NA,NA
56,37082103,karthik,2014-03-08T00:22:32Z,2014-03-08T00:22:32Z,and so it does!,NA,NA,NA
56,37082218,cboettig,2014-03-08T00:25:12Z,2014-03-08T00:25:12Z,Thanks @karthik and @sckott for getting me going with the travis integration!,NA,NA,NA
55,37082404,cboettig,2014-03-08T00:29:00Z,2014-03-08T00:29:00Z,"Nice, I [see in biophylo](http://biopython.org/wiki/Phylo#convert.28.29) that something like 

```python
from Bio import Phylo
Phylo.convert('example.xml', 'phyloxml', 'example2.xml', 'nexml')
```

should work.  I can't find a mention of ""phyloxml"" in `perldoc Bio::Phylo::Manual` though.  Not sure if the wrapper approach is good here, since either of these might be large dependencies to add whole-cloth.  
",NA,NA,NA
55,37082617,hlapp,2014-03-08T00:34:11Z,2014-03-08T00:34:11Z,"Bio::Phylo::Manual may be from Bio::Phylo, a separate CPAN package?

Indeed though, the dependencies would be significant. The arguments to
writing your own NeXML parser should largely also apply to whether or not
you want to write your own PhyloXML parser.

-- 
Hilmar Lapp -:- lappland.io",NA,NA,NA
57,37156580,craigcitro,2014-03-10T06:38:38Z,2014-03-10T06:38:38Z,"ok, i ended up making two more cleanups:

* added back `rjava` so that `rrdf` could install `;)`
* moved the `apt` dependencies into one `install_aptget` call, and stripped some repetitive ones.",NA,NA,NA
55,37159163,rvosa,2014-03-10T07:48:30Z,2014-03-10T07:48:30Z,"Bio::Phylo is a bit more extensive in how it captures phyloxml-specific
annotations and converts them to ""RDFa"" (and back), but as Hilmar says: the
same considerations w.r.t. introducing dependencies should hold. Maybe
there should be a conversion web service, like the one that converts NEXUS
to NeXML?


On Sat, Mar 8, 2014 at 1:34 AM, Hilmar Lapp <notifications@github.com>wrote:

> Bio::Phylo::Manual may be from Bio::Phylo, a separate CPAN package?
>
> Indeed though, the dependencies would be significant. The arguments to
> writing your own NeXML parser should largely also apply to whether or not
> you want to write your own PhyloXML parser.
>
>
> --
> Hilmar Lapp -:- lappland.io
>
> --
>
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/55#issuecomment-37082617>
> .
>
>",NA,NA,NA
55,37196567,cboettig,2014-03-10T15:42:28Z,2014-03-10T15:42:28Z,"Web service we could then query from R sounds ideal to me. Heavy users
would probably want to install bio::python but I imagine this would be
convenient for the once off case of the typical R user.

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Mar 10, 2014 12:48 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> Bio::Phylo is a bit more extensive in how it captures phyloxml-specific
> annotations and converts them to ""RDFa"" (and back), but as Hilmar says: the
> same considerations w.r.t. introducing dependencies should hold. Maybe
> there should be a conversion web service, like the one that converts NEXUS
> to NeXML?
>
>
> On Sat, Mar 8, 2014 at 1:34 AM, Hilmar Lapp <notifications@github.com
> >wrote:
>
> > Bio::Phylo::Manual may be from Bio::Phylo, a separate CPAN package?
> >
> > Indeed though, the dependencies would be significant. The arguments to
> > writing your own NeXML parser should largely also apply to whether or not
> > you want to write your own PhyloXML parser.
> >
> >
> > --
> > Hilmar Lapp -:- lappland.io
> >
> > --
> >
> > Reply to this email directly or view it on GitHub<
> https://github.com/ropensci/RNeXML/issues/55#issuecomment-37082617>
> > .
> >
> >
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/55#issuecomment-37159163>
> .
>",NA,NA,NA
55,37632748,rvosa,2014-03-14T10:11:26Z,2014-03-14T10:11:26Z,"At the upcoming hackathon I am planning to work on a data conversion /
merging / splitting / annotation web service that should be able to e.g.
provide phyloxml as nexml (and vice versa).


On Mon, Mar 10, 2014 at 4:42 PM, Carl Boettiger <notifications@github.com>wrote:

> Web service we could then query from R sounds ideal to me. Heavy users
> would probably want to install bio::python but I imagine this would be
> convenient for the once off case of the typical R user.
>
> ---
> Carl Boettiger
> http://carlboettiger.info
>
> sent from mobile device; my apologies for any terseness or typos
>
> On Mar 10, 2014 12:48 AM, ""Rutger Vos"" <notifications@github.com> wrote:
>
> > Bio::Phylo is a bit more extensive in how it captures phyloxml-specific
> > annotations and converts them to ""RDFa"" (and back), but as Hilmar says:
> the
> > same considerations w.r.t. introducing dependencies should hold. Maybe
> > there should be a conversion web service, like the one that converts
> NEXUS
> > to NeXML?
> >
> >
> > On Sat, Mar 8, 2014 at 1:34 AM, Hilmar Lapp <notifications@github.com
> > >wrote:
> >
> > > Bio::Phylo::Manual may be from Bio::Phylo, a separate CPAN package?
> > >
> > > Indeed though, the dependencies would be significant. The arguments to
> > > writing your own NeXML parser should largely also apply to whether or
> not
> > > you want to write your own PhyloXML parser.
> > >
> > >
> > > --
> > > Hilmar Lapp -:- lappland.io
> > >
> > > --
>
> > >
> > > Reply to this email directly or view it on GitHub<
> > https://github.com/ropensci/RNeXML/issues/55#issuecomment-37082617>
> > > .
> > >
> > >
> >
> > --
> > Reply to this email directly or view it on GitHub<
> https://github.com/ropensci/RNeXML/issues/55#issuecomment-37159163>
>
> > .
> >
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/55#issuecomment-37196567>
> .
>",NA,NA,NA
55,37671232,cboettig,2014-03-14T17:03:36Z,2014-03-14T17:03:36Z,"awesome


On Fri, Mar 14, 2014 at 3:11 AM, Rutger Vos <notifications@github.com>wrote:

> At the upcoming hackathon I am planning to work on a data conversion /
> merging / splitting / annotation web service that should be able to e.g.
> provide phyloxml as nexml (and vice versa).
>
>
> On Mon, Mar 10, 2014 at 4:42 PM, Carl Boettiger <notifications@github.com
> >wrote:
>
>
> > Web service we could then query from R sounds ideal to me. Heavy users
> > would probably want to install bio::python but I imagine this would be
> > convenient for the once off case of the typical R user.
> >
> > ---
> > Carl Boettiger
> > http://carlboettiger.info
> >
> > sent from mobile device; my apologies for any terseness or typos
> >
> > On Mar 10, 2014 12:48 AM, ""Rutger Vos"" <notifications@github.com> wrote:
> >
> > > Bio::Phylo is a bit more extensive in how it captures phyloxml-specific
> > > annotations and converts them to ""RDFa"" (and back), but as Hilmar says:
> > the
> > > same considerations w.r.t. introducing dependencies should hold. Maybe
> > > there should be a conversion web service, like the one that converts
> > NEXUS
> > > to NeXML?
> > >
> > >
> > > On Sat, Mar 8, 2014 at 1:34 AM, Hilmar Lapp <notifications@github.com
> > > >wrote:
> > >
> > > > Bio::Phylo::Manual may be from Bio::Phylo, a separate CPAN package?
> > > >
> > > > Indeed though, the dependencies would be significant. The arguments
> to
> > > > writing your own NeXML parser should largely also apply to whether or
> > not
> > > > you want to write your own PhyloXML parser.
> > > >
> > > >
> > > > --
> > > > Hilmar Lapp -:- lappland.io
> > > >
> > > > --
> >
> > > >
> > > > Reply to this email directly or view it on GitHub<
> > > https://github.com/ropensci/RNeXML/issues/55#issuecomment-37082617>
> > > > .
> > > >
> > > >
> > >
> > > --
> > > Reply to this email directly or view it on GitHub<
> > https://github.com/ropensci/RNeXML/issues/55#issuecomment-37159163>
> >
> > > .
> > >
> >
> > --
> > Reply to this email directly or view it on GitHub<
> https://github.com/ropensci/RNeXML/issues/55#issuecomment-37196567>
>
> > .
> >
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/55#issuecomment-37632748>
> .
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
58,37688422,karthik,2014-03-14T19:53:03Z,2014-03-14T19:53:03Z,"@cboettig Quick note, you can turn off builds on branches so it doesn't constantly fail when you are just experimenting. Easy to turn back on from the dashboard too. It will still build on PRs",NA,NA,NA
59,37883474,sckott,2014-03-17T23:24:32Z,2014-03-17T23:24:32Z,"I forget, can we POST/PUT to Treebase and/or Dryad?  As other options to publish to. 

Ideally have a local failover though in case no internet connection/figshare is down, etc. ",NA,NA,NA
59,37883817,cboettig,2014-03-17T23:30:20Z,2014-03-17T23:30:20Z,"Yeah, meant to comment on that.  It would be great if TreeBase took NeXML submissions, but it doesn't seem to at this time.  Likewise it would be great if Dryad supported the DataONE submission API that we already use to submit EML to the KNB, but again, that's not yet available.  Hence for the moment I'm using figshare as the example. At the moment figshare's download function will only work for published documents.  

Good point about the offline thing, there are certainly plenty of use-cases where a local file is preferable in the script.  Perhaps just a relative path would be best, and then distribute the data and code together (instead of relative paths that don't correspond to the data directory provided, like we saw in https://github.com/ropensci/rgbif_mcglinn/blob/master/dryad_climate/GBIF_run_all.R) ",NA,NA,NA
58,37890123,sckott,2014-03-18T01:10:54Z,2014-03-18T01:10:54Z,working on now @cboettig ,NA,NA,NA
59,37909366,rvosa,2014-03-18T08:34:49Z,2014-03-18T08:34:49Z,"We've made an effort during a GSoC project to enable uploading NeXML to
TreeBASE but it is far from trivial to embed all the hoops a proper
TreeBASE submission has to jump through into the document, and to then read
that and insert into the database. Unfortunately.


On Tue, Mar 18, 2014 at 12:30 AM, Carl Boettiger
<notifications@github.com>wrote:

> Yeah, meant to comment on that. It would be great if TreeBase took NeXML
> submissions, but it doesn't seem to at this time. Likewise it would be
> great if Dryad supported the DataONE submission API that we already use to
> submit EML to the KNB, but again, that's not yet available. Hence for the
> moment I'm using figshare as the example. At the moment figshare's download
> function will only work for published documents.
>
> Good point about the offline thing, there are certainly plenty of
> use-cases where a local file is preferable in the script. Perhaps just a
> relative path would be best, and then distribute the data and code together
> (instead of relative paths that don't correspond to the data directory
> provided, like we saw in
> https://github.com/ropensci/rgbif_mcglinn/blob/master/dryad_climate/GBIF_run_all.R)
>
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/59#issuecomment-37883817>
> .
>",NA,NA,NA
61,37957460,craigcitro,2014-03-18T16:52:56Z,2014-03-18T16:52:56Z,"yes, that's pretty strange -- at least on my machine, `apt-cache` tells me that `libgdal1-dev` depends on `libgdal-dev`, so should pick up that dependency by default.

maybe my change was overzealous? if you add that dependency back, do things start working again? (i'll try and roll a patch to test, but that probably won't happen until tonight.)",NA,NA,NA
62,37961785,cboettig,2014-03-18T17:24:55Z,2014-03-18T17:24:55Z,"@sckott Nice. Yeah, I think this workflow will work well for now.  I'll keep doing my edits on devel for the time being, and leave you to merge them to mscomm?  I can do a bit more flushing out of the text and examples before you need bother with it again anyway.  ",NA,NA,NA
62,37961846,sckott,2014-03-18T17:25:24Z,2014-03-18T17:25:24Z,"@cboettig Okay, cool. Sounds good",NA,NA,NA
61,37964620,cboettig,2014-03-18T17:46:56Z,2014-03-18T17:46:56Z,"@craigcitro Thanks for the reply; yeah, pretty weird.  If I add the dependency for libgdal-dev explicitly, it just gets upset about another dependency [log](https://travis-ci.org/ropensci/RNeXML/builds/21032851),

```
The following packages have unmet dependencies:
 libgdal-dev : Depends: libhdf5-serial-dev
```

Doesn't make any sense to me.  apt-get should resolve all the dependencies automatically unless they can't be satisfied, which clearly isn't the case.  (I also tried explicitly using apt-get call instead of the `./travis-tool.sh` call in [this attempt](https://travis-ci.org/ropensci/RNeXML/builds/21034151) and I get the same error.)

@craigcitro  I think I'm stumped, but would greatly appreciate any hints you have whenever you get around to it. Much appreciated!",NA,NA,NA
55,37988722,rvosa,2014-03-18T21:09:36Z,2014-03-18T21:09:36Z,We are working on this right now: https://github.com/naturalis/biovel-nbc,NA,NA,NA
61,38020378,craigcitro,2014-03-19T06:00:36Z,2014-03-19T06:00:36Z,"well, it looks like we aren't the [only folks hitting this](http://askubuntu.com/questions/206593/how-to-install-rgdal-on-ubuntu-12-10); looks like the root cause is a nasty problem with dependencies on specific versions of packages. i'm gonna fork and play around for a few minutes, see what i find ...",NA,NA,NA
61,38025335,craigcitro,2014-03-19T07:54:14Z,2014-03-19T07:54:14Z,"ok, so i understand what's going on here. the issue is that `netcdf-bin` wants `libhdf5-1.8.4`, but `gdal-bin` needs `libhdf5-dev`. trying to force both of them to install at once confuses the bejeepers out of `apt`, which makes sense. instead, i'm trying to split them up and do it in stages; i'm making progress, hopefully i'll send a PR shortly.

that said, i still have no idea what any of this code is actually doing -- if `netcdf-bin` has any libraries you're using, they may get confused when someone's dropped a new version of the hdf5 headers in under their nose. ",NA,NA,NA
61,38032230,craigcitro,2014-03-19T09:41:20Z,2014-03-19T09:41:20Z,"ahh, i love bugs like this: after quite a bit of fiddling, it turns out that the right fix was to **undo** part of my previous change. `:)` i'm not 100% clear on the details, but it looks like when we pick up the extra apt repo in `bootstrap`, we suddenly see some new-and-conflicting versions of some of the `gdal`-related dependencies. 

playing with installation order might work, but i realized that the smarter move was to just undo that: i moved *most* packages back before the `bootstrap` call, and then [everything works](https://travis-ci.org/craigcitro/RNeXML/builds/21082121).

PR coming shortly.

(as a side note, it might be worth installing `igraph` as a binary package, since it seems to eat a big chunk of the runtime.)

there are still some mysteries: for instance, why did this suddenly start failing a few days ago? my guess is that the PPA we get some packages from got updated around then, but i'm not sure.",NA,NA,NA
61,38069415,cboettig,2014-03-19T16:05:06Z,2014-03-19T16:05:06Z,Thanks for the PR and the explanations above.  What distro/version is Travis using for Linux anyhow?,NA,NA,NA
61,38073636,craigcitro,2014-03-19T16:33:04Z,2014-03-19T16:33:04Z,"http://docs.travis-ci.com/user/ci-environment/

they're on ubuntu 12.04 (precise).",NA,NA,NA
59,38341110,hlapp,2014-03-22T02:51:13Z,2014-03-22T03:12:25Z,"Dryad will support a [SWORD API](http://swordapp.org/) in the near future.
 However, you'll still need to have a publication to which the tree belongs.

-- 
Hilmar Lapp -:- lappland.io",NA,NA,NA
59,38341160,hlapp,2014-03-22T02:54:27Z,2014-03-22T02:54:27Z,"On Mon, Mar 17, 2014 at 7:19 PM, Carl Boettiger <notifications@github.com>wrote:

> Rather than loading the data from some local file, a researcher could then
> always work from the deposited copy in their own scripts, ensuring that the
> data is not lost and that future users can run the script without getting
> some error about a local file not being found
>
If that's your main use-case, wouldn't a Github / Bitbucket API be much
more useful then?

-- 
Hilmar Lapp -:- lappland.io",NA,NA,NA
59,38341175,cboettig,2014-03-22T02:55:38Z,2014-03-22T02:55:38Z,"very cool.  No problem, that makes sense.


On Fri, Mar 21, 2014 at 7:51 PM, Hilmar Lapp <notifications@github.com>wrote:

> Dryad will support a [SWORD API](http://swordapp.org/) in the near future.
> However, you'll still need to have a publication to which the tree belongs.
>
> --
> Hilmar Lapp -:- lappland.io
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/59#issuecomment-38341110>
> .
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
59,38341252,cboettig,2014-03-22T02:59:51Z,2014-03-22T02:59:51Z,"> If that's your main use-case, wouldn't a Github / Bitbucket API be much
more useful then?

I guess it depends how seriously we take the word ""ensuring"" and ""future users"".  Sure, Github is probably more reliable than a local copy, but probably less reliable than a CLOCKSS-backed repository with a DOI (e.g. figshare, Dryad).  

Good point though, I clearly need to be more specific about the usecase.  Discoverability would be another advantage.  ",NA,NA,NA
59,38341371,cboettig,2014-03-22T03:07:25Z,2014-03-22T03:07:25Z,I suppose we could add github as an additional option to the `repo` argument.  Though I guess that doesn't really need a function wrapper since there's neither any metadata entry or authentication step to perform.   @karthik would that be a task for git2r or just use a `system()` call?,NA,NA,NA
59,38341391,sckott,2014-03-22T03:08:33Z,2014-03-22T03:08:33Z,seems more likely a job for @cscheid 's rgithub since it'd be using the Github api,NA,NA,NA
33,38341438,sckott,2014-03-22T03:10:23Z,2014-03-22T03:10:23Z,Did you ever write a post @rvosa ?,NA,NA,NA
59,38341477,karthik,2014-03-22T03:12:34Z,2014-03-22T03:13:40Z,"@cboettig Would be really easy to do using git2r. Right now I have  a function called `markdown_link()`

```coffee
> library(git2r)
> markdown_link()
[1] ""[ecf853](https://github.com/ropensci/ecoengine.git/commit/ecf85379442cd87ba908465d1540763fefe3160d)""
```

but really just

```
git2r::head(repo)@hex
```

will grab the latest commit hash. But as @sckott says, if you know the repo will reside on GitHub (not always the case), then `rgithub` approach would be better.",NA,NA,NA
59,38341614,cboettig,2014-03-22T03:19:31Z,2014-03-22T03:19:31Z,"Um, I don't think github's API (and hence  @cscheid 's rgithub) includes actual git commands like git commit?  I think it just does the things that you can do on Github's web client, like create issues or view commits?  Maybe I'm just missing things here. 

Does git2r wrap commands like `git commit` in a more stable way than a system call?  Being repo agnostic would obviously be good.  ",NA,NA,NA
59,38341662,sckott,2014-03-22T03:21:49Z,2014-03-22T03:21:49Z,Does anyone know if Open Tree of Life will be accepting trees? In NeXML format hopefully? @kcranston ,NA,NA,NA
59,38341684,karthik,2014-03-22T03:23:14Z,2014-03-22T03:23:23Z,"> Does git2r wrap commands like git commit in a more stable way than a system call? Being repo agnostic would obviously be good.

Yes. It's definitely more stable than a system call. ",NA,NA,NA
24,38341791,sckott,2014-03-22T03:30:21Z,2014-03-22T03:30:21Z,@cboettig Where are we at on taxonomic ID integration?  Any more to be done? I assume so if the issue is still open. Anything to be done on the `taxize` side so that it integrates better here?,NA,NA,NA
24,38341908,cboettig,2014-03-22T03:38:03Z,2014-03-22T03:38:03Z,"It's in there, but just with the minimal annotation to the identifier (like TreeBASE nexml does, not the full provenance).  

Try: 

```coffee
library(RNeXML)
data(bird.orders)
birds <- add_trees(bird.orders)
birds <- taxize_nexml(birds, ""NCBI"")
nexml_write(birds, ""birds.xml"")
```

Some draft text now appears at the end of this section: https://github.com/ropensci/RNeXML/blob/devel/inst/doc/pubs/manuscript.md#writing-nexml-metadata",NA,NA,NA
24,38342028,cboettig,2014-03-22T03:45:16Z,2014-03-22T03:45:16Z,"@sckott It would be a good next step if `taxize_nexml` could provide other identifiers if a researcher wanted to indicate that their taxonomy conventions corresponded with an alternative authority than NCBI.  Also not sure what the correct error-handling behavior should be if no match is found for a given taxon label.  Perhaps just a warning, since it might not be an error?  An interactive prompt to try and correct the name might be overkill, particularly since the user would still have to decide if they wanted to change the original source of the name (e.g. the `phylo` object's tip names in the example above).  And we need to add a test-case to check that we actually are giving a warning when the function doesn't get a match.  ",NA,NA,NA
24,38342121,sckott,2014-03-22T03:50:40Z,2014-03-22T03:50:40Z,"@cboettig Thanks, will have a look. 

I don't the best answer off the top for the correct error handling in the RNeXML context. Will have a think about it.",NA,NA,NA
59,38350409,kcranston,2014-03-22T12:37:25Z,2014-03-22T12:37:25Z,Yes! We already do import of NeXML from TreeBASE through the UI. The APIs are under heavy development at the moment - see python library https://github.com/OpenTreeOfLife/peyotl as a starting point. @sckott ,NA,NA,NA
59,38354023,sckott,2014-03-22T15:14:21Z,2014-03-22T15:14:21Z,"Cool, thanks @kcranston . I like the library name :) Seems like something we can count on building in then. ",NA,NA,NA
24,38354225,sckott,2014-03-22T15:22:17Z,2014-03-22T16:11:42Z,"@cboettig  Some questions/thoughts:

* Would it make sense to have an option that is simply the use defines the names as conforming to e.g., NCBI's taxonomy, but they don't call out to get IDs so they end up with something like 

```xml
<meta xsi:type=""nex:ResourceMeta"" id=""m3"" source=""NCBI"" rel=""tc:toTaxon""/>
```

* An option to collect taxon ID's separately using `taxize` or some other route, then passing those in, e.g matching by taxon name
* Does it make sense that a user may follow different taxonomies for different taxa in the tree. e.g., follow NCBI for animals, but Tropicos for plants
* Do we want to also put in the taxon Identifier in addition to the URL? Like

```xml
<meta xsi:type=""nex:ResourceMeta"" id=""m3"" taxonid=""56308"" href=""http://ncbi.nlm.nih.gov/taxonomy/56308"" rel=""tc:toTaxon""/>
```
* Good idea about the warning - I'll write a test.",NA,NA,NA
24,38360255,cboettig,2014-03-22T18:34:52Z,2014-03-22T18:34:52Z,"@sckott Note that `meta` elements have to follow RDFa structure, so that you either have a `LiteralMeta` (like an html `<meta>` tag) that has attributes `property` and `content` (or child nodes in place of content), or a `ResourceMeta` that describes a link, with attributes `rel` and `href` (along with attributes like `id` referring to the id of the meta node itself, etc, see `?meta`.  (and `property` and `rel` terms must be appropriately namespaced).  

I've started describing this in the manuscript, but not sure how much detail to go into (e.g. detail about NeXML and RDFa that are documented elsewhere, vs detail about RNeXML) so feedback to that end would be great.  

Yeah, selecting taxon IDs separately and drawing from a mix of authorities for taxonomic annotation makes sense to me; though I'd appreciate perspective from @hlapp on all this.  ",NA,NA,NA
64,38360479,cboettig,2014-03-22T18:44:46Z,2014-03-22T18:44:46Z,"@sckott We can already grab the contents of all meta elements annotating otu elements with `get_meta(nexml, level=""otu"")`, though it is slow (because it serializes to XML and uses XPath instead of sapplys to get the items, kinda silly), and it doesn't return the meta S4 objects, but just extracts their values.  So the `get_metadata` function could be much improved, but I'm hesitant to add separate functions to the namespace for every possible level.  I've already added the higher-level one-stop-shop function for accessing elements, `nexml_get`, which wraps the other methods like `get_metadata`, `get_trees`, etc; the thought being you could refer to the documentation of `nexml_get` to see all the various access methods.  

I'm always undecided about when adding more to the namespace (convenience functions, aliases etc) makes the package easier or harder to use, so feedback is appreciated.  In the manuscript I try and walk through the ""hierarchy"" of methods for both accessing and writing elements, particularly meta elements, which goes from the very automatic higher-level stuff like `nexml_taxize` and `add_basic_meta` down to the lowest level of almost direct construction of the S4 class.  Again, not sure if I hit the right balance between flexible/powerful and simple/easy-to-use, so critique is welcome (either of the text or of the functions).  

Um, can you also take a look at `check()` locally on the devel branch and tell me what you get?  With travis I'm stuck on this `system.file` error it seems.  ",NA,NA,NA
64,38360871,sckott,2014-03-22T19:00:23Z,2014-03-22T19:00:23Z,"I understand. Okay If we close this pull, and I edit the test file using the existing functions, remove the new fxns I made, and send that back up as a PR?",NA,NA,NA
64,38360885,sckott,2014-03-22T19:00:49Z,2014-03-22T19:00:49Z,I think there is a good balance between flexibility and ease of use,NA,NA,NA
64,38361418,cboettig,2014-03-22T19:22:37Z,2014-03-22T19:22:37Z,"Sounds good, though we may want to keep your get metadata code as a backend
so maybe just leave it as an non-exported fn for now?

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Mar 22, 2014 12:00 PM, ""Scott Chamberlain"" <notifications@github.com>
wrote:

> I think there is a good balance between flexibility and ease of use
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/pull/64#issuecomment-38360885>
> .
>",NA,NA,NA
64,38361930,sckott,2014-03-22T19:40:32Z,2014-03-22T19:40:32Z,Okay,NA,NA,NA
33,38434108,rvosa,2014-03-24T11:33:34Z,2014-03-24T11:33:34Z,"Not yet! Are you at a stage where a code vignette would be reasonably
stable, API-wise?


On Sat, Mar 22, 2014 at 4:10 AM, Scott Chamberlain <notifications@github.com
> wrote:

> Did you ever write a post @rvosa <https://github.com/rvosa> ?
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/33#issuecomment-38341438>
> .
>",NA,NA,NA
33,38467394,cboettig,2014-03-24T16:37:36Z,2014-03-24T16:37:36Z,"@rvosa good question.  I believe the API for all functions shown in the README.md is stable, though it might be good to do a code review first (something we'd at least like to do before submitting to CRAN), to make sure that naming conventions and function calls are consistent and reasonably intuitive.  

- [ ] Consistent naming patterns for functions (add_trees, add_characters, get_trees, get_characters)
- [ ] Consistent naming patterns for function arguments, in consistent order (e.g. is the nexml object always called 'nexml', is it always the second argument in an add_* function, etc)
- [ ] Consistent terminology: e.g. I have the function `add_basic_meta` but also `get_metadata`.  Maybe `get_meta` would be more appropriate?
- [ ] Aliases to functions where it is helpful but not overboard.  For instance, I've called it `nexml_read` (along with the other functions I view as top-level API: `nexml_write`, `nexml_publish`, `nexml_validate`, `nexml_add`, and `nexml_get`), but I've also aliased it as read.nexml since most users will be familiar with `read.tree`, `read.nexus` from `ape` and `read.csv` etc in base R (the latter being a strange convention to me because it looks like R's S3 mechanism but isn't. )
- [ ] Other feedback.  

So comments on these things would be great.  


Obviously it would be ideal to be on CRAN for the blog post, to ease installation.  `devtools::install_github` makes it pretty easy though, but I need to deal with the build_failing case, which is just do to the new nexml_publish function having some upstream issues.  (An update to the third-party package `httr` broke my rfigshare package, and I haven't quite finished getting the new version stable again (won't change the rfigshare API and will make it more streamlined to authenticate).  
",NA,NA,NA
48,38509874,cboettig,2014-03-24T22:32:48Z,2014-03-24T22:32:48Z,"Okay, I've implemented my go at writing a simmap extension to NeXML along the lines we describe in this thread as an illustration of how `RNeXML` users can use the package to construct such extensions (rather than continuing to hack Newick formats as illustrated at the top of this thread).  Could really use some critique from @rvosa and @hlapp on my stab at this, particularly with regards to defining a `simmap` namespace.  I'm hoping to create an example to be something other users could reasonably
do themselves without expertise in RDFa or XML, but also to be a good model case that doesn't cut corners. 

You can see my attempt at explaining this implementation in this section of the manuscript: https://github.com/ropensci/RNeXML/blob/devel/inst/doc/pubs/manuscript.md#extending-the-nexml-standard-through-metadata-annotation  

Obviously in addition to refining the implementation, it would be good to improve the explanation as well.  (Overall not sure how much of that I will have space for in the manuscript body and what will be left to a supplement, vignette, and/or blog post, but for now not worrying about space.)   @sckott would be great to get your feedback on this as well from the practical R perspective more than the valid nexml perspective.  
",NA,NA,NA
48,38541396,rvosa,2014-03-25T08:48:00Z,2014-03-25T08:48:00Z,"I had a look at it and I think it's pretty good. I find the syntax (line
730...) palatable enough, in any case. As regards telling people to create
something at a URL that the namespace points to and defining their
predicates there: that's nice advice (though technically nothing will break
if they don't do that). Doing it in plain text is probably the best we can
expect, people certainly aren't going to fire up protege to define a couple
of predicates in their own research.


On Mon, Mar 24, 2014 at 11:32 PM, Carl Boettiger
<notifications@github.com>wrote:

> Okay, I've implemented my go at writing a simmap extension to NeXML along
> the lines we describe in this thread as an illustration of how RNeXMLusers can use the package to construct such extensions (rather than
> continuing to hack Newick formats as illustrated at the top of this
> thread). Could really use some critique from @rvosa<https://github.com/rvosa>and
> @hlapp <https://github.com/hlapp> on my stab at this, particularly with
> regards to defining a simmap namespace. I'm hoping to create an example
> to be something other users could reasonably
> do themselves without expertise in RDFa or XML, but also to be a good
> model case that doesn't cut corners.
>
> You can see my attempt at explaining this implementation in this section
> of the manuscript:
> https://github.com/ropensci/RNeXML/blob/devel/inst/doc/pubs/manuscript.md#extending-the-nexml-standard-through-metadata-annotation
>
> Obviously in addition to refining the implementation, it would be good to
> improve the explanation as well. (Overall not sure how much of that I will
> have space for in the manuscript body and what will be left to a
> supplement, vignette, and/or blog post, but for now not worrying about
> space.) @sckott <https://github.com/sckott> would be great to get your
> feedback on this as well from the practical R perspective more than the
> valid nexml perspective.
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/48#issuecomment-38509874>
> .
>",NA,NA,NA
24,38594105,cboettig,2014-03-25T17:21:46Z,2014-03-25T17:21:46Z,"@sckott: @rvosa raises a good question. What happens if `get_uid` hits multiple matches? How should we handle this?  Wanna take a crack at this and add a test case for it?

You'll see the function currently just grabs the id returned and throws a warning if it is an na, and otherwise tries to paste it into the metadata:

https://github.com/ropensci/RNeXML/blob/95ff1e9543418a0f15aa93e2fc59ea481323fee0/R/taxize_nexml.R#L17 

Feel free to edit the function to do something more intuitive.  @rvosa may have some suggestions.  ",NA,NA,NA
58,38598896,cboettig,2014-03-25T18:00:10Z,2014-03-25T18:00:10Z,"@rvosa Thanks for the edits and comments on the manuscript file.  Just a quick note: **you should edit manuscript.Rmd in future**; manuscript.md is generated automatically from that file by actually running the embedded code (dynamic documentation style, thanks to [knitr](http://yihui.name/knitr)).  I integrated your changes and rerun `make manuscript.md`.  Note we also have a `make manuscript.pdf` option which uses a latex template.  

I've added a few notes about this setup in the manuscript section of [CONTRIBUTING.md](https://github.com/ropensci/RNeXML/blob/devel/CONTRIBUTING.md#manuscript) in case it's helpful.  ",NA,NA,NA
48,38599502,cboettig,2014-03-25T18:04:38Z,2014-03-25T18:04:38Z,"@rvosa Cool, thanks for the feedback.  We'll probably need to keep working on the manuscript discussion of this as we get down the road. As it sounds like we have at least some acceptable basics for a simmap extension, I think I'll close this issue for now, but feel free to re-open.",NA,NA,NA
59,38599897,cboettig,2014-03-25T18:07:58Z,2014-03-25T18:07:58Z,"Cool. Well we have a basic example of publishing to figshare as a way to illustrate quickly getting a DOI, clockss archiving, and discoverability in a central database.  

Obviously it would be nice to have the ability to submit to Dryad for trees that accompany published papers, as well as other relevant repositories, though presumably that will all wait on us getting the corresponding API wrappers implemented in other packages anyhow.  We can open separate issues for each.  Meanwhile we have the proof of principle so I think we can close this one.  ",NA,NA,NA
20,38600550,cboettig,2014-03-25T18:13:17Z,2014-03-25T18:13:17Z,"Lots of good discussion in this thread.  I've done my best at implementing a kind of tiered approach for creating and editing metadata, going from assuming the user knows nothing about namespaces up through adding their own namespaces or parsing metadata with `XPath` and `SPARQL` queries.  Really not sure that my explanations are meaningful though, so would love feedback on both the [Writing metadata](https://github.com/ropensci/RNeXML/blob/devel/inst/doc/pubs/manuscript.Rmd#L332) and [Reading metadata](https://github.com/ropensci/RNeXML/blob/devel/inst/doc/pubs/manuscript.Rmd#L539) section of the manuscript before closing this.    I've put ""Writing"" section before the ""Reading"" section; not sure if that's the easiest order or not. ",NA,NA,NA
58,38605482,rvosa,2014-03-25T18:53:41Z,2014-03-25T18:53:41Z,"Oh, sorry! Did I screw that up? Ok, edit the .Rmd. Got it.


On Tue, Mar 25, 2014 at 7:00 PM, Carl Boettiger <notifications@github.com>wrote:

> @rvosa <https://github.com/rvosa> Thanks for the edits and comments on
> the manuscript file. Just a quick note: *you should edit manuscript.Rmd
> in future*; manuscript.md is generated automatically from that file by
> actually running the embedded code (dynamic documentation style, thanks to
> knitr <http://yihui.name/knitr>). I integrated your changes and rerun make
> manuscript.md. Note we also have a make manuscript.pdf option which uses
> a latex template.
>
> I've added a few notes about this setup in the manuscript section of
> CONTRIBUTING.md<https://github.com/ropensci/RNeXML/blob/devel/CONTRIBUTING.md#manuscript>in case it's helpful.
>
> --
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/58#issuecomment-38598896>
> .
>",NA,NA,NA
15,38626489,cboettig,2014-03-25T21:59:20Z,2014-03-25T21:59:20Z,We now have `<characters>` implemented and a full test suite.  ,NA,NA,NA
44,38626722,cboettig,2014-03-25T22:01:43Z,2014-03-25T22:01:43Z,"Think we're good here. Still need implementation for the rest of MIAPA ontology, #46 ",NA,NA,NA
26,38627567,cboettig,2014-03-25T22:09:26Z,2014-03-25T22:09:26Z,"Looks like the primary remaining issues here are to:

- flush out tools for easily expressing more the MIAPA ontology, now in #46 

and issues for the MIAPA ontology itself:

- https://github.com/miapa/miapa/issues/21
- https://github.com/miapa/miapa/issues/20
- https://github.com/miapa/miapa/issues/19",NA,NA,NA
46,38627611,cboettig,2014-03-25T22:09:54Z,2014-03-25T22:09:54Z,"Also see 

- https://github.com/miapa/miapa/issues/21
- https://github.com/miapa/miapa/issues/20
- https://github.com/miapa/miapa/issues/19",NA,NA,NA
24,38628041,cboettig,2014-03-25T22:14:07Z,2014-03-25T22:14:07Z,"Okay, since we can now add TSNs from species names using taxize, as this issue stipluates, I think I can close this thread.  

Further work improving this feature, such as 

- taxize tool error handling, 
- taxize tool user interface (interactive prompts), 
- handling alternative authority sources other than NCBI, and 
- capturing provenance  

should be listed under additional issues so they can be organized into appropriate milestones.  ",NA,NA,NA
24,38628535,sckott,2014-03-25T22:19:18Z,2014-03-25T22:19:18Z,"Sorry, a bit late to reply.  Yes, I'll have a look at the no match found problem. 

@cboettig Do you prefer those 4 issues you mentioned in one issue (since they are related) or each in separate issues (since they could be solved at different times I guess)  What milestone did you have in mind for these taxize issues? or a new one?",NA,NA,NA
24,38629356,cboettig,2014-03-25T22:27:52Z,2014-03-25T22:27:52Z,"@sckott No preference, either one issue or multiple is fine.  

Yeah, either long-term milestone or some new milestone since I don't think they are critical to the [CRAN release](https://github.com/ropensci/RNeXML/issues?milestone=4&state=open) (these additions shouldn't break the current API I think) and we probably won't have space to discuss them in the manuscript.  (see [Current Milestones](https://github.com/ropensci/RNeXML/issues/milestones))",NA,NA,NA
24,39491505,sckott,2014-04-03T19:04:15Z,2014-04-03T19:04:15Z,"Okay, these moved to the [Long Term objectives milestone](https://github.com/ropensci/RNeXML/issues?milestone=2&state=open)",NA,NA,NA
58,41548491,rvosa,2014-04-28T11:38:10Z,2014-04-28T11:38:10Z,"Hi guys,

I made some small edits in manuscript.Rmd on the dev branch, mostly just to test the water and make sure I am working on the right file. Do you guys have some sort of current status and planning in your head? I.e. if you are planning to submit this somewhere, what still needs to be done, and how can I help?

Thanks,

Rutger",NA,NA,NA
58,41580241,cboettig,2014-04-28T16:29:00Z,2014-04-28T16:29:00Z,"Thanks @rvosa !  Yup, that's the right file (devel branch); looks good.

I'm thinking an applications note to Methods in Ecology and Evolution and thinking we can submit sometime this summer, though I'm open to suggestions of other venues, particularly since you and @hlapp have more experience with this.  

Also not sure if length constraints might play a role in our choice of venue?  While I'm sure we could tighten up the text and examples, it would be nice to have some of the richer ones like the simmap extension and rdfa extraction where more people will see them.  I believe MEE applications notes are pretty short.  

I think we have most of the features I'd marked for inclusion in the manuscript and first CRAN release milestones, see https://github.com/ropensci/RNeXML/issues/milestones   

- [ ] First off, it would be great to get your thumbs up/down on the examples that we've included. Can they be understood, have I messed up any of my explanations (particularly on semantics and namespace stuff), do I say too much that could just be cited or too little?  Any examples you would drop? Any you'd like to see added?  

- [ ] Once we're happy with the examples we include (and thus know the scope of the work), we still need an introduction and discussion/conclusion that helps set up the larger context for why this is important.  I've started this but have been meaning to get back to it soon.  A list of bullet points, citations or whatnot that you want to see in those sections would be great.  If you want to take a stab at some prose, that would be even better.  

If you have suggestions for other journals and how we might want to structure the piece differently for them, I'd love to hear that too.  ",NA,NA,NA
58,41650535,rvosa,2014-04-29T08:02:32Z,2014-04-29T08:02:32Z,"I think MEE would be the perfect venue, and looking at the application notes that they publish it ought to be fairly straightforward to get the MS into that shape. The limit is 3000 words though, which indeed is a bit of a challenge. Would you consider relegating some/most of the examples to supplementary material?

Meanwhile, I'm trying to go through the MS, wanting to see it in pdf or markdown, but the make targets seem to be failing for me. If I do 'make manuscript.pdf' it fails like this:

<pre>
Quitting from lines 74-82 (manuscript.Rmd) 
Error in auto_exts[x] : invalid subscript type 'closure'
Calls: knit ... process_group.block -> call_block -> block_exec -> dev2ext

Execution halted
make: *** [manuscript.pdf] Error 1
</pre>

While 'make manuscript.md' fails thusly:

<pre>
output file: manuscript.md

[1] ""manuscript.md""
sed -i 's/```r/```coffee/' manuscript.md
sed: 1: ""manuscript.md"": invalid command code m
make: *** [manuscript.md] Error 1
</pre>

Sorry I can't figure this out for myself - what am I doing wrong?",NA,NA,NA
58,41701027,sckott,2014-04-29T16:46:18Z,2014-04-29T16:46:18Z,"@cboettig Would we be sure to get OA in MEE?  I thought one of your papers in there was supposed to be, but turned out not to be for some reason? Or maybe OA isn't important to others?

A more software focused OA journal could work, but I guess the audience would be likely to see it in MEE. 

I'll take a look at the examples. ",NA,NA,NA
58,41702575,cboettig,2014-04-29T16:58:38Z,2014-04-29T16:58:38Z,"Applications notes are open access (well, actually the publisher's copy is
just ""free"" as in beer, though the author can archive their own copy as we
did under CC0 as a vignette in the package itself).  Yes, there was some
confusion when our treebase paper first came out but they fixed that.

@rvosa taking a look now.  Can you go into R and try
knit(""manuscript.Rmd"")? If that fails, send me the output of
`sessionInfo()` from the R command line. In particular let me know what
version of knitr you have.

The manuscript.md make target is just switching the markdown language
encoding for Github, because somehow Github broke it's own R syntax
highlighter and so we tend to highlight as coffeescript.  Stupid hack.
 Anyway, the ""sed in place"" option, -i, is apparently a Linux-only
argument. Would probably be reasonable to use an Rscript for that simple
regex instead of sed and thus hopefully be more platform-independent.

Sorry about the cross-platform portability of this workflow, it's not
something I've had the opportunity to test outside of my own development
environment (well, and now travis).  You'll need pandoc 1.12 installed too.
Advice on how to do this better is always appreciated, particularly with
the various different environments (R, pandoc, sed, etc).




On Tue, Apr 29, 2014 at 9:46 AM, Scott Chamberlain <notifications@github.com
> wrote:

> @cboettig <https://github.com/cboettig> Would we be sure to get OA in
> MEE? I thought one of your papers in there was supposed to be, but turned
> out not to be for some reason? Or maybe OA isn't important to others?
>
> A more software focused OA journal could work, but I guess the audience
> would be likely to see it in MEE.
>
> I'll take a look at the examples.
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/58#issuecomment-41701027>
> .
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
58,41738943,hlapp,2014-04-29T22:13:56Z,2014-04-29T22:13:56Z,"OA is certainly very important to me. MEE is a hybrid journal, so you need to pay for the OA option, but it does have one (at least it did 2 years ago when coauthored an article there).

-hilmar

Sent with a tap.

On Apr 29, 2014, at 12:46 PM, Scott Chamberlain <notifications@github.com> wrote:

> @cboettig Would we be sure to get OA in MEE? I thought one of your papers in there was supposed to be, but turned out not to be for some reason? Or maybe OA isn't important to others?
> 
> A more software focused OA journal could work, but I guess the audience would be likely to see it in MEE.
> 
> I'll take a look at the examples.
> 
> —
> Reply to this email directly or view it on GitHub.",NA,NA,NA
58,42089062,cboettig,2014-05-02T23:32:46Z,2014-05-02T23:32:46Z,"@rvosa Sorry about the build issue -- by default `Rscript` doesn't load the `methods` package even though base R does.  Anyway I've fixed this in the new Makefile.  

I've moved the manuscript from `inst/doc/pubs` directory to the more semantically obvious `manuscripts` directory in the repo's root.  I've also tried to make it a bit more tidy, and added caching (see the README in manuscripts/, which now is actually a readme about making the manuscripts, rather than just a result of building the package README).  

",NA,NA,NA
70,42667002,cboettig,2014-05-09T13:45:32Z,2014-05-09T13:45:32Z,"I'll take a look.  Can you send me the output of sessionInfo()

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On May 9, 2014 6:42 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> I get this, not sure how to proceed:
>
> Error in setClass(""Base"", slots = c(xsi:type = ""character"")) :
> unused argument(s) (slots = c(xsi:type = ""character""))
> Error : unable to load R code in package 'RNeXML'
> ERROR: lazy loading failed for package 'RNeXML'
>
>    - removing
>    '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/RNeXML'
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/70>
> .
>",NA,NA,NA
70,42667136,cboettig,2014-05-09T13:46:41Z,2014-05-09T13:46:41Z,"Oh, you might also try upgrading to R >= 3.0.  Haven't tested on 2.15
recently...

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On May 9, 2014 6:45 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote:

> I'll take a look.  Can you send me the output of sessionInfo()
>
> ---
> Carl Boettiger
> http://carlboettiger.info
>
> sent from mobile device; my apologies for any terseness or typos
> On May 9, 2014 6:42 AM, ""Rutger Vos"" <notifications@github.com> wrote:
>
>> I get this, not sure how to proceed:
>>
>> Error in setClass(""Base"", slots = c(xsi:type = ""character"")) :
>> unused argument(s) (slots = c(xsi:type = ""character""))
>> Error : unable to load R code in package 'RNeXML'
>> ERROR: lazy loading failed for package 'RNeXML'
>>
>>    - removing
>>    '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/RNeXML'
>>
>> —
>> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/70>
>> .
>>
>",NA,NA,NA
70,42667137,rvosa,2014-05-09T13:46:42Z,2014-05-09T13:46:42Z,"<pre>
> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] devtools_1.1 geiger_2.0.1 ape_3.0-8   

loaded via a namespace (and not attached):
 [1] MASS_7.3-23      RCurl_1.95-4.1   Rcpp_0.10.3      coda_0.16-1     
 [5] deSolve_1.10-4   digest_0.6.3     evaluate_0.5.1   grid_2.15.2     
 [9] httr_0.2         lattice_0.20-15  memoise_0.1      mvtnorm_0.9-9997
[13] nlme_3.1-108     parallel_2.15.2  stringr_0.6.2    subplex_1.1-3   
[17] tcltk_2.15.2     tools_2.15.2     whisker_0.1     
</pre>",NA,NA,NA
70,42667227,rvosa,2014-05-09T13:47:36Z,2014-05-09T13:47:36Z,"Ok, I will upgrade to a less ancient version. Sorry about that. I will close this.",NA,NA,NA
58,42674629,rvosa,2014-05-09T14:52:01Z,2014-05-09T14:52:01Z,"@cboettig - I got a PDF out of it, so that's pretty cool. I have some trouble sorting out all the dependencies, though. I have worked through the following:

RNeXML => requires taxize => requires rgbif => requires rgdal.

rgdal fails (I can't get the underlying gdal to compile on OSX). Is this actually necessary?",NA,NA,NA
58,42675229,cboettig,2014-05-09T14:57:11Z,2014-05-09T14:57:11Z,"Huh, I thought the CRAN mac binary for taxize would take care of that.
@sckott any ideas here?  Does taxize really need rgdal or could it be made
an optional extension?
---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On May 9, 2014 7:52 AM, ""Rutger Vos"" <notifications@github.com> wrote:

> @cboettig <https://github.com/cboettig> - I got a PDF out of it, so
> that's pretty cool. I have some trouble sorting out all the dependencies,
> though. I have worked through the following:
>
> RNeXML => requires taxize => requires rgbif => requires rgdal.
>
> rgdal fails (I can't get the underlying gdal to compile on OSX). Is this
> actually necessary?
>
> —
> Reply to this email directly or view it on GitHub<https://github.com/ropensci/RNeXML/issues/58#issuecomment-42674629>
> .
>",NA,NA,NA
58,42677638,rvosa,2014-05-09T15:18:04Z,2014-05-09T15:18:04Z,"Some sort of frankenstein approach seems to have worked, carry on.",NA,NA,NA
58,42678281,sckott,2014-05-09T15:23:56Z,2014-05-09T15:23:56Z,"@cboettig Yeah, I don't like the situation with GDAL.  Taking a look at `taxize`, I think I actually moved any `rgbif` functions I needed into `taxize`, renaming them, so I don't think rgbif if required anymore. I'll make sure that's true, and if so, github version I think should soon not require GDAL. ",NA,NA,NA
58,42678919,rvosa,2014-05-09T15:29:23Z,2014-05-09T15:29:23Z,I'm now working through the examples in the manuscript. I must admit I hadn't actually done that yet. I must say I'm very impressed.,NA,NA,NA
58,42680736,sckott,2014-05-09T15:45:40Z,2014-05-09T15:45:40Z,"Agreed, nice work @cboettig !",NA,NA,NA
58,42688729,cboettig,2014-05-09T16:58:03Z,2014-05-09T16:58:03Z,"@rvosa @sckott Thanks!  

I've just added explicit version numbers for all the dependencies and suggests (and for `R (>= 0.3.0)` as well).  Some may be more aggressive than necessary, but at least all are on CRAN and better safe than sorry.  I've just run check and pushed this to devel, hopefully doesn't cause any problems.  ",NA,NA,NA
58,46474204,cboettig,2014-06-18T18:25:33Z,2014-06-18T18:25:33Z,"Hi @rvosa @hlapp ,

I flushed out a bit more of the manuscript introduction, but it could definitely benefit from your input. Finding it hard to strike the right balance of providing enough context (e.g. existing tech, existing data) to motivate the need and potential for RNeXML while remaining concise.  You've both done this well in other papers and could probably add some more citations to fill in the picture as well.  

Other than that, I feel we're getting close to having something to submit.  A few specific things I'd like feedback on: 

- [ ] The tutorial section is probably a bit too long; but I think I'm not impartial enough to make good decisions on what should be moved to the appendix (or left to other documentation).  While we had ideas for yet more ambitious examples of metadata (mipa etc) I think the current ones are complex enough (happy to be convinced otherwise!)  

- [ ] The tutorial part tries to provide basic background about namespaces and RDFa.  Please let me know if that section is either too long-winded or too technical.  

Hopefully you can both compile the manuscript from scratch without too much trouble.  See directions here: https://github.com/ropensci/RNeXML/tree/devel/manuscripts (will be easier when my dynamic citations package is on CRAN, or if we just didn't use dynamic citations ;-).   Feedback/bug reports on the process welcome! RStudio is integrating Pandoc in it's next release; and I have high hopes for this lowering the barriers for other users to successfully compile dynamic documents like ours without having to know makefiles and handle lots of custom installation stuff.  (No doubt I'm overly optimistic in that, as usual).  

Anyway, do let me know when you have a chance to read over the text and examples. I know you both have plenty of other demands on your time; but hoping we can submit something before summer is out? Sound good?
",NA,NA,NA
68,46733764,cboettig,2014-06-20T22:35:37Z,2014-06-20T22:35:37Z,"Was thinking along the lines of the provenance discussion on issue #24, eg https://github.com/ropensci/RNeXML/issues/24#issuecomment-26551613

or more specifically, one of the three options I outlined here: https://github.com/ropensci/RNeXML/issues/24#issuecomment-26611912",NA,NA,NA
72,46816636,rvosa,2014-06-23T08:13:09Z,2014-06-23T08:13:09Z,"(I'm only quiet because I don't have the experience to assess whether something is a ""good"" CRAN package.)",NA,NA,NA
58,46819352,rvosa,2014-06-23T08:47:17Z,2014-06-23T08:47:17Z,"- I think the tutorial section shouldn't be getting longer. I think readers simply need to see an example of adding and retrieving annotations (in addition to basic reading/writing/traversing NeXML data) but specific use cases (miapa and such) are probably out of scope.

- I'm afraid a bit of an introduction into namespaces and RDFa is necessary or people will miss the point either by not seeing how powerful it could be, or by doing it wrong (say, no prefixes) resulting in invalid NeXML out in the wild. So that should stay in.

- Things about the implementation of RNeXML (e.g. unit testing, S4 objects) should probably go into supplementary materials. Users don't necessarily need to know this.

I am having problems compiling the PDF again, though, so I haven't seen the MS in its full glory. I still have all the dependencies installed from previous attempts and I updated RStudio so I have the ""Knit PDF"" button, but I'm getting:

`Error in cite_options(citation_format = ""pandoc"", check.entries = FALSE) : 
  unused arguments (citation_format = ""pandoc"", check.entries = FALSE)
Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval -> cite_options`

As a suggestion for the section about data archiving, perhaps we can also cite Stolzfus et al.  (2012):
http://www.biomedcentral.com/1756-0500/5/574",NA,NA,NA
58,46861322,cboettig,2014-06-23T15:35:26Z,2014-06-23T15:35:26Z,"@rvosa thanks for the feedback, sorry about introducing new build problems.
 Looks like you might have an old version of knitcitations.

devtools::install_github(""cboettig/knitcitations"")

first and try the knit PDF button again?  Sorry about that.


On Mon, Jun 23, 2014 at 1:47 AM, Rutger Vos <notifications@github.com>
wrote:

>
>    -
>
>    I think the tutorial section shouldn't be getting longer. I think
>    readers simply need to see an example of adding and retrieving annotations
>    (in addition to basic reading/writing/traversing NeXML data) but specific
>    use cases (miapa and such) are probably out of scope.
>    -
>
>    I'm afraid a bit of an introduction into namespaces and RDFa is
>    necessary or people will miss the point either by not seeing how powerful
>    it could be, or by doing it wrong (say, no prefixes) resulting in invalid
>    NeXML out in the wild. So that should stay in.
>    -
>
>    Things about the implementation of RNeXML (e.g. unit testing, S4
>    objects) should probably go into supplementary materials. Users don't
>    necessarily need to know this.
>
> I am having problems compiling the PDF again, though, so I haven't seen
> the MS in its full glory. I still have all the dependencies installed from
> previous attempts and I updated RStudio so I have the ""Knit PDF"" button,
> but I'm getting:
>
> Error in cite_options(citation_format = ""pandoc"", check.entries = FALSE) :
> unused arguments (citation_format = ""pandoc"", check.entries = FALSE)
> Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval
> -> cite_options
>
> As a suggestion for the section about data archiving, perhaps we can also
> cite Stolzfus et al. (2012):
> http://www.biomedcentral.com/1756-0500/5/574
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/58#issuecomment-46819352>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
68,46868837,sckott,2014-06-23T16:33:48Z,2014-06-23T16:33:48Z,"I did recently add in a URI, your `Option 1` here https://github.com/ropensci/RNeXML/issues/24#issuecomment-26611912 , e.g., 

```r
get_colid(sciname='Puma concolor')
```

```r
[1] ""6862841""
attr(,""class"")
[1] ""colid""
attr(,""uri"")
[1] ""http://www.catalogueoflife.org/col/details/species/id/6862841""
```

So the URI can be extracted if you want. 

In your `Option 2` you suggested ""further annotation"".  We can get more detailed information from most taxon data providers, e.g, .from ITIS

```r
id <- get_tsn('Puma concolor')
itis_getrecord(id)
```

Result is a very long list, so I put it in a gist here: https://gist.github.com/sckott/3bceb87d46c13c6f93a3

Lots of info there. We could pull in some info that is deemed important, but not to the extend of your `Option 3`",NA,NA,NA
68,46871145,cboettig,2014-06-23T16:53:01Z,2014-06-23T16:53:01Z,"nice!


On Mon, Jun 23, 2014 at 9:33 AM, Scott Chamberlain <notifications@github.com
> wrote:

> I did recently add in a URI, your Option 1 here #24 (comment)
> <https://github.com/ropensci/RNeXML/issues/24#issuecomment-26611912> ,
> e.g.,
>
> get_colid(sciname='Puma concolor')
>
> [1] ""6862841""attr(,""class"")[1] ""colid""attr(,""uri"")[1] ""http://www.catalogueoflife.org/col/details/species/id/6862841""
>
> So the URI can be extracted if you want.
>
> In your Option 2 you suggested ""further annotation"". We can get more
> detailed information from most taxon data providers, e.g, .from ITIS
>
> id <- get_tsn('Puma concolor')
> itis_getrecord(id)
>
> Result is a very long list, so I put it in a gist here:
> https://gist.github.com/sckott/3bceb87d46c13c6f93a3
>
> Lots of info there. We could pull in some info that is deemed important,
> but not to the extend of your Option 3
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/68#issuecomment-46868837>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
68,46942367,rvosa,2014-06-24T08:00:36Z,2014-06-24T08:00:36Z,As an aside: in TreeBASE we use the NCBI taxon IDs via the UniProt resolver because it returns RDF. I'm not super happy about this because NCBI (now) have quite nice stable URIs but they don't return RDF.,NA,NA,NA
58,46942477,rvosa,2014-06-24T08:01:50Z,2014-06-24T08:01:50Z,"Cool, that worked. Sorry about being such a n00b.",NA,NA,NA
58,47209404,rvosa,2014-06-26T10:16:38Z,2014-06-26T10:16:38Z,"I went over the manuscript a couple of times, making small corrections as I went through it (side note: I'm being very granular with my commits, mostly so that they make sense in ""blame"" view. Is that a way of working you're happy with?). Generally speaking I think it's starting to take shape quite well. There's a couple of things that do need some re-organizing, I think, though I didn't feel that I should go in and do drastic stuff without some consensus:

* ""Understanding the nexml S4 object"": I think these are implementation details (with the '@' vs the '$' and so on) that should be moved to supplementary materials.
* ""Implementation, architecture and quality control"": I think the section about quality control on RNeXML itself should go to supplementary materials. I see what you're trying to do here and I'm also a big fan of unit testing and continuous integration, but I think it's not something that the MEE readership needs to hear about in this MS.
* Querying RDF: the idea behind RDF isn't that of a structured data format, but of a data model. The fact that RDF/XML (as opposed to turtle, n3, and so on) can be queried with XPath is incidental and not something that should be encouraged. It would be better to jump straight into SPARQL and give an example of a more powerful query, e.g. including a join of some kind. ",NA,NA,NA
73,47703641,cboettig,2014-07-01T20:06:29Z,2014-07-01T20:06:29Z,"A meaningful SPARQL example would be great.  Your proposed use case does sound like a common one that many researchers could relate to.  My only thought is that most R users would be more familiar with simply importing the tree and trait data, etc, and then extracting the union (the `treedata()` function from the `geiger` package being probably the most common way users handle this, though the function assumes perfectly matching species names being used on both tree and trait data).  

I was wondering if we might have an example that emphasizes the logical reasoning of SPARQL that doesn't have an immediate SQL-like analog.  For instance, a query that makes use of some ontology in identifying which species listed in the target dataset are a member of the queried taxonomic class or something (e.g. see our earlier thread: https://github.com/ropensci/RNeXML/issues/20#issuecomment-29642194 ).  Maybe that would be involved in the use case you already described.  

Will give a thought to some good published data examples.  ",NA,NA,NA
58,47704169,cboettig,2014-07-01T20:11:37Z,2014-07-01T20:11:37Z,"@rvosa Thanks much!

Granular commits sounds good, feel free to push your edits to the devel branch.  

Yeah, great points on re-organizing (will help shorten the manuscript too) and the RDF.  Feel free to edit directly (dropping the xpath example and moving those other details to a supplement) or open up another issue for that and I'll get to it when I return from travels.  Thanks again!",NA,NA,NA
73,47801030,rvosa,2014-07-02T16:41:15Z,2014-07-02T16:41:15Z,"Reasoning would be really great but might be hard to demonstrate - do you
know of any reasoning engines that are exposed to R?


On Tue, Jul 1, 2014 at 10:06 PM, Carl Boettiger <notifications@github.com>
wrote:

> A meaningful SPARQL example would be great. Your proposed use case does
> sound like a common one that many researchers could relate to. My only
> thought is that most R users would be more familiar with simply importing
> the tree and trait data, etc, and then extracting the union (the
> treedata() function from the geiger package being probably the most
> common way users handle this, though the function assumes perfectly
> matching species names being used on both tree and trait data).
>
> I was wondering if we might have an example that emphasizes the logical
> reasoning of SPARQL that doesn't have an immediate SQL-like analog. For
> instance, a query that makes use of some ontology in identifying which
> species listed in the target dataset are a member of the queried taxonomic
> class or something (e.g. see our earlier thread: #20 (comment)
> <https://github.com/ropensci/RNeXML/issues/20#issuecomment-29642194> ).
> Maybe that would be involved in the use case you already described.
>
> Will give a thought to some good published data examples.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/73#issuecomment-47703641>.
>",NA,NA,NA
73,48044110,rvosa,2014-07-04T13:32:40Z,2014-07-04T13:32:40Z,"With commit a7c8ffd I have added some example data which I believe might be interesting to demonstrate (recursive?) SPARQL queries. 

The NeXML file `primates.xml` contains a supertree of the Primates. The `otus` block contains both the terminal taxa and the higher taxa (genus through order). The nodes in the tree link to these taxa, so interior nodes may also have `otu` attributes that correspond with taxa (provided the tree makes these taxa monophyletic). 

The general idea is that we should be able to query for all the members of a higher taxon - so given the URI of the higher taxon, give me all the direct descendants that specify `rdfs:subClassOf` for that taxon. Secondly, it might be nice to then be able to extract the subtree for those taxa (and plot it?), or show recursive calls to traverse the taxonomy.

Unfortunately, there appear to be some bugs in how the RDF is extracted. In particular, the namespace prefixes are not extracted correctly in the file `primates_meta.xml`.

What we should be getting is:

 `xmlns:concept=""http://rs.tdwg.org/ontology/voc/TaxonConcept#""`
 `<concept:toTaxon rdf:resource=""http://ncbi.nlm.nih.gov/taxonomy/34827""/>`

But instead we are getting:

 `xmlns:ns1=""concept:""`
`ns1:rank rdf:resource=""http://rs.tdwg.org/ontology/voc/TaxonRank#Species""/>`

I gather that this RDF is obtained by posting the NeXML to a web service, so its output is out of our control. I would like to suggest an alternative that could build on commit e3845d6. In that commit I have added an XSL stylesheet that extracts RDF/XML from RDFa. The output it produces is valid, and we should be able to run it locally, probably with better performance. However, this means we would create a dependency on a library that can process XSL stylesheets, such as this one: http://www.omegahat.org/Sxslt/",NA,NA,NA
73,48049022,rvosa,2014-07-04T14:18:58Z,2014-07-04T14:18:58Z,"With commit d61a0c5 I have added an example that shows how we can query the valid RDF/XML that the XSL stylesheet produces. The example shows how you can fetch the taxon whose taxonomic rank is ""Order"", and return the corresponding NCBI taxon URI. Subsequently, with that URI, the example shows how to fetch its children. 

A person that actually knows R (so, not me ;-)) would be able to take these examples to write a simple recursive traversal from the root to the tips. As the URIs of the subjects in this graph are constructed from the `id` attributes in the input NeXML it ought to be possible to get the taxa and tree nodes that correspond with these RDF subjects, e.g. to extract subtrees and plot them.",NA,NA,NA
73,48058379,rvosa,2014-07-04T16:02:50Z,2014-07-04T16:02:50Z,"I played around with sparql.R a bit more. It is failing, but I hope someone will be able to get the recursion to work so it generates a newick string which we then plot. Bonus points if the newick string can have the taxon names from the original NeXML.",NA,NA,NA
73,48113444,cboettig,2014-07-06T14:42:05Z,2014-07-06T14:42:05Z,"Very cool!!  Look forward to digging in to your example when I'm back.

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Jul 4, 2014 5:02 PM, ""Rutger Vos"" <notifications@github.com> wrote:

> I played around with sparql.R a bit more. It is failing, but I hope
> someone will be able to get the recursion to work so it generates a newick
> string which we then plot. Bonus points if the newick string can have the
> taxon names from the original NeXML.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/73#issuecomment-48058379>.
>",NA,NA,NA
73,48175776,rvosa,2014-07-07T13:11:05Z,2014-07-07T13:11:05Z,"As of 81da59b, the RDF/XML taxonomy is traversed by recursive SPARQL queries, whose results are serialized to a Newick string with unbranched interior nodes, no branch lengths, and (optionally) interior node labels. In other words: it's a classification tree, which can be plotted as a cladogram, as the example shows. I think this would be a pretty neat use case for the supplementary materials: it's a bit too long (72 lines) to put in the MS body. To clean this up I am going to need a little more help, still:

* update `get_rdf` to use the XSL stylesheet instead of the web service
* make my code idiomatic R that plays nice with the rest of the package (coding style, relative paths etc.)",NA,NA,NA
58,48177214,rvosa,2014-07-07T13:24:53Z,2014-07-07T13:24:53Z,"As per the progress recorded in issue #73 there is now a working example of RDF traversal using recursive SPARQL queries (as of 81da59b). The example is a bit long, so this too should be a supplementary thing, though we could refer to it in the main MS, I guess. As far as I'm concerned, reworking the MS to move this, the S4 section, and some of the QC section to supplementary materials is roughly what still needs to happen and then we might be ready to try a first submission.",NA,NA,NA
51,48178815,rvosa,2014-07-07T13:38:56Z,2014-07-07T13:38:56Z,"I'm guess the right way to do this might be to store a mapping from namespace URIs to prefixes, so that you can then figure out which string is masquerading for ""nex:"" at the scope in the DOM tree where you're unpacking an xsi:type statement. To be honest, though, I strongly suspect all other NeXML parsers (Java/Python/Ruby/Perl) are being equally trusting and just have ""nex:"" hardcoded in there - so it's probably not a showstopper for the manuscript.",NA,NA,NA
51,48205335,hlapp,2014-07-07T16:53:08Z,2014-07-09T18:22:19Z,"I think relying on a hardcoded convention for how to name the prefix is a bad idea. Why not just split on colon, raise error if namespace not defined, and expand with namespace otherwise.

I.e., in the example, the type to be output or queried in conditionals should not be `nex:LiteralMeta` but `http://www.nexml.org/2009/LiteralMeta`. Otherwise, we aren't even using XML and XSD.",NA,NA,NA
51,48497831,cboettig,2014-07-09T16:21:05Z,2014-07-09T16:21:05Z,"@hlapp @rvosa Thanks for revisiting this issue. I did talk to @duncantl a while back about this. My recollection was that there's not an automatic way to handle namespaced attribute values, though Duncan suggested it would be relatively straight forward to have a function recursively expand namespaces based on their definitions using standard XML R functions (Duncan, did I get that correct? Were you thinking of adding a helper function for that purpose?)  

Meanwhile, @hlapp's solution sounds perfect to me. ",NA,NA,NA
73,48520927,cboettig,2014-07-09T19:14:32Z,2014-07-17T19:52:26Z,"Very nice.  I've just updated `get_rdf`, and will:

- [x] take a go over the code idioms to make the example a bit more native.  
- [x] I will also add this to the manuscript appendix (referencing appropriately from the SPARQL section).  
- [x] Then I can move the sparql.R into a demos/ directory (which is the usual place for such things in R packages; allowing them to be run interactively from the command line. inst/examples is a more generic dumping ground for things that aren't necessarily R scripts.)  

",NA,NA,NA
73,48525867,rvosa,2014-07-09T19:55:23Z,2014-07-09T19:55:23Z,"Excellent! Sorry I don't know the conventions (yet), but it's fun to learn
them.


On Wed, Jul 9, 2014 at 9:14 PM, Carl Boettiger <notifications@github.com>
wrote:

> Very nice. I've just updated get_rdf, and will:
>
>    -  take a go over the code idioms to make the example a bit more
>    native.
>     -  I will also add this to the manuscript appendix (referencing
>    appropriately from the SPARQL section).
>     -  Then I can move the sparql.R into a demos/ directory (which is the
>    usual place for such things in R packages; allowing them to be run
>    interactively from the command line. inst/examples is a more generic
>    dumping ground for things that aren't necessarily R scripts.)
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/73#issuecomment-48520927>.
>",NA,NA,NA
74,49336805,cboettig,2014-07-17T17:20:10Z,2014-07-17T17:20:10Z,"Done (In intro, next to Drew et al citation.  Perhaps a discussion of particular 10 practices would be nice, but space is limited so maybe for a blog post instead). ",NA,NA,NA
69,49364370,cboettig,2014-07-17T20:55:51Z,2014-07-17T20:55:51Z,"We don't want to bother building the pdfs though, since that means installing a ton of latex libraries for every travis check.  We avoid that by keeping BOOTSTRAP_LATEX off and not building the manual, but still building the vignettes:

```
env:
 global:
   - R_BUILD_ARGS=""--no-manual""
   - R_CHECK_ARGS=""--as-cran --no-manual""
   - BOOTSTRAP_LATEX=""""
```",NA,NA,NA
73,49371846,cboettig,2014-07-17T21:53:26Z,2014-07-17T21:53:26Z,"@rvosa I was just thinking about trying to make the figure generated by `sparql.R` a bit easier to read but am running into trouble.  My first thought was to plot just the internal node names (higher taxa levels), which would mean fewer labels crowding the plot and also make it clear that the cladogram just reflected the taxonomy.  

I followed the suggestion in your code about adding get_name(id) to the `recurse` function definition so I have a Newick tree with internal nodes labeled, but that seems to be giving me a Newick tree that I cannot parse for some reason. Maybe you can have a quick look?  Thanks much!",NA,NA,NA
73,49372893,cboettig,2014-07-17T22:03:43Z,2014-07-17T22:03:43Z,"@rvosa For quick reference, here's the Newick file I get when trying to add the node labels; not sure why it fails to parse (either using phylobase::readNewick, which uses the nexus class library, or using phytools::read.newick): https://github.com/ropensci/RNeXML/blob/96add29b379748a6dae302c483e6bbaf25297a7e/inst/examples/sparql.newick ",NA,NA,NA
72,49376979,cboettig,2014-07-17T22:52:41Z,2014-07-17T22:52:52Z,"On CRAN now. Just for the record involved just a few challenges: 

- handling the `Sxslt` dependency from omegahat (Added to SUGGESTS with `Additional_respository: http://www.omegahat.org/R` in Description and now good to go)
- Had to deal with a `no visible binding` NOTE from a call to `plyr::arrange`.  CRAN suggests using `utils::globalVariables` which Hadley decries as a ""hideous hack"" . SO has more suggestions (mostly hacks): http://stackoverflow.com/questions/9439256 I just went with NULLing and a note in the code.  Some CRAN maintainers just ignore these issues and let it go.  
- figshare publishing function could fail to authenticate from CRAN on one of the checks.  Though spurious, I've added additional error handling so this returns more information about what's wrong with the connection as a warning, and doesn't cause the test suite to trigger a fail.  

A few changes have been made since that submission further improving on the documentation, but will wait a bit for other bug reports before submitting an update to CRAN.  Meanwhile, we're on CRAN now!  Binaries should be built by tomorrow. http://cran.r-project.org/web/packages/RNeXML/

I'm curious if `install.packages(""RNeXML"", dependencies=c(""DEPENDS"", ""IMPORTS"", ""SUGGESTS""))` works or fails for people (i.e. if R is smart enough to install Sxslt using the `Additional_repositories` url...)  (Note that it may take a bit before the package propagates to the CRAN mirrors).  ",NA,NA,NA
58,49377763,cboettig,2014-07-17T23:03:36Z,2014-07-17T23:03:36Z,"@rvosa @hlapp @sckott Can you each let me know if you need anything added to the acknowledgements section (e.g. funders)?  https://github.com/ropensci/RNeXML/blob/master/manuscripts/manuscript.Rmd#L940
Can you also just double check that your affiliations are correct at the top of the document?

Other than polishing up the sparql example in the supplement (issue #73) I think I'm just waiting on the feedback or thumbs up from @sckott and @hlapp before we hazard a first submission (no rush though, just keeping things moving).  ",NA,NA,NA
58,49436160,sckott,2014-07-18T14:22:56Z,2014-07-18T14:22:56Z,"Looks good @cboettig I need to change affiliation from simon fraser to simply rOpenSci https://github.com/ropensci/RNeXML/blob/master/manuscripts/manuscript.Rmd#L13

> rOpenSci, University of California, Berkeley, CA, USA

Going over the manuscript today...",NA,NA,NA
76,49436551,sckott,2014-07-18T14:26:22Z,2014-07-18T14:26:22Z,"Maybe

> RNeXML: Parsing and Serializing Semantically Rich Phyloinformatic Data in R",NA,NA,NA
73,49502675,rvosa,2014-07-19T07:56:28Z,2014-07-19T07:56:28Z,"The tree description is valid in principle (you can paste it into figtree,
for example), but some of the newick parsers that I've played around with
seem to be picky about i) there are no branch lengths; ii) there are
""unbranched"" interior nodes; iii) there are node labels.


On Fri, Jul 18, 2014 at 12:03 AM, Carl Boettiger <notifications@github.com>
wrote:

> @rvosa <https://github.com/rvosa> For quick reference, here's the Newick
> file I get when trying to add the node labels; not sure why it fails to
> parse (either using phylobase::readNewick, which uses the nexus class
> library, or using phytools::read.newick):
> https://github.com/ropensci/RNeXML/blob/96add29b379748a6dae302c483e6bbaf25297a7e/inst/examples/sparql.newick
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/73#issuecomment-49372893>.
>",NA,NA,NA
58,49502737,rvosa,2014-07-19T07:59:58Z,2014-07-19T07:59:58Z,"My affiliation is fine. About funding, the original git repo was kicked off
by Kseniia Shumelchyk for her GSoC project. However, she dropped out and
hasn't been paid by Google. Arguably it might be good form to acknowledge
her, though her contributions have been minimal.


On Fri, Jul 18, 2014 at 4:22 PM, Scott Chamberlain <notifications@github.com
> wrote:

> Looks good @cboettig <https://github.com/cboettig> I need to change
> affiliation from simon fraser to simply rOpenSci
> https://github.com/ropensci/RNeXML/blob/master/manuscripts/manuscript.Rmd#L13
>
> rOpenSci, University of California, Berkeley, CA, USA
>
> Going over the manuscript today...
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/58#issuecomment-49436160>.
>",NA,NA,NA
77,49503460,rvosa,2014-07-19T08:41:25Z,2014-07-19T08:41:25Z,"On Fri, Jul 18, 2014 at 8:25 PM, Carl Boettiger <notifications@github.com>
wrote:

> @rvosa <https://github.com/rvosa> CRAN tells me that RNeXML was failing
> several of the automated tests last night due to www.nexml.org timing
> out. The tests are hitting the validator on the site there.
>
Yup, this can definitely happen. The validator applies two validation
steps: 1) schema validation using a small Java library, 2) sanity checks on
the ID references using a Perl library. Too many concurrent hits, or too
large input files, can bring this to its knees. The web service was
initially intended for developers to try out the NeXML they generate (in a
web browser), so when robots start hitting it, it'll show itself to be
fragile :)

 I can rewrite the validation function to just perform XML schema
> validation if www.nexml.org is unreachable or the validator request times
> out. That would either require adding a local copy of the schema to the
> package (perhaps that's bad practice) or seeing if we could still reach
> http://www.nexml.org/2009/nexml.xsd even when the online validator times
> out.
>
A straight up fetch of the schema files should be a lot faster, of course:
that's just apache serving up files with no processing in between.

>  There are also the previously identified caveats to using R's built-in
> (xmllint based) validator:
>
>    - First, as you told me earlier, schema-only validation doesn't do all
>    the checks that online validation does (From #34
>    <https://github.com/ropensci/RNeXML/issues/34>).
>     - Also, as Jim discovered, xmllint uses schema localization and thus
>    thinks that some things are not valid when in fact they are: #23
>    (comment)
>    <https://github.com/ropensci/RNeXML/issues/23#issuecomment-31784823>
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/77>.
>",NA,NA,NA
76,49503522,rvosa,2014-07-19T08:44:35Z,2014-07-19T08:44:35Z,"I like Scott's suggestion. In general, I prefer to avoid ""next generation""
anything: NeXML is from 2009 (and next gen sequencing is even older).


On Fri, Jul 18, 2014 at 4:26 PM, Scott Chamberlain <notifications@github.com
> wrote:

> Maybe
>
> RNeXML: Parsing and Serializing Semantically Rich Phyloinformatic Data in R
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/76#issuecomment-49436551>.
>",NA,NA,NA
76,49532207,hlapp,2014-07-19T23:23:44Z,2014-07-19T23:23:44Z,"Perhaps something less jargony? E.g.:

> RNeXML: a package for reading and writing richly annotated phylogenetic, character, and trait data in R",NA,NA,NA
58,49554726,hlapp,2014-07-20T18:19:01Z,2014-07-20T18:19:01Z,"> Other than polishing up the sparql example in the supplement (issue #73) I think I'm just waiting on the feedback or thumbs up from @sckott and @hlapp before we hazard a first submission (no rush though, just keeping things moving).

I'd like to give the text a thorough read, but will be occupied with grant writing until Aug 12. Are there reasons we want/need to get this out earlier?",NA,NA,NA
58,49555092,sckott,2014-07-20T18:32:13Z,2014-07-20T18:32:13Z,I could benefit from more time to read through too :),NA,NA,NA
58,49555202,cboettig,2014-07-20T18:35:23Z,2014-07-20T18:35:23Z,"No problem, thanks for the heads up.

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Jul 20, 2014 11:32 AM, ""Scott Chamberlain"" <notifications@github.com>
wrote:

> I could benefit from more time to read through too :)
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/58#issuecomment-49555092>.
>",NA,NA,NA
77,49664060,cboettig,2014-07-21T20:54:28Z,2014-07-21T20:54:28Z,"Thanks.  Have now implemented a fallback routine which will just validate against the (online copy of) the schema, and a system of error handling such that `nexml_validate` returns appropriate warnings if the validation cannot be performed.  In addition to the warning or error messages, the function will return TRUE if validation is successful, FALSE if the document is not valid, and NULL if validation cannot be performed.  The unit tests will now only throw a warning if the validator tests return NULL, and only fail if the validation actually fails (returns FALSE).  Should keep CRAN's automatic checks happy this way.  ",NA,NA,NA
76,49664221,cboettig,2014-07-21T20:55:36Z,2014-07-21T20:55:36Z,Thanks for the suggestions.  I'm going to put @hlapp's suggestion as our working title unless I hear otherwise.  ,NA,NA,NA
78,50184711,cboettig,2014-07-25T18:12:17Z,2014-07-25T18:12:17Z,"@fmichonneau thanks for your feedback! 

Would you mind opening a new issue for your list of additional things to correct/address? (A single bulleted list is fine, you can use github's `- [ ] item` notation to give me check boxes for each item).  All good stuff!",NA,NA,NA
78,50184777,fmichonneau,2014-07-25T18:13:01Z,2014-07-25T18:13:01Z,"No problem, I'll be working on it now!",NA,NA,NA
73,50187260,cboettig,2014-07-25T18:34:06Z,2014-07-25T18:34:06Z,"@fmichonneau Maybe you might have some idea why we I can't parse [this Newick file](https://github.com/ropensci/RNeXML/raw/96add29b379748a6dae302c483e6bbaf25297a7e/inst/examples/sparql.newick) successfully in R?  e.g. with phylobase:

```r
download.file(""https://github.com/ropensci/RNeXML/raw/96add29b379748a6dae302c483e6bbaf25297a7e/inst/examples/sparql.newick"", ""sparql.newick"", ""wget"")
readNewick(""sparql.newick"")
```

Gives me:

```
Warning:  
 A TAXA block should be read before the TREES block (but no TAXA block was found).  Taxa will be inferred from their usage in the TREES block.
at line 1, column (approximately) 5105 (file position 5104)
storing implied block: TAXA
storing read block: TREES
Error: index out of bounds
In addition: Warning message:
In FUN(X[[1L]], ...) : NAs introduced by coercion
```

though it seems like a valid tree (e.g. can be read into figtree)...",NA,NA,NA
73,50635660,fmichonneau,2014-07-30T15:58:20Z,2014-07-30T15:58:20Z,"I think this is a bug in ape (Unfortunately, phylobase still relies on ape to parse the tree string, phylobase uses NCL to extract information about the taxa, branch lengths, labels, etc, but on ape to convert the parentheses and commas into an R object). Apparently, ape doesn't support edge labels on terminal edges. To have edge labels on terminal edges, taxa need to be in parenthesis by themselves like so `(Avahi_laniger)Avahi,(...` However, this apparently is not supported by ape:

```
ape::read.tree(text=""(1,(2,3));"")
```
gives

```

Phylogenetic tree with 3 tips and 2 internal nodes.

Tip labels:
[1] ""1"" ""2"" ""3""

Rooted; no branch lengths.
```

But 

```
ape::read.tree(text=""((1),(2,3));"")
```

gives 

```
Error in if (sum(obj[[i]]$edge[, 1] == ROOT) == 1 && dim(obj[[i]]$edge)[1] >  : 
  missing value where TRUE/FALSE needed
```

This works with the phytools parser:

```
 phytools::read.newick(text=""((1),(2,3));"")
```

but the string from the example doesn't work (R hangs).

I reported the ape's bug to Emmanuel
",NA,NA,NA
73,50639461,cboettig,2014-07-30T16:23:10Z,2014-07-30T16:23:10Z,"Okay, thanks for taking a look.  Yeah, I'd given phytools a try too and I
ping'd Liam about the issue.  Keep me posted if you figure anything out
from Emmanuel, but nothing mission critical here.


On Wed, Jul 30, 2014 at 8:58 AM, Francois Michonneau <
notifications@github.com> wrote:

> I think this is a bug in ape (Unfortunately, phylobase still relies on ape
> to parse the tree string, phylobase uses NCL to extract information about
> the taxa, branch lengths, labels, etc, but on ape to convert the
> parentheses and commas into an R object). Apparently, ape doesn't support
> edge labels on terminal edges. To have edge labels on terminal edges, taxa
> need to be in parenthesis by themselves like so (Avahi_laniger)Avahi,(...
> However, this apparently is not supported by ape:
>
> ape::read.tree(text=""(1,(2,3));"")
>
> gives
>
>
> Phylogenetic tree with 3 tips and 2 internal nodes.
>
> Tip labels:
> [1] ""1"" ""2"" ""3""
>
> Rooted; no branch lengths.
>
> But
>
> ape::read.tree(text=""((1),(2,3));"")
>
> gives
>
> Error in if (sum(obj[[i]]$edge[, 1] == ROOT) == 1 && dim(obj[[i]]$edge)[1] >  :
>   missing value where TRUE/FALSE needed
>
> This works with the phytools parser:
>
>  phytools::read.newick(text=""((1),(2,3));"")
>
> but the string from the example doesn't work (R hangs).
>
> I reported the ape's bug to Emmanuel
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/73#issuecomment-50635660>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
73,50711643,cboettig,2014-07-31T04:33:34Z,2014-07-31T04:33:34Z,"Okay, with Liam's bugfix http://blog.phytools.org/2014/07/new-version-of-readnewick-that-can-read.html we can read the tree in and just plot internal node labels to avoid over-crowding the figure (see https://github.com/ropensci/RNeXML/blob/devel/manuscripts/supplement.Rmd#L330)

I think we have a nice sparql use case now.  We could possibly use a bit more text around this example, but I'll wait for others to weigh in.",NA,NA,NA
82,50790739,cboettig,2014-07-31T17:26:11Z,2014-07-31T17:26:11Z,"Thanks, done. ",NA,NA,NA
81,50791244,cboettig,2014-07-31T17:29:58Z,2014-07-31T17:29:58Z,"Cool, I think I've caught the most egregious of these now at least.",NA,NA,NA
79,50796899,cboettig,2014-07-31T18:11:59Z,2014-07-31T18:11:59Z,"@fmichonneau Thanks for pointing this out, definitely can't start throwing around words like 'attribute', 'value', and 'element' without defining them.  I've tried to introduce them a bit more carefully in the modified text, [lines 565-600](https://github.com/ropensci/RNeXML/commit/a8ec64a52f1d09a93338659f20133990a4b54c66#diff-5e5ba5eb30a5d4961114b40df47b8e97R564)  (though perhaps a figure would have served better?), and likewise for namespaces.  If you have a chance, let me know what you think.  ",NA,NA,NA
83,50797848,cboettig,2014-07-31T18:19:22Z,2014-07-31T18:19:22Z,"Now appears among the future directions directly mentioned, and also as a new issue #87.  ",NA,NA,NA
80,50798437,cboettig,2014-07-31T18:23:58Z,2014-07-31T18:23:58Z,"Hopefully this is sufficiently addressed by https://github.com/ropensci/RNeXML/commit/a8ec64a52f1d09a93338659f20133990a4b54c66, see thread in issue #79",NA,NA,NA
79,51760539,rvosa,2014-08-11T09:50:30Z,2014-08-11T09:50:30Z,"Is it possible to have some kind of infobox or glossary in MEE manuscripts? Perhaps it is an idea to just define the necessary concepts ('attribute', 'element', 'namespace'...) in something like that, and then refer the reader to the wealth of verbiage that has already been written about XML in the life sciences (e.g. doi:10.1016/S0167-7799(00)01465-7 and http://books.google.nl/books?id=J0pdinIbxqEC)",NA,NA,NA
88,52956240,cboettig,2014-08-21T17:47:50Z,2014-08-21T17:47:50Z,"Yup, let's give it a go.  at least CRAN seems to be managing to build the windows binaries, so should be a good test.  ",NA,NA,NA
88,52969764,sckott,2014-08-21T19:27:51Z,2014-08-21T19:27:51Z,ok,NA,NA,NA
88,52973537,sckott,2014-08-21T19:57:46Z,2014-08-21T19:57:46Z,"@cboettig I added appveyor file, badge to readme, and turned on daily builds for the package, that run around 730-930 am each day

The basic `appveyor.yml` file may not have everything it needs to build correctly, we'll see how it goes with this first build https://ci.appveyor.com/project/sckott/rnexml",NA,NA,NA
88,52977600,sckott,2014-08-21T20:24:15Z,2014-08-21T20:24:15Z,"Hmm not sure what the equivalent of `sudo apt-get` will be for Windows in the appveyor file https://github.com/ropensci/RNeXML/commit/0a56c8f2fd67e1128a6463916761531db34bf80c   -  Appveyor obviously doesn't like those commands since it's windows, anyone know",NA,NA,NA
58,52990231,sckott,2014-08-21T21:52:04Z,2014-08-21T21:59:16Z,"@cboettig WOrking on the ms right now. 

A few comments, I'll add any more as I go:

* Sometimes in text of a paragraph functions are referred to without parens, like `foo`, while other times they have a parens, like `foo()`. Perhaps make these consistent.  (not a huge deal obviously)",NA,NA,NA
58,52991135,cboettig,2014-08-21T22:00:19Z,2014-08-21T22:00:19Z,"definitely, good catch!

You should feel free to just add `()` to the mention of any function as you
go and commit your changes.

Lots of small commits with such messages like @rvosa did when making his
edits worked really nicely I thought. Also feel free to add HTML comments
to me in the text if that's easiest -- if reading the md version you'll see
a few still in there (though I've mostly removed the ones I felt were
resolved).


On Thu, Aug 21, 2014 at 2:52 PM, Scott Chamberlain <notifications@github.com
> wrote:

> @cboettig <https://github.com/cboettig> WOrking on the ms right now.
>
> A few comments, I'll add any more as I go:
>
>    - Sometimes in text of a paragraph functions are referred to without
>    parens, like foo, while other times they have a parens, like foo().
>    Perhaps make these consistent.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/58#issuecomment-52990231>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
58,52991198,sckott,2014-08-21T22:01:00Z,2014-08-21T22:01:00Z,"Right, I'm adding html comments for you, I'll make sure to do small commits",NA,NA,NA
89,52993509,cboettig,2014-08-21T22:24:36Z,2014-08-21T22:24:36Z,"Yeah, that's a great question.  

On one hand, row-names are handy for having very semantic subsetting, e.g.

```r
chars[""taxon_5"", ""reef-dwelling""]
```

Is rather nicer than

```r
chars[chars[[""taxa""]] == ""taxon_5"", ""reef-dwelling""]
```

On the other hand, like you say, most interesting uses (e.g. ggplot / dplyr manipulations) can't operate on row-names directly and need those names as a column.  I also think some R functions can actually cause row labels to be dropped. 

However, in this case the motivation comes from what I think is most common in R phylogenetics community.  The most popular R packages for handling trait data (like geiger), have the *terrible* convention of using matrices instead of data.frames as the data object, which forces them to indicate taxa as row names rather than as a column (since the matrices want to be numeric class for all the continuous trait values).  By using taxa labels the way I do here, coercion of this ""character matrix"" data.frame into a matrix object for use in those functions does the thing those functions expect automatically.  

In general though, I agree that including 'data' in row-names (e.g. using row-names at all) is probably a bad idea. Wonder if @hadley has a take on that. (I also think many R users would be so much happier if they never learned to use matrix). 




",NA,NA,NA
89,52994407,hadley,2014-08-21T22:34:27Z,2014-08-21T22:34:27Z,"IMO, you should _never_ use row names on a data frame (although they do make sense for matrices). Both plyr and dplyr drop row names.",NA,NA,NA
89,52994639,sckott,2014-08-21T22:37:14Z,2014-08-21T22:37:14Z,"@hadley brings up a good point that dplyr and plyr drop them

I _think_ some of the downstream packages folks will require the species names to be row names, but that's easy enough to do",NA,NA,NA
90,52997549,cboettig,2014-08-21T23:11:08Z,2014-08-21T23:11:08Z,"Yup, that's correct. I'd like to add KNB so that it would part of the DataONE inventory.  From what I understand DataONE has a NEXUS type but no NeXML type.  Though maybe we could just use the XML type.  See: https://cn.dataone.org/cn/v1/formats, @mbjones could probably set me straight on this.

Github is an interesting question.  My intuition is not to, since for anyone using github already it's almost easier to do that without an R function, and for users not using github they might think ""so where's my DOI?"".  

Dryad (& Treebase) are the most obvious targets for sure. IIRC @rvosa tells us that Treebase cannot accept NeXML at this time, and @hlapp tells us the Dryad doesn't (yet?) accept automatic submissions (or maybe the sword thing is up and running now?).  I think it would certainly be a nice use case as we could fill out the Dryad metadata automatically and perhaps more thoroughly this way.  ",NA,NA,NA
58,52998292,sckott,2014-08-21T23:20:39Z,2014-08-21T23:20:39Z,"@cboettig okay, sent PR",NA,NA,NA
90,52998459,sckott,2014-08-21T23:22:45Z,2014-08-21T23:22:45Z,"Right, I don't think Github is a great use case here, it makes sense for things like `.geojson` files that can be rendered as maps, e.g.

Yeah, i imagine since it's not free, Dryad would need users to authenticate somehow after payment is received?",NA,NA,NA
89,52999035,cboettig,2014-08-21T23:30:25Z,2014-08-21T23:30:25Z,"@hadley Excellent, I agree. Do you have this carved on a stone tablet somewhere we can wave around?  

@sckott Right, in this case we're mostly going with what works best for the downstream functions from the standard packages (which will take a data.frame with row.names but not without it).  Perhaps we could add an option like `taxa_as_column` for the sensible folk that would prefer that...",NA,NA,NA
90,53000543,hlapp,2014-08-21T23:37:16Z,2014-08-21T23:37:16Z,"No, the SWORD interface is not up yet in Dryad.",NA,NA,NA
90,53006568,mbjones,2014-08-22T00:26:02Z,2014-08-22T00:26:02Z,"@cboettig That's right, at DataONE we have NEXUS registered as a format but not NeXML yet as far as I can see.  We can easily add formats as needed, but like to set the format identifier to be that which is normally used by the community when typing their documents.  Do you know what people use for the namespace identifier?  Are there multiple versions with their own namespaces that correspond to different XSD versions?  I read the [paper on NexML](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3376374/), but the [NeXML web site](http://www.nexml.org/) it refers to seems to be down, so I'd have to look around for the current home.  I found a [nexml github repo](https://github.com/nexml/nexml) that had some [example documents](https://github.com/nexml/nexml/blob/master/examples/phenoscape.xml) using a namespace of http://www.nexml.org/2009, so maybe that is the right namespace?  If you can provide a list of namespace/names/versions for NeXML, I can help get them registered in the DataONE format list.",NA,NA,NA
89,53006889,sckott,2014-08-22T00:30:16Z,2014-08-22T00:30:16Z,Most downstream phylogenetic pkgs require datasets with taxa as row names?,NA,NA,NA
88,53033111,rvosa,2014-08-22T07:55:06Z,2014-08-22T07:55:06Z,"Unless the universe has drastically changed over the last few years there is nothing even remotely like `apt-get` under Windows. Seeing that this is for libxslt I suspect there would have to be some very dodgy maneuver to download the equivalent *.dll and place it somewhere in the %PATH%. Likewise, shell scripts won't work either and would have to be converted to *.bat scripts.

Maybe I'm misunderstanding what we're trying to accomplish here but this seems more trouble than it's worth? Who uses Windows anyway? ;-) ",NA,NA,NA
90,53033464,rvosa,2014-08-22T07:59:57Z,2014-08-22T07:59:57Z,"There is only the one namespace that you mention: http://www.nexml.org/2009

Would it be helpful to know that NeXML is known to the EDAM ontology? Not
sure if that is at all useful but worth pointing out:
http://www.ebi.ac.uk/ontology-lookup/?termId=format%3A3160


On Fri, Aug 22, 2014 at 2:26 AM, Matt Jones <notifications@github.com>
wrote:

> @cboettig <https://github.com/cboettig> That's right, at DataONE we have
> NEXUS registered as a format but not NeXML yet as far as I can see. We can
> easily add formats as needed, but like to set the format identifier to be
> that which is normally used by the community when typing their documents.
> Do you know what people use for the namespace identifier? Are there
> multiple versions with their own namespaces that correspond to different
> XSD versions? I read the paper on NexML
> <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3376374/>, but the NeXML web
> site <http://www.nexml.org/> it refers to seems to be down, so I'd have
> to look around for the current home. I found a nexml github repo
> <https://github.com/nexml/nexml> that had some example documents
> <https://github.com/nexml/nexml/blob/master/examples/phenoscape.xml>
> using a namespace of http://www.nexml.org/2009, so maybe that is the
> right namespace? If you can provide a list of namespace/names/versions for
> NeXML, I can help get them registered in the DataONE format list.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/90#issuecomment-53006568>.
>",NA,NA,NA
90,53036376,mbjones,2014-08-22T08:37:03Z,2014-08-22T08:37:03Z,"@cboettig @rvosa OK, I requested creation of the NeXML format by @csjx in [DataONE issue 6068](https://redmine.dataone.org/issues/6068). Please comment on that ticket if anything looks awry with the proposed format info.

Should we differentiate the NEXUS/NeXML formats (http://www.nexml.org) from the similarly named NeXus/NeXML format in the neutron and xray community (http://www.nexusformat.org/)?  Maybe its not an issue?",NA,NA,NA
90,53041028,rvosa,2014-08-22T09:30:17Z,2014-08-22T09:30:17Z,"@mbjones there is a definite possibility of confusion (I've seen it in a deeply embarrassing publication: http://www.deepdyve.com/lp/institute-of-electrical-and-electronics-engineers/the-design-of-ruby-rdf-api-for-evolutionary-informatics-fnVpOUe4Qs), hence it might make sense to also cite the EDAM term. Just FYI: the nexml.org domain will come back to life, I promise. I'm switching domain registrars.",NA,NA,NA
88,53060813,sckott,2014-08-22T13:36:21Z,2014-08-22T13:36:21Z,"I wouldn't be surprised if more than 50% of our users across our pkgs are windows users. Maybe phylogenetics community is an especially non-Windows community though. 

Anyway, the point is to know quickly when a change is breaking on Windows.  ",NA,NA,NA
90,53079614,mbjones,2014-08-22T16:01:44Z,2014-08-22T16:01:44Z,@rvosa Thanks for the info.  Any chance I can get a copy of the XSD schema from somewhere before the nexml.org site comes back up?,NA,NA,NA
90,53080664,rvosa,2014-08-22T16:08:02Z,2014-08-22T16:08:02Z,"https://github.com/nexml/nexml/tree/master/xsd


On Fri, Aug 22, 2014 at 6:01 PM, Matt Jones <notifications@github.com>
wrote:

> @rvosa <https://github.com/rvosa> Thanks for the info. Any chance I can
> get a copy of the XSD schema from somewhere before the nexml.org site
> comes back up?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/90#issuecomment-53079614>.
>",NA,NA,NA
88,53087010,cboettig,2014-08-22T16:40:20Z,2014-08-22T16:40:20Z,"CRAN is already supplying windows builds and daily windows checks for
RNeXML, so even though we may have a lot of Windows users I don't think we
need to worry about this.  See
http://cran.r-project.org/web/checks/check_results_RNeXML.html


On Fri, Aug 22, 2014 at 6:36 AM, Scott Chamberlain <notifications@github.com
> wrote:

> I wouldn't be surprised if more than 50% of our users across our pkgs are
> windows users. Maybe phylogenetics community is an especially non-Windows
> community though.
>
> Anyway, the point is to know quickly when a change is breaking on Windows.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/88#issuecomment-53060813>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
89,53089553,hadley,2014-08-22T17:00:42Z,2014-08-22T17:00:42Z,"@cboettig the tidy data paper is probably the best ref for my thinking, but it doesn't include anything explicitly on row names.",NA,NA,NA
88,53090194,sckott,2014-08-22T17:06:06Z,2014-08-22T17:06:06Z,"Definitely do remove, but CRAN is only testing the CRAN version. i guess this package doesn't primarily work with a web API that can change, so less important here",NA,NA,NA
89,53236389,rvosa,2014-08-25T07:46:45Z,2014-08-25T07:46:45Z,"I think it makes sense to retain row names, especially because in NeXML row names (i.e. row's 'label' attribute) are distinct from taxon names (i.e. otu's 'label'). You can imagine that row names could be things such as FASTA definition lines or some other descriptive name that applies specifically to character data, which users may want to distinguish from proper, 'normalized' taxonomic names.",NA,NA,NA
89,53258240,hadley,2014-08-25T12:36:25Z,2014-08-25T12:36:25Z,"@rvosa I would still argue that those shouldn't be row names, but explicit variables. One problem with row names is that the don't have their own name/label so you'd need to look up their meaning in the docs.",NA,NA,NA
91,53287007,cboettig,2014-08-25T16:21:52Z,2014-08-25T16:21:52Z,"Nice Scott, thanks for the edits.",NA,NA,NA
89,53290274,cboettig,2014-08-25T16:48:34Z,2014-08-25T16:48:34Z,"@rvosa Note that the data is there either way, this is just a peculiar aspect of R, whereby the data can be stored in ""row names"" rather than in, say, the first column. At an abstract level this is irrelevant, as a user can go between the formats without information lost, but from a practical matter it impacts the syntax. 

I've gone with this otherwise distasteful option because 90% of users will be using this feature for the purpose of getting data into and out of the geiger package, which for historical reasons uses row-names rather than a unique column to contain the data. (Other phylogenetics packages also tend to adopt this convention).  Thus a novice user can do: 

```r
chars <- get_characters(nex)
trees <- get_trees(nex)
geiger::fitContinuous(trees, chars)    # use function from geiger
```

(see the end of our README for an example of this.)  This just gives users a more compact workflow than first having to add rownames and then drop a column first:

```r
rownames(char) <- char[[1]]
char <- char[[-1]]
```

Users wanting to promote these rownames to a bona fide column can of course do it manually, with a line or so of code, but I'm adding an option to toggle this:


```r
chars <- get_characters(nex, rownames_as_col=TRUE)
```

Not sure if that's a good name for the argument (a bit verbose).  ",NA,NA,NA
89,53292559,sckott,2014-08-25T17:06:05Z,2014-08-25T17:06:05Z,"@cboettig `rownames_as_col ` is somewhat long, but seems fine to me

I agree that if most users are used to having taxa as row.names on their data frames for phylogenetic work then we should go with that. ",NA,NA,NA
89,53388005,rvosa,2014-08-26T08:07:32Z,2014-08-26T08:07:32Z,">
> @cboettig <https://github.com/cboettig> rownames_as_col is somewhat long,
> but seems fine to me
>
> I agree that if most users are used to having taxa as row.names on their
> data frames for phylogenetic work then we should go with that.
>
Does R expect row.names to be unique? Because we can't guarantee that for
the 'label' attribute anyway (uniqueness is required of 'id', but not of
'label').",NA,NA,NA
89,53962256,sckott,2014-08-30T15:54:36Z,2014-08-30T15:54:36Z,"@rvosa Yes , row names have to be unique. ",NA,NA,NA
86,56194259,rvosa,2014-09-19T15:40:17Z,2014-09-19T15:40:17Z,"Along similar lines, a timestamp is probably nice to have as well. Though then the question becomes: what does a program have to do if it reads a file with a timestamp and writes it again: append another timestamp? Overwrite it?",NA,NA,NA
86,56203586,cboettig,2014-09-19T16:50:46Z,2014-09-19T16:50:46Z,Good question.  Wondering if there's a good way to coordinate thinking about this kind of thing at a higher level so at least whatever we do is consistent across parsers and with most users expectations?,NA,NA,NA
79,58012188,rvosa,2014-10-06T12:52:43Z,2014-10-06T12:52:43Z,"Hi guys,

it appears (at first glance :)) that there are only two outstanding issues for the manuscript milestone, neither of which have shown a lot of progress over the last month or so. Is there anything that I can/should do?

Rutger",NA,NA,NA
79,58036337,cboettig,2014-10-06T15:39:09Z,2014-10-06T15:39:09Z,"@rvosa Thanks for checking in. After my last read over in August I felt we were pretty much there (the basic xml concepts are now defined in text, though a box or such might indeed be better; the other issue is of course the generic thread on manuscript comments). @hlapp wanted some time to read over the latest copy before we submit. Planning to submit by the end of the month.",NA,NA,NA
79,58058834,hlapp,2014-10-06T17:53:21Z,2014-10-06T17:53:21Z,"I think the manuscript needs some more work. I'm doing a first pass with comments, and then we can plan for a conference call.",NA,NA,NA
79,58059063,cboettig,2014-10-06T17:54:31Z,2014-10-06T17:54:31Z,"@hlapp Sounds good, many thanks!

On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <notifications@github.com>
wrote:

> I think the manuscript needs some more work. I'm doing a first pass with
> comments, and then we can plan for a conference call.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>.
>



-- 
Carl Boettiger
UC Santa Cruz
http://carlboettiger.info/",NA,NA,NA
79,59984538,cboettig,2014-10-21T19:31:14Z,2014-10-21T19:31:14Z,"Hey @hlapp just wanted to check in where we are on this.  Time to schedule
a chat?

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Oct 6, 2014 10:54 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote:

> @hlapp Sounds good, many thanks!
>
> On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <notifications@github.com>
> wrote:
>
>> I think the manuscript needs some more work. I'm doing a first pass with
>> comments, and then we can plan for a conference call.
>>
>> —
>> Reply to this email directly or view it on GitHub
>> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>.
>>
>
>
>
> --
> Carl Boettiger
> UC Santa Cruz
> http://carlboettiger.info/
>",NA,NA,NA
79,60210980,rvosa,2014-10-23T09:02:45Z,2014-10-23T09:02:45Z,"I would be up for that as well.

On Tue, Oct 21, 2014 at 9:31 PM, Carl Boettiger <notifications@github.com>
wrote:

> Hey @hlapp just wanted to check in where we are on this. Time to schedule
> a chat?
>
> ---
> Carl Boettiger
> http://carlboettiger.info
>
> sent from mobile device; my apologies for any terseness or typos
> On Oct 6, 2014 10:54 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote:
>
> > @hlapp Sounds good, many thanks!
> >
> > On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <notifications@github.com>
> > wrote:
> >
> >> I think the manuscript needs some more work. I'm doing a first pass
> with
> >> comments, and then we can plan for a conference call.
> >>
> >> —
> >> Reply to this email directly or view it on GitHub
> >> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>.
> >>
> >
> >
> >
> > --
> > Carl Boettiger
> > UC Santa Cruz
> > http://carlboettiger.info/
> >
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-59984538>.
>",NA,NA,NA
79,60279460,hlapp,2014-10-23T17:52:57Z,2014-10-23T17:52:57Z,"I'm taking the text onto the plane to Stockholm (TDWG). Chat sounds great, but needs to be after Nov 3.

-hilmar

Sent from away

> On Oct 21, 2014, at 3:31 PM, Carl Boettiger <notifications@github.com> wrote:
> 
> Hey @hlapp just wanted to check in where we are on this. Time to schedule 
> a chat? 
> 
> --- 
> Carl Boettiger 
> http://carlboettiger.info 
> 
> sent from mobile device; my apologies for any terseness or typos 
> On Oct 6, 2014 10:54 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote: 
> 
> > @hlapp Sounds good, many thanks! 
> > 
> > On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <notifications@github.com> 
> > wrote: 
> > 
> >> I think the manuscript needs some more work. I'm doing a first pass with 
> >> comments, and then we can plan for a conference call. 
> >> 
> >> — 
> >> Reply to this email directly or view it on GitHub 
> >> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>. 
> >> 
> > 
> > 
> > 
> > -- 
> > Carl Boettiger 
> > UC Santa Cruz 
> > http://carlboettiger.info/ 
> >
> —
> Reply to this email directly or view it on GitHub.",NA,NA,NA
79,61029801,cboettig,2014-10-30T00:46:16Z,2014-10-30T00:46:16Z,"Sounds good, shall we schedule a Skype / google hangout / whatnot next week
then?

---
Carl Boettiger
http://carlboettiger.info

sent from mobile device; my apologies for any terseness or typos
On Oct 23, 2014 10:53 AM, ""Hilmar Lapp"" <notifications@github.com> wrote:

> I'm taking the text onto the plane to Stockholm (TDWG). Chat sounds great,
> but needs to be after Nov 3.
>
> -hilmar
>
> Sent from away
>
> > On Oct 21, 2014, at 3:31 PM, Carl Boettiger <notifications@github.com>
> wrote:
> >
> > Hey @hlapp just wanted to check in where we are on this. Time to
> schedule
> > a chat?
> >
> > ---
> > Carl Boettiger
> > http://carlboettiger.info
> >
> > sent from mobile device; my apologies for any terseness or typos
> > On Oct 6, 2014 10:54 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote:
> >
> > > @hlapp Sounds good, many thanks!
> > >
> > > On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <notifications@github.com>
>
> > > wrote:
> > >
> > >> I think the manuscript needs some more work. I'm doing a first pass
> with
> > >> comments, and then we can plan for a conference call.
> > >>
> > >> —
> > >> Reply to this email directly or view it on GitHub
> > >> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>.
>
> > >>
> > >
> > >
> > >
> > > --
> > > Carl Boettiger
> > > UC Santa Cruz
> > > http://carlboettiger.info/
> > >
> > —
> > Reply to this email directly or view it on GitHub.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-60279460>.
>",NA,NA,NA
79,61075197,rvosa,2014-10-30T11:02:34Z,2014-10-30T11:02:34Z,"Sounds good! I am fairly happy with google hangouts, and I have you in my
circles. Ideally for me would be wednesday, when I'm not scheduled for
anything (though I guess it would be evening for me anyway). I'd like to
avoid Thursday evening and Friday.

On Thu, Oct 30, 2014 at 1:46 AM, Carl Boettiger <notifications@github.com>
wrote:

> Sounds good, shall we schedule a Skype / google hangout / whatnot next
> week
> then?
>
> ---
> Carl Boettiger
> http://carlboettiger.info
>
> sent from mobile device; my apologies for any terseness or typos
> On Oct 23, 2014 10:53 AM, ""Hilmar Lapp"" <notifications@github.com> wrote:
>
> > I'm taking the text onto the plane to Stockholm (TDWG). Chat sounds
> great,
> > but needs to be after Nov 3.
> >
> > -hilmar
> >
> > Sent from away
> >
> > > On Oct 21, 2014, at 3:31 PM, Carl Boettiger <notifications@github.com>
>
> > wrote:
> > >
> > > Hey @hlapp just wanted to check in where we are on this. Time to
> > schedule
> > > a chat?
> > >
> > > ---
> > > Carl Boettiger
> > > http://carlboettiger.info
> > >
> > > sent from mobile device; my apologies for any terseness or typos
> > > On Oct 6, 2014 10:54 AM, ""Carl Boettiger"" <cboettig@gmail.com> wrote:
> > >
> > > > @hlapp Sounds good, many thanks!
> > > >
> > > > On Mon, Oct 6, 2014 at 10:53 AM, Hilmar Lapp <
> notifications@github.com>
> >
> > > > wrote:
> > > >
> > > >> I think the manuscript needs some more work. I'm doing a first pass
> > with
> > > >> comments, and then we can plan for a conference call.
> > > >>
> > > >> —
> > > >> Reply to this email directly or view it on GitHub
> > > >> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-58058834>.
>
> >
> > > >>
> > > >
> > > >
> > > >
> > > > --
> > > > Carl Boettiger
> > > > UC Santa Cruz
> > > > http://carlboettiger.info/
> > > >
> > > —
> > > Reply to this email directly or view it on GitHub.
> >
> > —
> > Reply to this email directly or view it on GitHub
> > <https://github.com/ropensci/RNeXML/issues/79#issuecomment-60279460>.
> >
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/79#issuecomment-61029801>.
>",NA,NA,NA
94,61690456,cboettig,2014-11-04T18:35:09Z,2014-11-04T18:35:09Z,"Great! Github staff has now resolved this:

> No problem, ropensci/RNeXML is now a normal repository in its own fork network and we ran a contributions backfill for your account.

> Thanks!
> Robert",NA,NA,NA
94,61691004,sckott,2014-11-04T18:38:31Z,2014-11-04T18:38:31Z,nice!,NA,NA,NA
96,61774110,rvosa,2014-11-05T08:27:05Z,2014-11-05T08:27:05Z,"Zenodo copies need to be tagged releases, so ""latest version"" does not
apply precisely.

On Tue, Nov 4, 2014 at 7:31 PM, Carl Boettiger <notifications@github.com>
wrote:

>
>    - Make sure that Zenodo copy syncs to latest version
>    - Update package CITATION file/function appropriately.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/96>.
>",NA,NA,NA
96,61846318,cboettig,2014-11-05T17:22:33Z,2014-11-05T17:22:33Z,"@rvosa yeah that's what I meant to write anyway.  Our tags correspond to versions 'released' to CRAN, so the Zenodo archive should correspond 1:1 with the version history as CRAN sees it.  

Note we have semantic version numbering; with the additional practice (borrowed from RStudio folks) of appending `.99` to the active development version (so we can distinguish if someone has installed from Github vs CRAN).  Hence we're on version `1.1.3` on CRAN and `1.1.3.99` on Github, which will be bumped to `1.1.4` on our next CRAN release (assuming it's bug fixes and not new functionality).  ",NA,NA,NA
98,64011312,cboettig,2014-11-21T18:01:41Z,2014-11-21T18:01:41Z,"Nice, thanks!",NA,NA,NA
97,64040395,cboettig,2014-11-21T21:27:31Z,2014-11-21T21:27:31Z,Added a line about this to the [Release notes](https://github.com/ropensci/RNeXML/commit/94558b2a5cadb0abe57eaa9996e8185c3ac67fd9); thinking I'll bump to `2.0.0` then on the CRAN release.  ,NA,NA,NA
97,64040808,sckott,2014-11-21T21:30:32Z,2014-11-21T21:30:32Z,Makes sense to bump if breaking,NA,NA,NA
100,64838028,cboettig,2014-11-27T23:41:28Z,2014-11-27T23:41:28Z,"Looks great, nice work.",NA,NA,NA
101,65116038,cboettig,2014-12-01T19:01:25Z,2014-12-01T19:01:25Z,"@hlapp I think you wanted the function `class()` instead of the function `typeof` in your edits.  (For instance, the return class of `nexml_read()` is an object of `class` `nexml`, but is `typeof` `S4`, I don't think most users care about the latter. Similarly the tree in the second example is of `class` `multiPhylo`, while it is of `typeof` `list` because all `S3` objects are lists. 

Guess I'm not sure about whether it helps to show the class explicitly like this each time, or if it just crowds up the document. (Remember that knitr is echoing the output of the displayed commands into the pdf.)",NA,NA,NA
101,65121981,cboettig,2014-12-01T19:39:59Z,2014-12-01T19:39:59Z,"Okay, thanks for these edits, I've pushed a few changes to address some of the things you've brought up so far.",NA,NA,NA
101,65232027,hlapp,2014-12-02T13:44:24Z,2014-12-02T13:44:24Z,"@cboettig re: `class()` vs `typeof()`, you are correct. I wasn't sure based on documentation, and haven't had time yet to test.",NA,NA,NA
104,65850597,cboettig,2014-12-05T20:36:54Z,2014-12-05T20:36:54Z,"@hadley Thanks for the report.  Since you introduced me to this trick perhaps you can suggest the right approach here?

The packages that define these functions are listed in the SUGGESTS list.  Apparently CRAN check doesn't think that's good enough and wants them in IMPORTS, forcing a bigger dependency footprint. How are you handling this in your packages that provide functions that link to packages in SUGGESTS?

the xslt function is more tricky because Duncan' Sxslt package isn't on CRAN...

",NA,NA,NA
104,65850777,hadley,2014-12-05T20:38:08Z,2014-12-05T20:38:08Z,"Don't add to imports, just use `foo::fs_add_tags`",NA,NA,NA
104,65850835,hadley,2014-12-05T20:38:36Z,2014-12-05T20:38:36Z,And I'd strongly recommend against suggesting non-CRAN packages,NA,NA,NA
104,65852388,cboettig,2014-12-05T20:50:40Z,2014-12-05T20:50:40Z,"thanks! and yeah, tell me about it...

On Fri Dec 05 2014 at 12:38:37 PM Hadley Wickham <notifications@github.com>
wrote:

> And I'd strongly recommend against suggesting non-CRAN packages
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/104#issuecomment-65850835>.
>",NA,NA,NA
105,66306161,cboettig,2014-12-09T16:03:12Z,2014-12-09T16:03:12Z,"Looks like your testing system doesn't have the Suggested dependencies for
RNeXML installed -- java libraries in this case. I've only recently fixed a
bug wrt pre-installing these java libraries on the docker images

On Tue, Dec 9, 2014, 7:59 AM Scott Chamberlain <notifications@github.com>
wrote:

> I just checked devtools::revdep_check(), and I get for RNeXML (this
> doesn't seem like a problem with taxize, but i wasn't sure):
>
> * using log directory ‘/private/var/folders/gs/4khph0xs0436gmd2gdnwsg080000gn/T/RtmpMsC2do/check_cran52d34045f85/RNeXML.Rcheck’
> * using R version 3.1.2 (2014-10-31)
> * using platform: x86_64-apple-darwin13.4.0 (64-bit)
> * using session charset: UTF-8
> * using option ‘--no-codoc’
> * checking for file ‘RNeXML/DESCRIPTION’ ... OK
> * checking extension type ... Package
> * this is package ‘RNeXML’ version ‘2.0.0’
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking whether package ‘RNeXML’ can be installed ... [10s/10s] OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking ‘build’ directory ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies ... OK
> * checking whether the namespace can be unloaded cleanly ... WARNING
> ---- unloading
> Error in .mergeMethodsTable(generic, mtable, get(tname, envir = env),  :
>   trying to get slot ""defined"" from an object of a basic class (""environment"") with no slots
> Calls: unloadNamespace ... <Anonymous> -> .updateMethodsInTable -> .mergeMethodsTable
> Execution halted
> * checking dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd line widths ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... SKIPPED
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking contents of ‘data’ directory ... OK
> * checking data for non-ASCII characters ... OK
> * checking data for ASCII and uncompressed saves ... OK
> * checking installed files from ‘inst/doc’ ... OK
> * checking files in ‘vignettes’ ... OK
> * checking examples ... [16s/16s] OK
> * checking for unstated dependencies in tests ... OK
> * checking tests ... ERROR
> Running the tests in ‘tests/test-all.R’ failed.
> Last 13 lines of output:
>      0 taxonomic units
>    Taxa:      ...
>
>    NeXML generated by RNeXML using schema version: 0.9
>    size: 21.7 Kb
>
>   parsing : ...
>   publish : Authentication successful
>   5
>   rdf : Loading required package: Sxslt
>   .Loading required package: rrdf
>   Loading required package: rJava
>   No Java runtime present, requesting install.
>
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/105>.
>",NA,NA,NA
105,66308876,sckott,2014-12-09T16:18:22Z,2014-12-09T16:18:22Z,"ah, right, thanks, got it now",NA,NA,NA
106,68582053,hlapp,2015-01-03T03:49:19Z,2015-01-03T03:49:19Z,"The last series of commits complete the first pass all the way through. We're now at ~4200 words (excluding abstract and acknowledgements).

Hence, as anticipated, a second pass of tightening up the text is now needed, to shave off another ~1000 words. May also want to change _Future Directions_ into a _Conclusions and Future Directions_ section.",NA,NA,NA
107,69114263,cboettig,2015-01-07T23:53:29Z,2015-01-07T23:53:29Z,"very nice, thanks for going through this.",NA,NA,NA
58,70422904,hlapp,2015-01-18T19:56:07Z,2015-01-18T19:56:07Z,@cboettig looks like we're done with this issue for now. Close?,NA,NA,NA
79,70422965,hlapp,2015-01-18T19:57:50Z,2015-01-18T19:57:50Z,"I'm going to make the call that this is addressed, in part with PR #106. ",NA,NA,NA
95,70423021,hlapp,2015-01-18T19:58:56Z,2015-01-18T19:58:56Z,"I think this is done, in part through PRs #106, #109, and #110.",NA,NA,NA
99,70423082,hlapp,2015-01-18T20:00:19Z,2015-01-18T20:00:19Z,"Done, see #106 and #109.",NA,NA,NA
58,70423338,cboettig,2015-01-18T20:05:44Z,2015-01-18T20:05:44Z,"Yup, done here",NA,NA,NA
93,70423354,hlapp,2015-01-18T20:06:07Z,2015-01-18T20:06:14Z,"I think this is addressed through the following commits:
- f20f13e2544a605f381dc49e503ef1075401d713
- 7bad1ab0d30cd7359aa04467f3f4f7d3378b65d7
- 133fa15d67a982cdbd118952d4702ac0e37eb23f
- 836da45b9293780645cae87cd6e52dba55647385
- 7b81b3a10804946eaaece6fcf2f4e37339902c08
- 7cb0ffc7d8e7323db6c34894c15e7f76c09cef3a

Ready to close out this issue?",NA,NA,NA
96,70423416,hlapp,2015-01-18T20:07:39Z,2015-01-18T20:07:39Z,@cboettig did you do this before or as part of submission? ,NA,NA,NA
90,70423835,hlapp,2015-01-18T20:17:35Z,2015-01-18T20:30:24Z,"> @cboettig @rvosa OK, I requested creation of the NeXML format by @csjx in DataONE issue 6068. Please comment on that ticket if anything looks awry with the proposed format info.

Just as an FYI to everyone, [DataONE issue 6068](https://redmine.dataone.org/issues/6068) has been implemented and closed (see the [D1 registration record](https://cn.dataone.org/cn/v1/formats/http://www.nexml.org/2009)).",NA,NA,NA
96,70425109,cboettig,2015-01-18T20:46:43Z,2015-01-18T20:46:43Z,"@hlapp Good question, I could use some feedback here.

I first set up the Zenodo tracking on Nov 5th, but as I had not yet tagged a release, nothing was pushed to Zenodo yet.  However, on Dec 6th I pushed a new version of RNeXML to CRAN (2.0.0), which implemented a simple change in the user-facing functions/API of the package (making the `nexml` argument to `add_basic_meta` be the last instead of the first argument, for consistency with all other methods.  Since this change could potentially break existing code, we bumped the version up).  

I've been tagging CRAN releases in git corresponding to their version, so when this release was tagged it was published to Zenodo.  Since then we had a minor change (2.0.1) requested by CRAN on 2014-12-26 (see [NEWS](https://github.com/ropensci/RNeXML/blob/master/NEWS)), but the Zenodo API was failing over the the holiday, and this tag was not detected (I understand the issue has since been fixed).

The more recent tweaks for the manuscript+vignettes will be in release 2.0.2, but CRAN requests packages do not submit updates more frequently than every two months; so this has not been pushed to CRAN.  Consequently the Zenodo version is still at the 2014-12-06 version (2.0.0), CRAN is as 2.0.1, and Github at 2.0.1.99 (which will be bumped to 2.0.2 when pushed to CRAN and then bring everything to the same version).  

So, long story short, perhaps it's not great having the manuscript in the same repo as the R package, since it makes it harder to keep these synchronized?  (On the other hand, there's a certain advantage to having everything together).  

To address this, perhaps we want to have tagged releases on Github that correspond to versions of the manuscript, independent of tagged releases that correspond to versions released to CRAN?  This still leaves the question of how to structure the manuscript-related tags.  I suppose this could be done according to submissions; e.g. submitted-mee-1 or something like that?  Or is it likely too confusing to have both software version tags and manuscript tags in the same repo?  

",NA,NA,NA
113,70425207,cboettig,2015-01-18T20:48:40Z,2015-01-18T20:48:40Z,"nice, that's a great idea.  presumably this might be used if no prefix was supplied, and otherwise supplying a prefix would allow a user to override the default?",NA,NA,NA
111,70426077,cboettig,2015-01-18T21:09:55Z,2015-01-18T21:09:55Z,"@hlapp thanks for testing this out.  Whoops, forgot to update the paths in those comments.  I'm still trying to figure out what (if anything) is the most useful way both for a user to use the Docker images and for us to document them.  

Now that RNeXML is on CRAN and provided by the rocker/ropensci Docker container, I'm not sure that it's even worth providing a separate Dockerfile for RNeXML.  As you can see in the Dockerfile, it doesn't install any software; it just loads the manuscript.Rmd file onto the `rocker/ropensci` container and sets some user permissions and defaults.

Other workflows might make more sense; for example:

-  a user could launch rocker/ropensci in RStudio mode, clone RNeXML from RStudio, open `manuscript.Rmd` and hit the `knit2pdf`.  
- When I rebuild the manuscript, I go to the `manuscripts/` working directory and run:

```
docker run -v $(pwd):/host -w /host -u rstudio --rm rocker/ropensci r r -e 'rmarkdown::render(""manuscript.Rmd"")'
```

 Having to link the current working directory that has the right files, manually specify the user, the container's working directory and the default command makes that line a bit more cumbersome (all these things being done by the `rnexml` Dockerfile as defaults).  But it's also explicit and perhaps less magical.  

Meanwhile, the currently documented example avoids having to share a working directory (thus avoiding any user permission issues or configuration which can be more tricky on a Mac/boot2docker client); relying on that `docker cp` command to get the final thing off.  And the RStudio way would avoid the command line all together.  So not sure which we should recommend. Thoughts?",NA,NA,NA
96,70426393,hlapp,2015-01-18T21:17:24Z,2015-01-18T21:17:24Z,"I guess it depends on what is the primary goal for having an archive of record on Zenodo. If it's the software reported in the paper, rather than the manuscript, then changes to the manuscript that do not change the code should not trigger re-archival in Zenodo. Also, if the version on CRAN is what we are reporting in the manuscript (and I think it is, isn't it), then the archive on record associated with the paper should be consistent with that. Which it seems it is at present.

The one thing that's amiss is that the DOI of the archive at Zenodo is not referenced in the text, which made me think that there is no archive. We should make sure that we cite the DOI in the revised version (assuming that the text won't be accepted straight up as is). This would then also serve as the DOI for the data used in the paper, for which in the submitted version we don't cite an archival record either. (Hint hint for a reviewer who is wondering what to criticize :smile: )",NA,NA,NA
115,70426498,cboettig,2015-01-18T21:19:27Z,2015-01-18T21:19:27Z,"whoops, it should be `--volume`.  I've actually dropped this example in the version I just pushed, since I figured `docker cp` was probably more robust than sharing volumes; but it sounds like `--volume` is working fine for you.  Anyway, see my earlier comments on what to do about the Docker approach in general.  having too many different ways to do the same thing is just confusing, but I'm not sure which one to choose.",NA,NA,NA
93,70426642,cboettig,2015-01-18T21:22:31Z,2015-01-18T21:22:31Z,"yup, thanks for tagging the commits. (I shoulda been better about tagging the relevant issue in my commit logs).  ",NA,NA,NA
86,70427214,cboettig,2015-01-18T21:35:23Z,2015-01-18T21:35:23Z,"A top-level timestamp is added only if one does not yet exist by `add_basic_metadata` since d93056b2496f951896ef35453e0115cafe9525cf, `USER` added in a2c94a4b613999d7fa6604cd856294be548f1e88 .  Currently this leaves updating the timestamp up to the use of more manual controls by the user. (automatically appending a new timestamp each time seems messy without richer metadata describing the differences, and changing existing metadata without notice seemed rude). ",NA,NA,NA
96,70428555,cboettig,2015-01-18T22:05:38Z,2015-01-18T22:05:38Z,"+1 regarding referencing the DOI in the text.  As the DOIs are versioned too, there's also the matter of which DOI to use.  (At present, I think Zenodo could do a better job of connecting multiple versions)

For me, the Zenodo archive exists simply to provide a (DatCite) DOI for and 'permanent copy' of the Github repository (along with more machine-readable metadata served through OAI-PMH and also indexed & served by DataCite).  The Github repository exists to provide the full version-ed record of both the software and the paper, and having them in the same repo makes sense to me as they are both manifestations of the same 'project'.  I suppose I could be convinced that they should still be separate repos on Github, and thus separate archives on Zenodo.  ",NA,NA,NA
96,70434737,hlapp,2015-01-19T00:45:25Z,2015-01-19T00:45:25Z,"I wasn't trying to make a case for separating repos for software and manuscript (AFAIAC, I'm mostly neutral on that question). I was just trying to argue what should take priority in triggering a new Zenodo deposit, and according to my argument it seems the version of the _software_ that should have been deposited for this initial submission of the manuscript _is_ indeed deposited. (It's just not cited in the paper.) It also seems that putting a new version on CRAN triggers a re-deposit on Zenodo, which sounds to me what we want to have for the purposes of citing in the paper.",NA,NA,NA
117,96763148,cboettig,2015-04-27T18:10:27Z,2015-04-27T18:10:27Z,"Looks great, thanks.",NA,NA,NA
116,96765088,cboettig,2015-04-27T18:14:30Z,2015-04-27T18:14:30Z,"Thanks for these!

- yup, vignettes should go up on CRAN in the next release (figured might as well wait for reviewer feedback since you know how touchy CRAN is)

- typo fixed.  

- didn't add the discuss.ropensci.org link since I think pointing just to issues is simpler (and I'm more likely to see it ;-) )",NA,NA,NA
116,96775340,sckott,2015-04-27T18:40:05Z,2015-04-27T18:40:05Z,All sound good :),NA,NA,NA
121,104008196,rvosa,2015-05-20T19:34:42Z,2015-05-20T19:34:42Z,"Are we still in the process of formulating a response to this? Sorry, I've been traveling, not sure if I need to provide input here.",NA,NA,NA
121,104011403,cboettig,2015-05-20T19:46:04Z,2015-05-20T19:46:04Z,"nope, we're all set & waiting on the editor's decision.  I only just got
permission to publically post the replies we made to reviewer 2 and the
associate editor, so I can have those up soon.  Sharing the reviews that
the reviewers agreed to share has been a very new thing for MEE, so this
process has been slightly bureaucratic.

On Wed, May 20, 2015 at 12:34 PM Rutger Vos <notifications@github.com>
wrote:

> Are we still in the process of formulating a response to this? Sorry, I've
> been traveling, not sure if I need to provide input here.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/121#issuecomment-104008196>.
>
",NA,NA,NA
121,104013160,rvosa,2015-05-20T19:50:18Z,2015-05-20T19:50:18Z,"Ah, ok - I thought that's where we were in the process. Just making sure.",NA,NA,NA
119,105274214,cboettig,2015-05-25T17:28:10Z,2015-05-25T17:28:10Z,"@hadley Thanks for this, now that the new testthat is available on CRAN I guess I can release this.  I hadn't done so earlier as the fix requires this `skip_if_not_installed()` function which wasn't available on previous `testthat` versions.  Not sure what the right strategy is in such cases.",NA,NA,NA
120,105276925,cboettig,2015-05-25T17:45:28Z,2015-05-25T17:45:28Z,"(Our replies to the associate editor, also posted with permission now)

--------------------------------

> A bit more of a focus on how the file format and R package can help users, rather than statements that you can get more things into it would be useful.  The section on metadata (p8 - 13) is a prime example of this.  It's clear that this is something that is important to the authors, but it's framed starting from a set of arbitrary looking commands, rather than from a problem that is not currently solvable.

This section has been substantially revised to be more accessible and problem focused. We have tried to strike a balance between documenting the technical aspects of the file format and R package while also addressing the bigger picture of appealing to users.  

> Similarly flagging which bits are for package developers (see below) might be helpful.  The strength of the ape package is that people have built other packages on top of it (~100 packages on CRAN).  Features pitched at package developers would necessarily be more technical in nature.

We have at several places highlighted sections that should be considered more advanced.  We have tried to present a continuum of complexity rather than strictly discriminating between users and developers; just as the R language itself blurs this distinction much more than previous, easy-to-use GUI driven software. (No doubt ape owes some of its success in accumulating reverse dependencies to the very fact that it did not much separate the user from the developer). 

We bear in mind too that some readers may come from a biodiversity informatics background instead of a background of using `ape`, and for whom a transparent expression of formal semantics concepts that will be foreign to the typical R user will be useful signposts. Having co-authors without any prior experience in R has helped us substantially in this regard.


> While the horse has well and truly bolted, I feel that S4 is the wrong technology for this sort of thing.  S4 classes will be a barrier for people to contribute to the package (personally I wish they could be removed from the language).  

We have designed RNeXML so that users can take advantage of its functionality and even develop extensions without knowledge of S4 using the function API. We also note that the XML R package is closely integrated with S4, automating many things that would otherwise be very tedious and error prone. A developer seeking to do things that cannot be done already be done with the user-facing RNeXML functions would have to confront the conversion of R structures to XML as we did, and thus would also benefit more than they lose by being able to take advantage of the S4-specific tools in the XML package.

> Nothing can be done about this, but that ape remains the primary way people interact with trees in R speaks to the benefits of ease of use and extension over formality for the R user and developer base at large (in contrast with ape, I see 4 declared dependencies on phylobase on CRAN).

We agree and are not trying to displace the `ape` structure. The RNeXML package works seamlessly to both generate ape::phylo trees from NeXML files and serialize ape::phylo trees as NeXML.

> Similarly, I wish the abstractions involved with XML were not so leaky.  Does the average user need to understand about Dublin Core and XML namespaces to be able to append metadata to their phylogenies?  Or do the authors imagine other user-friendly tools being built on top of RNeXML, with this package being some sort of solid low-level commands?  If one needs to deal with XML to read/write files that will be a serious barrier to use; most biologists should not need to care how their files are being loaded/saved.

Excellent points, much of this jargon has now been removed (e.g. 'Dublin Core,' and see further comments below). Where a concept is essential (such as 'namespace') we have explained the definition and the purpose more carefully.  We present examples of reading and writing that require no familiarity with XML. As noted above, we still introduce these topics in the more advanced sections, as they may be of interest to the biodiversity informatics community or the R user seeking to take advantage of those concepts.


> Despite the focus on formal validity (ostensibly the benefit of XML), it's somehow disturbing to me that there are additional checks not captured by the schema (l. 150).  I didn't get a sense of what these additional checks are.

These are checks constraints on nested references to identifiers (as detailed in the citation).  An example of such a constraint is as follows: ""a node in this trees block may only reference a taxon inside the taxa block referenced by the trees block that contains the node"". You simply can't say that in XML schema (it's hard enough to say it in English :-)), so you have to check for this kind of referential integrity in the application.  It is perhaps not clear why this is disturbing; for example, it is not possible to define such constraints in relational databases such as SQL, where similar checks are often done at the application level, as we do here. 

> The package as explained in the title is for reading/writing XML files of a particular format.  It's not clear why this takes >2700 lines of code (excluding comments).  Perhaps this is the necessary verbosity of dealing with S4 and XML, but I wonder if the authors are underselling some of the functionality of the package.  If the latter is true, that is their call of course.

Additional functionality is covered in the four vignettes, covering topics of more special interest. Specifying formal class structures and methods does require a bit of verbage. 

> l. 183 ""a time-stamp of when a tree was produced"": is this always a good idea?  I presume ""produced"" here is when the tree is written to file.  So reading and immediately writing a tree would update the timestamp?  This would mean that it's impossible to verify the results of an analysis are unchanged by comparing file hashes even if the contents are substantially unchanged.

This is the default behavior and can be configured. We have edited the text to address this now. 

> l. 196: for extending the syntax - will this not lead to downstream
incompatibilities as with the NEXUS format?  

Correct, as we state later in this section, the result is still valid NeXML and can still
be parsed by any of the many parsers available for NeXML (available in ruby, python, perl, java, and now R).  

> This section will be
quite opaque to most readers.  ""The RNeXML interface described above
for built-in metadata annotations perform this cast automatically
behind the scenes, including mapping metadata attributes to terms in
requisite common vocabularies (such as Dublin Core for ""title"",
""creator"", etc.) or ontologies"".

We have revised the introduction of this section accordingly:


""The `RNeXML` interface described above for built-in metadata allows
users to create precise and semantically rich annotations without 
confronting any of the complexity of namespaces and ontologies.
Nevertheless, advanced users may desire the explicit control over
these semantic tools to take full advantage of the flexibility
and extensibility of the NeXML specification [@Vos2012; @Parr2011].
In this section we detail how to accomplish these more complex uses
in RNeXML.""


As we have tried to highlight in the revisions, you are quite correct that this
section will probably be opaque to most readers who are not already familiar with
the biodiversity informatics literature.  Nonetheless we wanted to illustrate for
more advanced users or readers familiar with that literature how it could be applied
in RNeXML.  We do leave the most complex examples, such as SPARQL queries that illustrate
this machine reasoning in action, to the supplementary materials. 


> l. 272: I'm honestly not sure what this is meant to express.  I can't imagine that typing something like this is going to inspire people to get excited about using the package.  Presumably nobody would actually write such verbose commands, but package authors (e.g. Revell if using RNeXML storing data for reconstructions) would write functions that generate calls like this?

This example has been removed from the text.  It represented a simmap tree shown in Revell 2012.  Correct, no one would write such code by hand, as we had already stated.  Rather than present this example and then introduce the helper functions that illustrate how a developer would implement this, we now jump directly to discussing the  `nexml_to_simmap` and `simmap_to_nexml`, which convert between this format and Revell's extended `ape::phylo` simmap format. This section has also been shortened as more details are already available in the simmap vignette.  
",NA,NA,NA
119,105502638,hadley,2015-05-26T12:15:05Z,2015-05-26T12:15:05Z,"I think the best practice is to make it conditional, i.e.

```{r}
if (packageVersion(""testthat"") >= ""0.10.0"") {
  testthat::skip_if_not_installed(...)
}
```

but that's a reasonable amount of work for little gain in many cases.",NA,NA,NA
121,106958334,cboettig,2015-05-29T23:32:17Z,2015-05-29T23:32:17Z,"> I have two (related) critiques of this manuscript. The goal of the RNexML project is
to facilitate the use of NeXML standards in phylogenetics and comparative methods.
While the package certainly goes a long way towards this goal, I feel that the
manuscript could be better in this regard.

> 1. I think you need a better hook in the opening (and the abstract). Why should your
average empirical biologist care whether their files are in NeXMl format/why is it
worth bothering with (i.e., why not just deposit .tre and .csv files?) I can imagine
a few ""killer apps"", such as meta-analyses (both formal and informal) and populating
databases (such that it makes it easier to load trees into OpenTree) but these
aren't really described. While the manuscript describes why NeXML is superior to
NEXUS, I don't feel you provide sufficient examples or motivation as to why exactly
this is important. Perhaps this is not your role here -- you are not developing the
NeXML standards in this paper -- but if the goal is facilitating adoption among
empiricists, I think you need to be better marketers.

This is an excellent point also raised by the Associate Editor. We have tried to detail
some of this potential in the introduction, but ultimately feel that this task requires
a review of the biodiversity informatics literature that is beyond the scope (or word count!)
of this applications note, and instead must point the readers to some of the excellent
and accessible reviews of these concepts and possibilities elsewhere; e.g. Parr et al. paper
in TREE. 

> 2. The manuscript is jargon-laced and in some places, unnecessarily so. Even though
I am a programming dork (or at least more so than the average biologist), I did not
understand what you were referring to in some places. I think this is another
barrier that will hinder adoption -- I am afraid that an empirist will take one look
at this and conclude it is not for them.  Here is a list of some examples (there are
others) where I think the terminology is confusing; in some places, I think the
jargon could be cut without loss, while in others I think some explanation in plain
language would go a long way.

Thanks, the list below is very helpful.  In addition, we have cut back
the jargon considerably throughout the introduction and in some of the
most dense sections such as the advanced metadata use.

> line 10: forward-compatible

Replaced with 'extensible'

> line 17: normative

Dropped. (""XML schema"" is sufficient).

> line 60: validated

We've clarified the definition that follows to read:

""i.e., it can be verified whether a file precisely follows this grammar, and therefore whether it can be read (parsed) without errors by software that uses the NeXML grammar (e.g. RNeXML) is predictable""

> line 64: computable semantics

Now defined in the sentence following as:


""i.e., it can be verified whether a file precisely follows this grammar, and therefore whether it can be read (parsed) without errors by software that uses the NeXML grammar (e.g. RNeXML) is predictable""

> line 64: computable semantics

Now defined in the sentence following as:

 ""it is designed for expressing metadata such that machines can understand their meaning and make inferences from
 it. For example, OTUs in a tree or character matrix for frog species can be linked to concepts in a formally def
ined hierarchy of taxonomic concepts such as the Vertebrate Taxonomy Ontology [@Midford_2014], which enables a ma
chine to infer that a query for amphibia is to include the frog data in what is returned. (For a more broader dis
cussion of the value of such capabilities for evolutionary and biodiversity science we refer the reader to @Parr2
011.)""

> line 67: axiomated ontologies

removed.  The term ""ontology"" is re-introduced above, now with a definition, though the distinction between vocab
ulary and ontology is glossed over, and details are left to the citation to provide.

> line 202: subject-predicate-object triples

removed

> line 205: Dublin core

removed

> line 210: vocabularies

defined in introduction, see comment re line 64.

> line 240: SKOS vocabulary

defined and linked 



> line 248: SPARQL

defined and linked

> Minor comments on manuscript

> line 12: **you** aim to provide, not the software

fixed 

> line 83: where is the branch length information stored (in topology or metadata)?

along with the topology, thanks, this has been made explicit now. 

> line 44: an extra sentence here would be useful explaining why the needs of
interoperability are greater now then they have been in the past

Less diversity in tools meant their was less to inter-operate between. MrBayes decided
it needed something that couldn't be represented in the original NEXUS so they defined
a new convention for it.  So did PAUP, and so on, and so MrBayes NEXUS isn't the same
as a PAUP NEXUS file.  While word count constraints don't permit a proper treatment,
the Vos et al paper cited there which introduces the NeXML format provides a thorough
discussion of this point.

> line 141: I would appreciate it if you would please use Pennell et al. 2014
Bioinformatics as the geiger citation

Done, thanks. (You may want to update the citation information in the `geiger` package
as well; see `citation(""geiger"")`.  

> line 274: PDF weirdness

Fixed.

> Comments on code

> 1. In your example of writing nexml files, you use the geospiza dataset from geiger.
In this dataset, the tip labels in the tree and the dataset do not perfectly match

```
data(geospiza) geiger::treedata(geospiza$phy, geospiza$dat)
```



> Is this a feature or a bug of nexml? Either way, I think it is worth pointing out.

Yes, this is intentional and we have added a short clarification to the text:

""Note that the NeXML format is well-suited for incomplete data: for instance,
here it does not assume the character matrix has data for every tip in the tree.""


The function simply generates a tree object with all available data.
As you observe, a user can of course use `geiger::treedata` if they
need to drop incomplete taxa from either the tree or traits list,
but that is not the role of NeXML, which seeks to represent whatever
data is available.  Note also that because NeXML is easily extended,
you could in fact dump many character matrices into it, each perhaps
missing certain taxa, and then use RNeXML to help extract as complete
a character matrix as possible from the assembly.


> 2. I tried running the function `nexml_validate` while offline and received an error
message (even though I had the XML package installed and loaded)

```
nexml_validate(""geospiza.xml"") Error in function (type, msg, asError = TRUE)  :
Could not resolve host: www.nexml.org
```

We have since patched the R package so that it will use a fallback method to validate NeXML 
if the online validator is not available.  This function will now issue a warning if
it cannot connect to the online validator before using the fallback method.

> 3. I love the idea of being able to programmatically archive data (in figshare or
wherever else) but am wondering whether there is a potential problem in that people
may inadvertantly archive the same data over and over again. If for example, one
sets up the workflow to be completely reproducible, will the function add a new
version of the dataset every time the script is run. Are there safeguards built in
for this?

Good point -- we have updated this example to publish only a private (draft) version to figshare.
This reserves the identifier and facilitates collaboration, while a user will still
need to login online and flip the switch on figshare to make the data public.  These drafts
can also be deleted by the user either via the online interface or the `rfigshare` R package.

",NA,NA,NA
122,110583066,cboettig,2015-06-10T04:10:13Z,2015-06-10T04:10:13Z,"Thanks for the positive words and the bug report.  Looks like I can replicate this bug as well.

The segfault crashing R appears to arise from the plotting function in the `ape` package.  I'll report this to the ape maintainer and see if he has any ideas.  

The example tree shown there (`S100.xml`) was selected at random and seems to have some pathology for the `ape` plotting function that I do not see.  e.g. I do not get any errors trying other trees from the treebase data right now, e.g. `S101.xml`.  I'll have to dig deeper with the ape maintainer and find what it is about that tree that is causing ape to segfault.  

Cheers,

Carl",NA,NA,NA
122,110587041,wcornwell,2015-06-10T04:39:43Z,2015-06-10T23:36:42Z,"My guess is one or more non-splitting nodes in one of the trees?

",NA,NA,NA
122,110772102,fmichonneau,2015-06-10T14:22:56Z,2015-06-10T14:22:56Z,"For what it's worth,

plot(tr_phy[[1]][[1]])
plot(tr_phy[[1]][[2]])

work but plot(tr_phy[[1]][[3]]) and plot(tr_phy[[1]][[4]]) trigger the
segfault.





On Wed, Jun 10, 2015 at 12:39 AM, Will Cornwell <notifications@github.com>
wrote:

> My guess is one or more non-splitting nodes in one of the tree?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/122#issuecomment-110587041>.
>
",NA,NA,NA
122,112115809,cboettig,2015-06-15T15:48:40Z,2015-06-15T15:48:40Z,"@emmanuelparadis points out to me:

> I had a look at your trees using that function I put on github:

> https://github.com/emmanuelparadis/checkValidPhylo

> and they all return at least one FATAL message. I hope this may help
you to fix some issues in RNeXML.

> I'll look further how to catch such issues in the most efficient way
in ape.


I'll have to see if these issues are already present in the TreeBASE NeXML and figure out what the best way to handle them is. Perhaps we should still still parse the NeXML with `nexml_read` but refuse to return an ape format from `get_trees` if the trees do not pass these checks?",NA,NA,NA
96,142439095,hlapp,2015-09-22T22:24:35Z,2015-09-22T22:24:35Z,"The [v2.0.0 release](https://github.com/ropensci/RNeXML/releases/tag/v2.0.0) was archived in Zenodo, which is referenced in the paper: [![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.13131.svg)](http://dx.doi.org/10.5281/zenodo.13131)

There are newer v2.0.x tags since then, which haven't been made into point releases yet, but that's I think separate from this issue.",NA,NA,NA
112,142439206,hlapp,2015-09-22T22:25:21Z,2015-09-22T22:25:21Z,Fixed in 30992c11802b2d09ec8abbad897c3695a93f8963.,NA,NA,NA
108,142439500,hlapp,2015-09-22T22:26:57Z,2015-09-22T22:26:57Z,"I don't think we've addressed this for the manuscript (and it's more a general modeling improvement issue, I would say), and so I'm de-coupling this from the manuscript milestone again.",NA,NA,NA
108,142439886,cboettig,2015-09-22T22:29:34Z,2015-09-22T22:29:34Z,:+1:,NA,NA,NA
124,142442931,cboettig,2015-09-22T22:48:52Z,2015-09-22T22:48:52Z,"Yes, is due to issue #51.

I believe this is essentially because NeXML namespaces attribute values, which XML treats as strings.  @hlapp's solution in #51 looks reasonable but has not yet been implemented.  ",NA,NA,NA
125,142443086,hlapp,2015-09-22T22:49:51Z,2015-09-22T22:50:01Z,@cboettig or @sckott if you could look into this soon that'd be great. It's essentially a showstopper right now for using RNeXML for the RPhenoscape package.,NA,NA,NA
125,142444833,sckott,2015-09-22T23:00:56Z,2015-09-22T23:00:56Z,I'll take a look,NA,NA,NA
125,142453429,sckott,2015-09-22T23:37:11Z,2015-09-22T23:38:54Z,"hmmm, the file doesn't validate on nexml.org http://www.nexml.org/ - doe that not matter? (or do via `RNeXML::nexml_validate`)

here https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test.xml#L35 you have `xsi:type=""ns:StandardCells""`, whereas the relevant fxn here is looking for `nex:StandardCells`  https://github.com/ropensci/RNeXML/blob/master/R/get_characters.R#L24-L39",NA,NA,NA
125,142457419,sckott,2015-09-23T00:05:48Z,2015-09-23T00:05:48Z,"@xu-hong @hlapp okay, i pushed a change to a different branch, fixes for me locally, can test from there, 

`devtools::install_github(""ropensci/RNeXML"", ref = ""sckott-char-fix"")`

@cboettig not sure if this change is the best one. 

* I think https://github.com/ropensci/RNeXML/commit/0340607bef662487eaa8ee0715bd3541c35bb62b?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR214 makes sense, but
* not sure if https://github.com/ropensci/RNeXML/commit/0340607bef662487eaa8ee0715bd3541c35bb62b?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR24 and  https://github.com/ropensci/RNeXML/commit/0340607bef662487eaa8ee0715bd3541c35bb62b?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR30 is the best solution, 

thoughts?",NA,NA,NA
125,142557053,rvosa,2015-09-23T10:21:31Z,2015-09-23T10:21:31Z,"In principle this ought to work: the namespace declaration specifies the
prefix 'ns' as being bound to 'http://www.nexml.org/2009' so actually this
is correct. In the R code the prefix 'nex' is hardcoded, when one should
not actually make the assumption that that prefix is always used. Better
would be to make a map of namespace URIs to prefixes (and back) so that
foo:StandardCells also works as long as the declaration xmlns:foo=""
http://www.nexml.org/2009"" is inherited from any of the containing elements.

On Wed, Sep 23, 2015 at 1:37 AM, Scott Chamberlain <notifications@github.com
> wrote:

> hmmm, the file doesn't validate on nexml.org http://www.nexml.org/ - doe
> that not matter?
>
> here
> https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test.xml#L35
> you have xsi:type=""ns:StandardCells"", whereas the relevant fxn here is
> looking for nex:StandardCells
> https://github.com/ropensci/RNeXML/blob/master/R/get_characters.R#L24-L39
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/125#issuecomment-142453429>.
>
",NA,NA,NA
125,142640223,sckott,2015-09-23T15:30:53Z,2015-09-23T15:30:53Z,"thanks @rvosa , looking in to mapping namespaces",NA,NA,NA
125,142647512,sckott,2015-09-23T15:58:41Z,2015-09-23T15:58:41Z,"Okay, updated namespace mapping https://github.com/ropensci/RNeXML/compare/master...sckott-char-fix - `ns` was missing

Also generalized `get_characters_list()` to not be hard-coded to a specific namespace -

all examples and tests pass, so I think this shouldn't break anything

`devtools::install_github(""ropensci/RNeXML"", ref = ""sckott-char-fix"")`",NA,NA,NA
125,142662238,cboettig,2015-09-23T16:58:24Z,2015-09-23T16:58:24Z,"Nice work Scott in tracking it down to the namespace issue.  Looks like this is essentially a version of issue #51, where the problem is that the attribute values, as well as the attribute names, are namespaced.  The XML package has native support for arbitrary namespace abbreviations in any XML fields (node names, attribute names, etc) but the attribute values are treated as strings and I'm not sure if there's a good generic fix for that.  @rvosa how have you handled this in other languages? Do they just support namespaced values out of the box?  

Hilmar [suggested](https://github.com/ropensci/RNeXML/issues/51#issuecomment-48205335) expanding all the prefix values using the full namespace definitions, presumably by just doing regex substitution on every single value field in the XML document, though I think implementing that in way that isn't too fragile would be tricky.  (For instance, if I recall correctly XML permits omitting the namespace and inheriting it from a default, e.g. `<state>` instead of `<nex:state>` , and these can be inherited from parent elements as well as from the top-level, right?)  So in general I'm not sure what the right way to solve this problem is.  For the moment, I think Scott's solution is best, in which we recognize `StandardCells` etc regardless of the namespace to which it has been assigned.  ",NA,NA,NA
125,142689678,sckott,2015-09-23T18:28:58Z,2015-09-23T18:28:58Z,"@cboettig Okay, let let me know if you want me to PR that branch to master",NA,NA,NA
125,142690846,cboettig,2015-09-23T18:33:51Z,2015-09-23T18:33:51Z,"@sckott yup, go ahead with a PR.  

Looking at @rvosa 's [comments](https://github.com/ropensci/RNeXML/issues/51#issuecomment-48178815) in the #51 thread, it looks like namespaces on values is a generic problem that probably isn't automatically handled by other NeXML parsers either, so IMHO your solution is best (e.g. less fragile than any of the alternatives suggested).  ",NA,NA,NA
125,142880660,rvosa,2015-09-24T10:06:25Z,2015-09-24T10:06:25Z,"> Hilmar suggested
> <https://github.com/ropensci/RNeXML/issues/51#issuecomment-48205335>
> expanding all the prefix values using the full namespace definitions,
> presumably by just doing regex substitution on every single value field in
> the XML document, though I think implementing that in way that isn't too
> fragile would be tricky. (For instance, if I recall correctly XML permits
> omitting the namespace and inheriting it from a default, e.g. <state>
> instead of <nex:state> , and these can be inherited from parent elements
> as well as from the top-level, right?)
>
They can be inherited from any ancestral element that can override each
other, the most recent ancestor taking precedence. Doing a global search
and replace could therefore result in hard to track down bugs.

My sense is that it's really best to have an actual mapping such that from
any focal element you can traverse towards the root and find the nearest
ancestor that binds prefix 'foo' to a namespace.

What @hlapp suggests is basically precomputing this approach during an
initial traversal so that in pre-order you read/update the mapping for
'foo' as you move towards the tips and then replace 'foo:bar' with '{
http://example.org}:bar' as you encounter it. When you look at how XML
editing / processing tools internally represent namespaced elements and
attributes, that's basically what they do (including the curly braces,
even).

So in general I'm not sure what the right way to solve this problem is. For
> the moment, I think Scott's solution is best, in which we recognize
> StandardCells etc regardless of the namespace to which it has been
> assigned.
>
That's probably going to work for 99% of all cases, at least until someone
else comes up with the same name in a different namespace, at which point
this will need to be addressed structurally. I'm actually not strongly
opposed to pragmatically doing it this way if that means the current issues
are fixed, as long as we're aware that it's quite possible we'll have
problems down the line.
",NA,NA,NA
125,142936676,cboettig,2015-09-24T14:00:01Z,2015-09-24T14:00:01Z,"Thanks Rutger!

> What @hlapp suggests is basically precomputing this approach during an initial traversal so that in pre-order you read/update the mapping for 'foo' as you move towards the tips and then replace 'foo:bar' with '{ http://example.org}:bar' as you encounter it. When you look at how XML editing / processing tools internally represent namespaced elements and attributes, that's basically what they do (including the curly braces, even).

Right, but I guess what I'm not clear on here is how we are supposed to handle the case where no namespace is applied, and thus there is no `:` to split upon (or otherwise the `:` is not related to a namespace).  e.g. one can have:

```
<characters xsi:type=""ns:StandardCells"" ...
```
instead of the more explicit:

```
<ns:characters xsi:type=""ns:StandardCells"" ..
```

So if we are playing by the rules of inheritance in xml, shouldn't it also be valid to have:

```
<characters xsi:type=""StandardCells"" ..
```

Where the `ns` is assumed for both?  Or do we always namespace attribute values?  If we can omit them, I'm not sure how to do the preprocessing, since I don't think we'd want to expand all attribute values to the default, since some of these are explicitly not namespaced, e.g. lengths, or `symbol=1` shouldn't become `symbol=http://www.nexml.org/2009:1` right?  Happy to fix this but I just haven't figured out the implementation in my head because of these details.  

> That's probably going to work for 99% of all cases, at least until someone else comes up with the same name in a different namespace

Right. And Scott's implementation is specific to the `xsi:type` value of the `<characters>` element, so it would have to be a namespace that defined valid for that specific location, and not just any namespace, right?  I get the value of namespaces in general but in this specific context it really feels like it is going to be much safer to treat the value of an attribute as a string. 

As you commented in #51, it sounds like this case might be trouble for other NeXML parsers as well, which might hardwire a particular prefix rather than attempt to namespace the attribute values.

I've merged Scott's fix to master, so feel free to close if the current fix seems to address the issue.  ",NA,NA,NA
125,142969625,rvosa,2015-09-24T15:48:47Z,2015-09-24T15:48:47Z,"Hi Carl,

> Right, but I guess what I'm not clear on here is how we are supposed to
> handle the case where no namespace is applied, and thus there is no : to
> split upon (or otherwise the : is not related to a namespace). e.g. one
> can have:
>
> <characters xsi:type=""ns:StandardCells"" ...
>
> instead of the more explicit:
>
> <ns:characters xsi:type=""ns:StandardCells"" ..
>
> In the former case, without a prefix, the default namespace of the focal
context applies to the element. This namespace can be identified by
traversing from the focal element to the root looking for the nearest
xmlns=""http://example.org"", as opposed to xmlns:ns=""http://example.org"".

In most NeXML documents this will lead you back to the root element, which
often has an xmlns=""http://www.nexml.org/2009"" on it. Of course for any
given focal element only a single default namespace can be in effect.
Multiple xmlns="""" statements on the same enclosing element are invalid. If
there are nested default namespace declarations, the most recent ancestor
takes precedence.

> So if we are playing by the rules of inheritance in xml, shouldn't it also
> be valid to have:
>
> <characters xsi:type=""StandardCells"" ..
>
>
Nice try, and that would make total sense if in this case we were playing
by the rules of namespace prefix inheritance in xml attribute values.
Unfortunately, we've now left that particular rule book and are moving on
to some other ones. In NeXML there are three separate situations where we
have attribute values that have colons in them:

1. the current case where we specify which schema subtype an element
instance implements. This is done using these xsi:type statements, and the
value *must* always be a QName, i.e. fully qualified, with prefix and
colon. In implementing a mapping between prefixes and namespaces that, at
least, should be some relief.

2. the case where we specify what the datatype is of the content
attribute's value of a meta element. For example, datatype=""xsd:string"".
Here we also reference a schema (sub)type. Hence: *must* be a QName.

3. property names in meta elements. In that case the rules of RDFa apply,
i.e. the property name must be a CURIE (http://www.w3.org/TR/curie/), which
nearly always are QNames, though the production rules of the W3C CURIE
grammar imply that a CURIE may not have a prefix, but still have a colon
(i.e. property="":foo""), or even omit the colon.

For our parsers case 1. is by far the most important, especially if we
assume that our parsers don't actually try to interpret the semantics of
property names or the data types of content values in meta elements. The
fact that CURIEs are also intended to be used in non-XML documents (i.e.
totally outside of the context of this namespace malarkey) suggests that we
can more or less safely treat property names as string literals when
internally representing meta annotations if all we care about is
roundtripping.

Of course if you do want to do something with CURIEs and you want to be
sure that ""dc:title"" is in fact the ""title"" predicate from the Dublin Core
vocabulary, well, then you *will* have to start scanning for namespace
prefixes in the ancestors.

So, in the simple case of us not actually trying to interpret the semantics
of meta annotations:

<meta content=""Mycologia"" datatype=""xsd:string"" id=""meta17"" property=""
dc:publisher"" xsi:type=""nex:LiteralMeta""/>

- datatype=""xsd:string"" - probably don't need to care about this unless we
want to store the value of the content attribute in some clever way.
""Mycologia"" is a string anyway, but you can imagine that for number types
it might make sense to represent it internally as a number that you can do
maths with. If all you care about is round-tripping and you're not going to
interpret the annotation, don't worry about this case of a namespaced
attribute value. Anyhow, this will always be a QName.

- property=""dc:publisher"" - don't need to care about this unless you are
going to interpret this and want to know for sure that dc:publisher refers
to the Dublin Core and not some other vocabulary with different semantics.
This is a CURIE which therefore may not have a namespace prefix, though
this is rare.

- xsi:type=""nex:LiteralMeta"" - this one is important: a parser will have to
distinguish between nex:LiteralMeta and nex:ResourceMeta, because they are
different element structures (in nex:ResourceMeta the value of the
annotation is a ""resource"", which either means that the element has an
attribute 'href', or the element encloses literal XML, whereas
nex:LiteralMeta has a literal value, which is defined by the content
attribute). This is a QName, which always has a prefix.

> Where the ns is assumed for both? Or do we always namespace attribute
> values? If we can omit them, I'm not sure how to do the preprocessing,
> since I don't think we'd want to expand all attribute values to the
> default, since some of these are explicitly not namespaced, e.g. lengths,
> or symbol=1 shouldn't become symbol=http://www.nexml.org/2009:1 right?
> Happy to fix this but I just haven't figured out the implementation in my
> head because of these details.
>
The number 1 is a simple literal, so it wouldn't really be namespaced. By a
pretty poor analogy you can think of this along similar lines as the
primitives in Java (int, char, etc.) versus objects. For objects, their
behaviour is determined by the class they were instantiated from and which
therefore are sort-of namespaced in that class, whereas primitives are not.
I know this doesn't help that much - it just illustrates that both XML
schema as well as Java are pretty inconsistent in similar ways.


> That's probably going to work for 99% of all cases, at least until someone
> else comes up with the same name in a different namespace
>
> Right. And Scott's implementation is specific to the xsi:type value of
> the <characters> element, so it would have to be a namespace that defined
> valid for that specific location, and not just any namespace, right? I get
> the value of namespaces in general but in this specific context it really
> feels like it is going to be much safer to treat the value of an attribute
> as a string.
>
Well, maybe. The xsi:type pops up in a number of places, one of which
specifies the subtype that a character state matrix implements. The other
two cases are that it occurs on tree elements (in practice this is
basically to specify whether branch lengths are integers or reals) and on
meta elements (as noted above).

In all three cases, some kind of branching or dispatching depending on the
specific subtype is probably going to have to be done (maybe not with the
number types for branch lengths?) so it makes sense to think for a bit
about a reasonably generic approach that makes as little assumptions about
usually-but-not-always-hardcoded prefixes as possible.

> As you commented in #51 <https://github.com/ropensci/RNeXML/issues/51>,
> it sounds like this case might be trouble for other NeXML parsers as well,
> which might hardwire a particular prefix rather than attempt to namespace
> the attribute values.
>
> I've merged Scott's fix to master, so feel free to close if the current
> fix seems to address the issue.
>
",NA,NA,NA
125,142974462,cboettig,2015-09-24T16:06:53Z,2015-09-24T16:06:53Z,"@rvosa ah ha! Right, of course I had forgotten that these types were constrained by the schema to begin with, so that makes perfect sense.  Thanks much for the detailed reply, that does clear things up for me.  ",NA,NA,NA
125,143499469,hlapp,2015-09-26T22:03:52Z,2015-09-26T22:03:52Z,"> hmmm, the file doesn't validate on nexml.org http://www.nexml.org/ - doe that not matter? (or do via `RNeXML::nexml_validate`)

Just for the record, the file had to be modified from the original returned by the Phenoscape API, because otherwise RNeXML throws an error when loading it. See #124.",NA,NA,NA
125,143500034,hlapp,2015-09-26T22:11:04Z,2015-09-26T22:11:17Z,"> @cboettig not sure if this change is the best one.
> 
> * I think 0340607?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR214 makes sense, but
> * not sure if 0340607?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR24 and
> * 0340607?w=1#diff-0a17c9effc561b26fb9890f0d9fcec7cR30 is the best solution,
>
> thoughts?

Perhaps this will help in the short-term with the output the Phenoscape API is returning (@balhoff - what are your plans to make this less verbose and more compliant with prefix conventions ? See #124) but I'm assuming we all understand that this is only a temporary fix?",NA,NA,NA
125,143595756,cboettig,2015-09-27T21:21:04Z,2015-09-27T21:21:04Z,"@hlapp Correct, this is a temporary fix for the problem described in the title of this issue thread.  The deeper is issue has already been logged as issue #51, as noted above, which still awaits a proper solution.  As highlighted in #51, this issue may be impacting other nexml parsers as well, since most XML libraries, e.g. libxml2 on which `XML` is built, deal with the namespaces of XML elements automatically but don't have a native implementation for namespaces of attributes; even though as Rutger clarified for me that use is well-defined in via the schema file.  

I feel the long term issue here would be far better off if it was addressed by more fundamental XML/XML schema infrastructure to handle namespaces on attributes rather than just patched for RNeXML alone, but I don't think I'm in a good position presently to do this.  Maybe Duncan's XMLSchema package or something else will one day provide us the best tools to handle this case. ",NA,NA,NA
124,143836262,balhoff,2015-09-28T18:32:39Z,2015-09-28T18:32:39Z,@hlapp in the next few weeks I will try to look into how to remove the redundant namespace declarations. I recall that it resulted from my workaround for the fact that the XML library I was using didn't automatically handle namespaces for attribute values.,NA,NA,NA
127,144392323,cboettig,2015-09-30T13:19:27Z,2015-09-30T13:19:27Z,"Thanks!

 I think this is mostly due to the new phytools release, but in my queue.",NA,NA,NA
126,144524965,hlapp,2015-09-30T20:05:59Z,2015-09-30T20:05:59Z,"Am I right that this can only be expected to fix the character matrix extraction from the XML? @xu-hong and I continue to see the same issue with `nexml_read()` failing to read the NeXML emitted by the Phenoscape API. 

The character matrix extraction now succeeds if the Phenoscape API output is manually modified to use `nex:LiteralMeta` instead of `ns:LiteralMeta` etc.

FYI, the error from `nexml_read()` is the following:
```
 Error in fromNeXML(new(type[1]), from) : 
  error in evaluating the argument 'obj' in selecting a method for function 'fromNeXML': Error in getClass(Class, where = topenv(parent.frame())) : 
  “ns:LiteralMeta” is not a defined class 
```",NA,NA,NA
124,144525608,hlapp,2015-09-30T20:07:57Z,2015-09-30T20:09:50Z,"As an addition piece of information, here is the error that results from `nexml_read()` on the output returned by the Phenoscape API:

```
 Error in fromNeXML(new(type[1]), from) : 
  error in evaluating the argument 'obj' in selecting a method for function 'fromNeXML': Error in getClass(Class, where = topenv(parent.frame())) : 
  “ns:LiteralMeta” is not a defined class 
```

Traceback:
```R
15 fromNeXML(new(type[1]), from) 
14 asMethod(object) 
13 FUN(X[[i]], ...) 
12 lapply(kids[names(kids) == ""meta""], as, ""meta"") 
11 initialize(value, ...) 
10 initialize(value, ...) 
9 new(""ListOfmeta"", lapply(kids[names(kids) == ""meta""], as, ""meta"")) 
8 .nextMethod(obj = obj, from = from) 
7 callNextMethod() 
6 fromNeXML(new(""nexml""), from) 
5 fromNeXML(new(""nexml""), from) 
4 asMethod(object) 
3 as(xmlRoot(doc), ""nexml"") 
2 nexml_read(""./inst/examples/test_original.xml"") at pk_ontotrace.R#56
1 rphenoscape::test_nexml() 
```",NA,NA,NA
126,144537775,cboettig,2015-09-30T20:45:28Z,2015-09-30T20:45:28Z,"You're correct.  We need to go through the code and replace all the hard-wired namespaces on attribute elements with the same fix of at least stripping the namespace (though ultimately we should rather be expanding it based on the declaration, but that gets messy very quickly since it cannot be handled by the existing XML namespace logic, as it is defined only at the schema level)",NA,NA,NA
126,144542306,hlapp,2015-09-30T21:05:34Z,2015-09-30T21:05:47Z,"@cboettig am I right that if the Phenoscape API returned NeXML with `nex:` as the namespace for attribute values that that should then work out of the box and not be dependent on when you get around to make this fix? cc @balhoff

We're trying to determine how we can best make progress here because this is now holding up rphenoscape. I'd love if we don't have to go to the extent of subjecting returned NeXML to wholesale string substitution - that'd be pretty messy.",NA,NA,NA
126,144545441,balhoff,2015-09-30T21:16:38Z,2015-09-30T21:16:38Z,@hlapp I will look at how I might switch to `nex:` ASAP.,NA,NA,NA
126,144567178,cboettig,2015-09-30T22:45:54Z,2015-09-30T22:45:54Z,"Yes that should fix it

On Wed, Sep 30, 2015, 2:16 PM Jim Balhoff <notifications@github.com> wrote:

> @hlapp <https://github.com/hlapp> I will look at how I might switch to
> nex: ASAP.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/pull/126#issuecomment-144545441>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
126,144590285,balhoff,2015-10-01T01:30:13Z,2015-10-01T01:30:24Z,"So do the attribute values need to have the `nex:` prefix? Ideally they wouldn't have any prefix at all since the default namespace of the whole document is NeXML. The schema defines these as QNames, for which I believe the prefix is optional (so that you can use the default namespace).

http://www.w3.org/TR/1999/REC-xml-names-19990114/#dt-qname",NA,NA,NA
124,144591557,balhoff,2015-10-01T01:38:58Z,2015-10-01T01:39:14Z,"I was wrong that it was a workaround I did. I use the XMLbeans API to write the documents. It looks like it always redundantly declares a namespace for writing QName attribute values (it's safer). I know how to specify namespace prefixes for the whole document, but haven't yet found a way to specify which prefixes I want for these QName values.",NA,NA,NA
126,144592468,cboettig,2015-10-01T01:46:10Z,2015-10-01T01:46:10Z,"I agree, ideally no namespace at all.  Some have hardwired nex namespace
right now, I should be able to fix that as soon as I get a free moment at a
computer. Sorry to be the slow cog

On Wed, Sep 30, 2015, 6:30 PM Jim Balhoff <notifications@github.com> wrote:

> So do the attribute values need to have the nex: prefix? Ideally they
> wouldn't have any prefix at all since the default namespace of the whole
> document is NeXML. The schema defines these QNames, for which I believe the
> prefix is optional (so that you can use the default namespace).
>
> http://www.w3.org/TR/1999/REC-xml-names-19990114/#dt-qname
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/pull/126#issuecomment-144590285>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
128,144604374,cboettig,2015-10-01T03:07:48Z,2015-10-01T03:07:48Z,"Right, but these errors come straight from the nexml.org validator, and I get the same errors when I just upload the file to the browser, so this is not an RNeXML issue.  

Incidentally, I'm getting validation errors from the nexml.org validator when I try with no namespaces on the elements as well (just as we discussed), even though I would have thought the default namespace would be inferred.  @rvosa did I misunderstand something here?  Possibly this is a bug on the validator?",NA,NA,NA
126,144604937,cboettig,2015-10-01T03:15:28Z,2015-10-01T03:15:28Z,"Gave this a try on `drop-nex` branch, but hitting validator issues on my tests that seem to be related to the absence of namespaces on these attributes (now that I fixed tests on master, sorry about that too).  see #128 

```
Validation failed, error messages: 
                    Can't locate Bio/Phylo/Matrices/Datatype/Continuouscells.pm in @INC (@INC contains: ../site/lib ../../bio-phylo/lib ../../perllib/arch ../../perllib /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at ../../bio-phylo/lib/Bio/Phylo/Util/CONSTANT.pm line 242, <DATA> line 1.
```",NA,NA,NA
128,144667884,rvosa,2015-10-01T09:23:52Z,2015-10-01T09:23:52Z,"These errors are not mysterious at all: XML identifiers (that is, id
attributes that can be referenced elsewhere in a document) have to be
""non-colonized names"" (NCName). URIs are not suited for this: they contain
colons, as well as other characters that (AFAIK) are also not allowed under
the production rules for NCNames (namely, the forward slashes).

On Wed, Sep 30, 2015 at 11:37 PM, Hilmar Lapp <notifications@github.com>
wrote:

> Here's the log:
>
> > nexml_validate(""./inst/examples/test_original.xml"")
> [1] FALSEWarning message:In nexml_validate(""./inst/examples/test_original.xml"") :
>   Validation failed, error messages:
>                     'http://purl.obolibrary.org/obo/VTO_0036225' is not a valid xml NCName for Bio::Phylo::Taxa::Taxon=SCALAR(0x1ce5440)            Validation failed, error messages:
>                     'http://purl.obolibrary.org/obo/VTO_0036225' is not a valid xml NCName for Bio::Phylo::Taxa::Taxon=SCALAR(0x1ce5440)
>
> The file
> <https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test_original.xml>
> is the original NeXML returned by the Phenocape API.
>
> One thing that might come into play here is the use of HTTP URIs as local
> identifiers. I have filed issue phenoscape/phenoscape-kb-services#15
> <https://github.com/phenoscape/phenoscape-kb-services/issues/15> for
> whether this is on purpose, and what motivates it.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/128>.
>
",NA,NA,NA
128,144668590,rvosa,2015-10-01T09:27:18Z,2015-10-01T09:27:18Z,"> Incidentally, I'm getting validation errors from the nexml.org validator
> when I try with no namespaces on the elements as well (just as we
> discussed), even though I would have thought the default namespace would be
> inferred. @rvosa <https://github.com/rvosa> did I misunderstand something
> here? Possibly this is a bug on the validator?
>
It is impossible to say without seeing the input file and the log. Apart
from the integrity checks about whether the right blocks are referring to
each other (which you can't really express in XML Schema) the validation is
for the most part a totally generic XML Schema validation that involved
essentially zero coding on my end, so the scope for bugs there is probably
limited.
",NA,NA,NA
126,144669204,rvosa,2015-10-01T09:30:58Z,2015-10-01T09:30:58Z,"Mmmm... this actually does look like a bug on the end of the validator,
that is, the part that does the reference checking (which I had to code ""by
hand""). The hand-coded part of the validator - wrongly - expects that
xsi:type statements always have a namespace prefix.

On Thu, Oct 1, 2015 at 5:15 AM, Carl Boettiger <notifications@github.com>
wrote:

> Gave this a try on drop-nex branch, but hitting validator issues on my
> tests that seem to be related to the absence of namespaces on these
> attributes (now that I fixed tests on master, sorry about that too). see
> #128 <https://github.com/ropensci/RNeXML/issues/128>
>
> Validation failed, error messages:
>                     Can't locate Bio/Phylo/Matrices/Datatype/Continuouscells.pm in @INC (@INC contains: ../site/lib ../../bio-phylo/lib ../../perllib/arch ../../perllib /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at ../../bio-phylo/lib/Bio/Phylo/Util/CONSTANT.pm line 242, <DATA> line 1.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/pull/126#issuecomment-144604937>.
>
",NA,NA,NA
126,144673187,rvosa,2015-10-01T09:38:38Z,2015-10-01T09:38:38Z,"Well, mmmm..., wait a sec. How is the type name written? It needs to be
CamelCase, i.e. ContinuousCells. Is it possible that this is not done
correctly?
",NA,NA,NA
128,144707458,hlapp,2015-10-01T12:05:40Z,2015-10-01T12:05:40Z,The XML isn't valid. See @balhoff's comments on phenoscape/phenoscape-kb-services#15,NA,NA,NA
128,144748887,cboettig,2015-10-01T14:42:42Z,2015-10-01T14:42:42Z,"@rvosa @hlapp @balhoff Thanks, that makes perfect sense in the case of the phenoscape example.

I'm still a little confused by the validation with respect to having namespace prefixes like`nex:` on the values of attributes (particularly the value of `xsi:type` attributes.  For instance, [this NeXML file](https://github.com/ropensci/RNeXML/blob/master/inst/examples/meta_example.xml) is valid by the online validator, and it uses bare `xsi:type` values in meta elements, e.g. it uses:

```xml
 <meta xsi:type=""LiteralMeta""
```

instead of 

```xml
 <meta xsi:type=""nex:LiteralMeta""
```

However, when I remove the `nex:` prefixes from [this other valid NeXML](https://github.com/ropensci/RNeXML/blob/master/inst/examples/characters.xml) character `xsi:type` values, it stops being valid.  Why?  Why isn't the top level namespace inferred automatically?

If I understood from recent discussion, we felt that it was best to ignore these prefixes until we could expand them properly, and when generating XML to omit them for compatibility.  Maybe I got that wrong.  ",NA,NA,NA
126,144750904,cboettig,2015-10-01T14:50:40Z,2015-10-01T14:50:40Z,"I think the name is correct, all that changed is the removal of the prefix.  I put links to example XML files in #128 where I just removed the prefix and the validator gets unhappy.  It does look like the validator gives the error message in not-quite camelCase even though the original file is camelCased. (sorry to cross my threads, but see #128)",NA,NA,NA
128,144752154,rvosa,2015-10-01T14:54:29Z,2015-10-01T14:54:29Z,"On Thu, Oct 1, 2015 at 4:42 PM, Carl Boettiger <notifications@github.com>
wrote:

> @rvosa <https://github.com/rvosa> @hlapp <https://github.com/hlapp>
> @balhoff <https://github.com/balhoff> Thanks, that makes perfect sense in
> the case of the phenoscape example.
>
> I'm still a little confused by the validation with respect to having
> namespace prefixes likenex: on the values of attributes (particularly the
> value of xsi:type attributes. For instance, this NeXML file
> <https://github.com/ropensci/RNeXML/blob/master/inst/examples/meta_example.xml>
> is valid by the online validator, and it uses bare xsi:type values in
> meta elements, e.g. it uses:
>
>  <meta xsi:type=""LiteralMeta""
>
> instead of
>
>  <meta xsi:type=""nex:LiteralMeta""
>
> However, when I remove the nex: prefixes from this other valid NeXML
> <https://github.com/ropensci/RNeXML/blob/master/inst/examples/characters.xml>
> character xsi:type values, it stops being valid. Why? Why isn't the top
> level namespace inferred automatically?
>

I wonder what would happen if you removed the xsi:schemaLocation attribute
from the file that fails if the xsi:type is not fully qualified. In your
former case (the file that succeeds whether or not there is a prefix) we
don't actually say anywhere explicitly where the schema is located - though
the validator knows, on the basis of the namespace URI. In the latter, we
do give a schema location. Perhaps the validator tries (and fails) to do
something with that in the case of the default namespace?
",NA,NA,NA
126,144752626,rvosa,2015-10-01T14:55:31Z,2015-10-01T14:55:31Z,"Ok, then there is a bug in the parser on the server....

On Thu, Oct 1, 2015 at 4:50 PM, Carl Boettiger <notifications@github.com>
wrote:

> I think the name is correct, all that changed is the removal of the
> prefix. I put links to example XML files in #128
> <https://github.com/ropensci/RNeXML/issues/128> where I just removed the
> prefix and the validator gets unhappy. It does look like the validator
> gives the error message in not-quite camelCase even though the original
> file is camelCased. (sorry to cross my threads, but see #128
> <https://github.com/ropensci/RNeXML/issues/128>)
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/pull/126#issuecomment-144750904>.
>
",NA,NA,NA
126,144760741,rvosa,2015-10-01T15:20:53Z,2015-10-01T15:20:53Z,"I applied a fix to the parser so that it now accepts xsi:type attributes
without namespace prefixes:
https://github.com/rvosa/bio-phylo/commit/ec6ab9446a133e3d0943cdd565736de1f13bf1da
",NA,NA,NA
126,144784656,cboettig,2015-10-01T16:51:07Z,2015-10-01T16:51:07Z,"Nice, thanks. Is that live on the online validator now?",NA,NA,NA
126,144983313,rvosa,2015-10-02T10:15:56Z,2015-10-02T10:15:56Z,"Not yet, I'm afraid. I'm in a bit of a bind with this: nexml.org is still
being hosted on a nescent server where I can't expect a great deal of
support (for obvious reasons). What I really should be doing is reinstall
the website on a naturalis server. All the arrangements for that are in
place but it'd take a bit more time than I have today. Can we live with the
fact that non-prefixed xsi:type attributes should validate, which they do
locally, but that this will take till some time next week to become live?

On Thu, Oct 1, 2015 at 6:51 PM, Carl Boettiger <notifications@github.com>
wrote:

> Nice, thanks. Is that live on the online validator now?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/pull/126#issuecomment-144784656>.
>
",NA,NA,NA
126,144997750,hlapp,2015-10-02T11:53:55Z,2015-10-02T11:53:55Z,Validation isn't mandatory to succeed for reading a file to succeed so I suppose this isn't a hold up.,NA,NA,NA
126,145021066,cboettig,2015-10-02T13:33:33Z,2015-10-02T13:33:33Z,"@rvosa No problem, no rush from me, I just wanted to make sure that the errors I still got were not due to something else I screwed up.  

@hlapp Meanwhile, can you just try the `drop-nex` branch?  Like I mentioned, it's still failing some tests, I think all due to this but maybe not; I haven't had time myself to debug more. Hopefully it should fix all those issues. ",NA,NA,NA
126,145024613,hlapp,2015-10-02T13:43:51Z,2015-10-02T13:43:51Z,"> @hlapp Meanwhile, can you just try the drop-nex branch? Like I mentioned, it's still failing some tests, I think all due to this but maybe not; I haven't had time myself to debug more. Hopefully it should fix all those issues.

This should go to @xu-hong. I won't have time before Wednesday next week.",NA,NA,NA
126,145028342,rvosa,2015-10-02T13:54:14Z,2015-10-02T13:54:14Z,">
> @rvosa <https://github.com/rvosa> No problem, no rush from me, I just
> wanted to make sure that the errors I still got were not due to something
> else I screwed up.
>
Well, I guess I can't say for sure ;-)

But errors that spit out messages such as ""Can't locate
Bio/Phylo/Matrices/Datatype/XXX.pm in @INC..."" are ones that are triggered
because the fix hasn't gone live yet.
",NA,NA,NA
126,145136253,xu-hong,2015-10-02T19:40:15Z,2015-10-02T19:40:15Z,"@cboettig @hlapp  
Hi I tried the ```drop-nex``` branch and test nexml_read() against the NeXML returned from the Phenoscape API, stored in [this file](https://raw.githubusercontent.com/xu-hong/rphenoscape/master/inst/examples/test_original.xml). And I am still getting the same error: 
```
Error in fromNeXML(new(type[1]), from) : 
  error in evaluating the argument 'obj' in selecting a method for function 'fromNeXML': Error in getClass(Class, where = topenv(parent.frame())) : 
  “ns:LiteralMeta” is not a defined class
```
",NA,NA,NA
126,145138197,cboettig,2015-10-02T19:45:17Z,2015-10-02T19:45:17Z,"Thanks @xu-hong, I'll try and take a look soon.  ",NA,NA,NA
126,145182182,cboettig,2015-10-02T23:26:14Z,2015-10-02T23:26:14Z,"@xu-hong my bad, looks like I hadn't committed and pushed a change.  Can you try again?",NA,NA,NA
125,145556535,balhoff,2015-10-05T14:53:10Z,2015-10-05T14:53:10Z,"@rvosa I was reading back through this thread and want to question one point. Above where you say 

>  1. the current case where we specify which schema subtype an element
instance implements. This is done using these xsi:type statements, and the
value *must* always be a QName, i.e. fully qualified, with prefix and
colon. In implementing a mapping between prefixes and namespaces that, at
least, should be some relief.

I don't think that is right. A QName does not have to contain a colon. If it has no prefix, it follows the default namespace. You can see this here: http://www.w3.org/TR/1999/REC-xml-names-19990114/#NT-QName

I also tested this in Oxygen and it validates. So you don't need to prefix the values for `xsi:type=""ResourceMeta""`.
 ",NA,NA,NA
128,145595518,balhoff,2015-10-05T16:46:27Z,2015-10-05T16:46:27Z,@hlapp XML coming out of OntoTrace should validate completely now (since 2015-10-5). Please let me know if you encounter any problems.,NA,NA,NA
125,145851385,rvosa,2015-10-06T13:08:10Z,2015-10-06T13:08:10Z,"Yeah, our progressing insight has indeed led us to conclude that a prefix
is NOT required, i.e. xsi:type=""..."" can be specified without it. You're
right, and I wasn't.

>
",NA,NA,NA
125,145852355,balhoff,2015-10-06T13:13:00Z,2015-10-06T13:13:00Z,Every time an issue comes up with this stuff I end up slowly re-learning all the details that I had previously figured out and forgotten.,NA,NA,NA
129,146618854,cboettig,2015-10-08T16:48:59Z,2015-10-08T16:48:59Z,"A couple ways, depending on how you like.  You can always query the S4 object structure, as described in the S4 vignette (https://cran.r-project.org/web/packages/RNeXML/vignettes/S4.html), which is the natural R way.  You can query by xpath, but that's less easy in RNeXML since we assumed few users would know xpath (or if they did, would just be doing the parsing directly with XML library)

Um, stupid question just to be clear: In your example, which is the id?  The value of the id attribute on the otu element? or the href of the subsequent meta element? (though of course these are related).  

For RDFa meta elements, there's more tooling, including first generating the corresponding RDF-XML document and then performing full SPARQL queries if you like, (as well as XML/Xpath-based queries of the RDF-XML).  HTH,",NA,NA,NA
129,146654903,hlapp,2015-10-08T18:59:47Z,2015-10-08T18:59:47Z,"> A couple ways, depending on how you like. You can always query the S4 object structure, as described in the S4 vignette (https://cran.r-project.org/web/packages/RNeXML/vignettes/S4.html), which is the natural R way.

Isn't the S4 way to use API methods rather than accessing the object structure directly? (Otherwise, why even use an S4 object?)

> Um, stupid question just to be clear: In your example, which is the id? The value of the id attribute on the otu element? or the href of the subsequent meta element? (though of course these are related).

The `dwc:taxonID` annotation. I.e., the ID is the object of the `dwc:taxonID` relationship, or http://purl.obolibrary.org/obo/VTO_0061495 in the example above.

The `id` attribute of the `<otu/>` element is, I think, not useful, because it's local and not expected to roundtrip. In the Phenoscape-emitted XML is has a nice value, but it's really just there to tie the elements together in the XML document. That's why it's the annotation that's important. 

> For RDFa meta elements, there's more tooling, including first generating the corresponding RDF-XML document and then performing full SPARQL queries if you like, (as well as XML/Xpath-based queries of the RDF-XML)

Yes, but I find this rather dissatisfying as an answer for how to get at one of the most important pieces of information about an OTU. I do think that there should be an API method for it.",NA,NA,NA
129,146712812,cboettig,2015-10-08T23:10:33Z,2015-10-08T23:10:33Z,"Hi @hlapp,

Yes, as I mentioned there are several ways, most of which are in the documentation.  For instance, you can get the metadata from `otu` level options with the `get_metadata(nex, level=""otu"")` function, which is an S4 method (as opposed to S4 subsetting).  Let me know if that gets what you want.  

Sorry to be disappointing, without understanding the use case and the user's preferences better it's hard to know what is the best way to get what. e.g. someone who really wants to make semantic sparql queries might find the R-level API functions dissatisfying.  I don't have much intuition about what is the ""most important information about X"", but we have tried to document the different methods.  It seemed silly to just write S4 accessor methods for everything so these focus on things like the metadata elements.  Suggestions and PRs always welcome.",NA,NA,NA
129,146713550,cboettig,2015-10-08T23:15:38Z,2015-10-08T23:15:38Z,"(Whoops, forgot the link to the metadata vignette: https://cran.r-project.org/web/packages/RNeXML/vignettes/metadata.html)",NA,NA,NA
129,146717864,hlapp,2015-10-08T23:46:49Z,2015-10-08T23:47:52Z,"The use case is to extract a table that maps OTU labels (which are the row labels in the data.frame returned by `get_characters()`) to corresponding taxon IDs. According to the list made by @sckott in ropensci/traits#38, ID is a candidate for being fairly common among trait data API packages, @xu-hong and I were brainstorming how to obtain (and return) those.

Does `get_metadata(nex,level=""otu"")` return the metadata in a predictable order? Would they be in the same order as the matrix (data.frame) row labels, or the same order returned by `get_taxa()`? If not, how would one establish the mapping?",NA,NA,NA
126,146908614,rvosa,2015-10-09T15:49:45Z,2015-10-09T15:49:45Z,"I have now deployed the validator (and most of the rest of the website) to
the new host. For now I haven't updated the DNS records yet so you'll have
to use http://162.13.187.155/

Please let me know how you get on. I've tested the thing with the xsi:type
not needing a prefix and that now validates correctly so all should be well.

If you get the chance to click some other buttons on the website to see if
the deployment all worked I would be very grateful. I think there are two
bad bits for now:

1. I haven't tested any of the other (conversion) service, mostly because I
don't think people are using them so I didn't bother

2. for the schema documentation some of the menu items on the right hand
side still have the old URLs. I'd have to regenerate the static HTML to fix
that.
",NA,NA,NA
130,147850145,cboettig,2015-10-13T20:51:57Z,2015-10-13T20:51:57Z,"Thanks, this is due to a recent update in the `phytools` dependency actually and not the fault of `testthat`.  Just put a new release into the queue today!",NA,NA,NA
123,148184948,hlapp,2015-10-14T20:25:29Z,2015-10-14T20:25:29Z,"@sckott and @cboettig: for context, the idea is that fixing this would allow the return value from `httr::content` (with the NeXML document returned by the Phenoscape API) to be passed on directly to `nexml_read`, instead of having to create a temporary file first. Can you confirm that this is indeed how it would work if the above issue were corrected?",NA,NA,NA
129,148186321,hlapp,2015-10-14T20:29:43Z,2015-10-14T20:39:54Z,"> Does get_metadata(nex,level=""otu"") return the metadata in a predictable order? Would they be in the same order as the matrix (data.frame) row labels, or the same order returned by get_taxa()?

@cboettig or @sckott - seems that the order is not the same, as per what @xu-hong just tried.",NA,NA,NA
129,148207247,sckott,2015-10-14T21:26:15Z,2015-10-14T21:26:15Z,"@hlapp not sure, example to play with?",NA,NA,NA
123,148209751,sckott,2015-10-14T21:37:57Z,2015-10-15T00:08:38Z,"Hmm, one option would be to make an S3 generic and dispatch on different inputs instead of using `if..else`

e.g., 

```r
foo <- function(x) {
    UseMethod(""foo"")    
}
# for URL and file name inputs (then just need logic to act appropriately on url vs. file
foo.character <- function(...)
# for XMLInternalDocument input
foo.XMLInternalDocument <- function(...)
# for XMLInternalNode input
foo.XMLInternalNode <- function(...)
# any others ...
```",NA,NA,NA
129,148212078,hlapp,2015-10-14T21:48:25Z,2015-10-14T21:48:25Z,"The example query in the [Phenoscape Apiary docs for OntroTrace](http://docs.phenoscapekb.apiary.io/#reference/ontotrace/ontotrace/generate-matrix-of-inferred-presence/absence-associations-for-anatomical-structures-subsumed-by-the-provided-entity-class-expression,-for-any-taxa-within-the-provided-taxon-class-expression) will do: http://kb.phenoscape.org/api/ontotrace?taxon=%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FVTO_0036217%3E&entity=%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FBFO_0000050%3E%20some%20%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FUBERON_0008897%3E",NA,NA,NA
123,148212749,hlapp,2015-10-14T21:52:03Z,2015-10-14T21:52:20Z,"> Hmm, one option would be to make an S3 generic and dispatch on different inputs instead of using if..else

Is `if...else` a discouraged way of doing this? Or are you saying that there is more to it than just changing the order of the conditions to make the problem go away?",NA,NA,NA
123,148213967,sckott,2015-10-14T21:56:31Z,2015-10-14T21:56:31Z,"The way I proposed is just another way of dealing with various inputs. In the case where a function can have lots of different inputs, the above seems a little bit cleaner, thoughts @cboettig ",NA,NA,NA
123,148228668,cboettig,2015-10-14T23:05:31Z,2015-10-14T23:05:31Z,"@sckott sure, that looks like a good way to deal with the issue and make the code cleaner.  @hlapp Scott's approach just relies more explicitly on classes, I think it should also deal with the problem based @xu-hong 's comments.  Haven't had a chance to dig into this, but PR welcome.",NA,NA,NA
123,148247510,sckott,2015-10-15T01:09:18Z,2015-10-15T01:09:18Z,it's coming,NA,NA,NA
129,148443599,cboettig,2015-10-15T16:23:03Z,2015-10-15T16:23:03Z,"It looks like `get_metadata` return order is that given by XPath for the matching node set, while `get_taxa` is just using R's `lapply` over the structure. In both cases though I would have thought the order would just be that in which these elements appear in the XML file; is that not the case?  Or is that not the desired behavior?  Not sure if there was a good reason for `get_metadata` to use XPath here in the first place.  

 @hlapp can you give us a bit more detail as to what would be the most desired behavior for the return objects of `get_metadata` and `get_taxa` and maybe we can clean these methods up a bit?",NA,NA,NA
129,148454754,sckott,2015-10-15T16:54:28Z,2015-10-15T16:55:07Z,"Looks like `get_characters()` is the only one that doesn't return them in order 

```r
x <- nexml_read(""http://kb.phenoscape.org/api/ontotrace?taxon=%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FVTO_0036217%3E&entity=%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FBFO_0000050%3E%20some%20%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FUBERON_0008897%3E"")
get_characters(x)
#>                         pelvic splint anterior dentation of pectoral fin spine anterior distal serration of pectoral fin spine
#> Ictalurus pricei                    1                                        1                                               1
#> Ictalurus lupus                     1                                        1                                               1
#> Ictalurus balsanus                  1                                        0                                            <NA>
#> Ictalurus furcatus                  1                                        0                                               1
#> Ictalurus punctatus              <NA>                                        1                                               1
#> Ictalurus australis                 1                                        1                                               1
#> Ictalurus sp. (Mo 1991)             0                                     <NA>                                            <NA>
#> Ictalurus dugesii                   1                                     <NA>                                               1
#> Ictalurus mexicanus                 1                                     <NA>                                               1

get_metadata(x, level = ""otu"")
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0036225""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0061498""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0061495""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0036221""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0036218""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0036223""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0036220""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0061497""
#> 
#> $`dwc:taxonID`
#> [1] ""http://purl.obolibrary.org/obo/VTO_0061496""

get_taxa(x)
#> [1] ""Ictalurus punctatus""     ""Ictalurus mexicanus""     ""Ictalurus australis""     ""Ictalurus balsanus"" ""Ictalurus pricei""        ""Ictalurus furcatus""      ""Ictalurus lupus""         ""Ictalurus dugesii"" ""Ictalurus sp. (Mo 1991)""
```",NA,NA,NA
131,148463770,cboettig,2015-10-15T17:20:32Z,2015-10-15T17:20:32Z,Nice.  Can you add a test that shows this fixes the bug in #123?,NA,NA,NA
131,148466991,sckott,2015-10-15T17:32:21Z,2015-10-15T17:32:21Z,yeah,NA,NA,NA
131,148470907,sckott,2015-10-15T17:49:07Z,2015-10-15T17:49:07Z,added,NA,NA,NA
131,148477649,hlapp,2015-10-15T18:16:00Z,2015-10-15T18:16:00Z,Looks great!,NA,NA,NA
129,148478534,hlapp,2015-10-15T18:18:49Z,2015-10-15T18:18:49Z,So is the real issue that the rows in the matrix need to be reordered to be consistent with what the other methods return?,NA,NA,NA
129,148479107,hlapp,2015-10-15T18:20:48Z,2015-10-15T18:22:03Z,"> @hlapp can you give us a bit more detail as to what would be the most desired behavior for the return objects of get_metadata and get_taxa and maybe we can clean these methods up a bit?

Does the link to the issue on the rphenoscape tracker help establish enough context as to where this is coming from? Essentially the use-case is to create mapping tables from name to identifier(s). To apply these painlessly and with the least gotcha's, the names in the mapping table should be in the same order as everywhere else. Does that make sense?

The alternative is to get metadata back directly linked to what they annotate.

One way or another, there needs to be good way to establish that mapping.",NA,NA,NA
129,148481756,cboettig,2015-10-15T18:31:04Z,2015-10-15T18:31:04Z,"@hlapp yeah, the rphenoscape example is helpful, but I'm still processing the details here.

It's not clear to me why the order in which the characters are returned in the table matters; in that generally we expect methods that operate on data.frames to be agnostic of the order of the rows.  I thought NeXML had the same philosophy that in general it encodes all data explicitly in fields, rather than implicitly through structure (such as ordering or nestedness).

Do I have this wrong?  

It seems like the problems with the above methods are not so much the order as the lack of an additional id column.  My reading of the phenoscape issue is that we want three data.frames as the return objects.  `get_taxa` and `get_metadata` are currently returning a character string and a named list, respectively, which seems non-ideal.  

I think they should return data.frames, and I think it sounds like they need another column that contains the data you refer to as being represented by the ordering, but I'm not quite sure what that is.  (e.g. I suppose it is what they are annotating, but be really explicit for me: is it that the id of the element, or the label, or something else?)

Anyway, I completely agree that we need a good way to establish the mapping and that the current return objects are failing to preserve that information.  ",NA,NA,NA
129,148483865,hlapp,2015-10-15T18:39:36Z,2015-10-15T18:43:13Z,"> It's not clear to me why the order in which the characters are returned in the table matters; in that generally we expect methods that operate on data.frames to be agnostic of the order of the rows.

Isn't it pretty common in R to use the index for subsetting? Say I wanted to subset the matrix to keep all rows for taxa that have an identifier:

```r
data <- get_characters(nexml)
ids <- get_metadata(nexml, level=""otu"") # this won't work this way right now, of course
data <- data[!is.na(ids), ]
```

Say you have a function `pk_is_descendant(x1, x2)` that returns TRUE if x2 is a descendent of x1 and FALSE otherwise:
```r
data <- get_characters(nexml)
ids <- get_metadata(nexml, level=""otu"") # this won't work this way right now, of course
data <- data[pk_is_descendant(""Mammalia"", ids), ]
```

Does that make sense?",NA,NA,NA
129,148484560,hlapp,2015-10-15T18:42:24Z,2015-10-15T18:42:24Z,"> My reading of the phenoscape issue is that we want three data.frames as the return objects. get_taxa and get_metadata are currently returning a character string and a named list, respectively, which seems non-ideal.
> 
> I think they should return data.frames, and I think it sounds like they need another column that contains the data you refer to as being represented by the ordering, but I'm not quite sure what that is. (e.g. I suppose it is what they are annotating, but be really explicit for me: is it that the id of the element, or the label, or something else?)

The piece that is being used elsewhere for row and column labels. For example, the data matrix uses apparently the taxon labels for its row labels, and the character labels for its column labels.",NA,NA,NA
129,148488270,cboettig,2015-10-15T18:57:24Z,2015-10-15T18:57:24Z,"> The piece that is being used elsewhere for row and column labels. For example, the data matrix uses apparently the taxon labels for its row labels, and the character labels for its column labels.

Yup.  I think that was a bad choice though.  The row labels should be a column, and the rows should be unlabelled. This is more consistent with database design and more robust for manipulation.  

Yes, people subset in R with index vectors, but typically only when the index vector is constructed from a column of the data.frame you are subsetting (where clearly you cannot have the problem of different orderings).  

Your example is very helpful, but it sounds like `get_characters()` should be returning a column for `ids` as well as a column (rather than row-labels) for `taxon label`, and that `get_metadata(nexml, level=""otu"")` should be returning a `data.frame` with id as a column (or is it taxon label that we want as the key?), and then columns for attribute and value (the `rel` and `href` of the meta element).  Then you could join the metadata table and the characters table, and filter, subset, etc, intelligently (with nice `dplyr` functions or standard index subsetting) and not have to ever worry about ordering of rows.  Does that sound right to you?

",NA,NA,NA
131,148506007,xu-hong,2015-10-15T20:04:34Z,2015-10-15T20:04:34Z,It works great! Just changed the reading nexml part [https://github.com/xu-hong/rphenoscape/commit/38eb615e8dbc041b9e814e584cad817a52f220b4] (https://github.com/xu-hong/rphenoscape/commit/38eb615e8dbc041b9e814e584cad817a52f220b4) in rPhenoscape @hlapp ,NA,NA,NA
129,148517516,xu-hong,2015-10-15T20:50:32Z,2015-10-15T20:50:32Z,"Hi @cboettig,
I agree that ```get_characters()``` should return a ```data.frame``` that has taxon labels as a column, instead of row labels. But perhaps the ```data.frame``` should not include a column for ```ids``` - my understanding is that ```ids``` are not always the information the users need to know when they ask for ```OntoTrace matrix```?

```ids```should be found separately in the ```data.frame```returned by ```get_metadata(nexml, level=""otu"")```, along with taxon labels (as the key) and other values, as you mentioned. And the metadata table can be joined with the ontotrace matrix on taxon labels.

@hlapp Do you agree? ",NA,NA,NA
123,148572190,hlapp,2015-10-16T01:44:48Z,2015-10-16T01:44:48Z,I think this can be closed as per #131 and @xu-hong's confirmation.,NA,NA,NA
129,148755915,hlapp,2015-10-16T16:04:50Z,2015-10-16T16:04:50Z,"Yes, I agree, that seems more natural. That said, it would be easy enough to splice out the ID column in rphenoscape (and to construct a separate data.frame with metadata mapped to taxon labels) before returning the result to the user, in case @cboettig would rather put it into the data.frame returned by `get_characters()`.",NA,NA,NA
129,148762602,cboettig,2015-10-16T16:33:07Z,2015-10-16T16:33:07Z,"Thanks for the advice here, very helpful.  I'm still a tad leary of using labels instead of ids as keys for indexing and joining tables, (I'm guessing labels can have more weird UTF-8 chars then ids, and thus cause trouble if a user has not configured locales sensibly), isn't that why we have ids in the first place?  

Are we always guaranteed to have both id and label elements available (i.e. are they both required by the schema? guess I should know that...)",NA,NA,NA
129,148944515,rvosa,2015-10-17T19:03:34Z,2015-10-17T19:03:34Z,No! The label attribute is optional.,NA,NA,NA
129,148955281,cboettig,2015-10-17T22:08:09Z,2015-10-17T22:08:09Z,"@rvosa very good, that makes much more sense.  I'll return ids as the key column for each of the data.frames",NA,NA,NA
129,148958667,hlapp,2015-10-17T22:55:30Z,2015-10-17T22:55:30Z,"Which IDs? The ones in the `id=""""` attribute? That would, I think, be a bad choice, because they are ephemeral, not expected to roundtrip, and local to the document. Or in other words, a sequential numbering would just be as good, but would not give the impression that any assumptions could be made about  the ID.",NA,NA,NA
129,148959693,cboettig,2015-10-17T23:13:32Z,2015-10-17T23:13:32Z,"Right, they are local to the document, but they'd still be better than
assuming the row order with no id's at all?  What is the purpose of those
ids? What would you recommend we use?  Using an optional element seems
unwise, right?

On Sat, Oct 17, 2015, 3:55 PM Hilmar Lapp <notifications@github.com> wrote:

> Which IDs? The ones in the id="""" attribute? That would, I think, be a bad
> choice, because they are ephemeral, not expected to roundtrip, and local to
> the document. Or in other words, a sequential numbering would just be as
> good, but would not give the impression that any assumptions could be made
> about the ID.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/129#issuecomment-148958667>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
129,148961872,rvosa,2015-10-17T23:59:31Z,2015-10-17T23:59:31Z,"Also, there is no requirement that all otu attributes, even if they're there, are unique. 

@hlapp do you think it would ever be problematic that the ids are ephemeral? I mean, in practice? They are unique keys for managing referential integrity within the document, anything else you should use an annotation for (example: any kind of database ID).",NA,NA,NA
129,148962015,hlapp,2015-10-18T00:05:03Z,2015-10-18T00:05:03Z,"> They are unique keys for managing referential integrity within the document

Exactly (and @cboettig, this is the answer to your question - they are in essence local primary keys, which are never really useful to expose or export to anything else, including not from XML documents) . So you might as well use a sequential numbering - it's unique for each row, and will obviously be local to a data matrix (whereas that fact might be much less obvious from the XML doc's primary keys).

So I know there's been concern with and objection to using the row order of the data matrix, but in essence we're back to that.",NA,NA,NA
129,149019998,rvosa,2015-10-18T14:21:39Z,2015-10-18T14:21:39Z,"I must apologize for not having read the thread closely enough. If @hlapp's
use case is to map *names* to taxon ID annotations then this sounds to me
like a table with two columns: one with the label attribute - being the
place where names go - and one with the value of the taxon ID annotation
(in this case a URI).

The consequence is that the names column may legally have empty or
non-unique values but that, to me, seems inevitable considering that names
are not required, unique, primary keys in the real world.

Programmatically we therefore can't rely on them to act like primary keys
(or hash keys or whatever). But I don't think that was a requirement anyway
for @hlapp, right? The converse may be true though: the taxon IDs are
globally unique (so that column might be treated as such), and may have
zero or more labels attached to it.
Op Sun, 18 Oct 2015 om 02:05 schreef Hilmar Lapp <notifications@github.com>

> They are unique keys for managing referential integrity within the document
>
> Exactly (and @cboettig <https://github.com/cboettig>, this is the answer
> to your question - they are in essence local primary keys, which are never
> really useful to expose or export to anything else, including not from XML
> documents) . So you might as well use a sequential numbering - it's unique
> for each row, and will obviously be local to a data matrix (whereas that
> fact might be much less obvious from the XML doc's primary keys).
>
> So I know there's been concern with and objection to using the row order
> of the data matrix, but in essence we're back to that.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/129#issuecomment-148962015>.
>
",NA,NA,NA
129,150011313,hlapp,2015-10-21T20:10:56Z,2015-10-21T20:10:56Z,"Just as an FYI, now that @balhoff implemented identifier annotations for character definitions (see phenoscape/phenoscape-kb-services#20), we can see that the order in which `get_metadata(nex, level=""char"")` returns results isn't the same as the order of columns in the matrix returned by `get_characters()` either.

So right now, `get_metadata()` is kind of useless for getting at those metadata. And I agree that simply fixing the order doesn't cut it - if an `otu` or `char` element lacks an annotation, then that fact isn't represented by an `NA` in the list returned by `get_metadata()`.

Perhaps this is a good point to arrange a conference call to move this issue forward?",NA,NA,NA
129,150024038,cboettig,2015-10-21T21:05:45Z,2015-10-21T21:05:45Z,"Sounds good to me.  

I've implemented a new version of get_metadata now on the `drop-nex` branch, which returns a data.frame that contains as its columns the attribute values of any meta elements at the desired level, along with the id of the parent element,  e.g. [this NeXML](https://github.com/ropensci/RNeXML/blob/master/inst/examples/primates.xml) gives:

```
 > get_metadata(nex, ""otu"")
Source: local data frame [959 x 5]

      id             rel                                              href         xsi.type parent_id
   (chr)           (chr)                                             (chr)           (fctr)     (chr)
1    ma4 concept:toTaxon            http://ncbi.nlm.nih.gov/taxonomy/54135 nex:ResourceMeta     ou475
2    ma5    concept:rank http://rs.tdwg.org/ontology/voc/TaxonRank#Species nex:ResourceMeta     ou475
3    ma6 rdfs:subClassOf            http://ncbi.nlm.nih.gov/taxonomy/54134 nex:ResourceMeta     ou475
4    ma8 concept:toTaxon           http://ncbi.nlm.nih.gov/taxonomy/122248 nex:ResourceMeta     ou465
5    ma9    concept:rank http://rs.tdwg.org/ontology/voc/TaxonRank#Species nex:ResourceMeta     ou465
6   ma10 rdfs:subClassOf           http://ncbi.nlm.nih.gov/taxonomy/122247 nex:ResourceMeta     ou465
7   ma12 concept:toTaxon            http://ncbi.nlm.nih.gov/taxonomy/30590 nex:ResourceMeta     ou578
8   ma13    concept:rank http://rs.tdwg.org/ontology/voc/TaxonRank#Species nex:ResourceMeta     ou578
9   ma14 rdfs:subClassOf             http://ncbi.nlm.nih.gov/taxonomy/9499 nex:ResourceMeta     ou578
10  ma16 concept:toTaxon             http://ncbi.nlm.nih.gov/taxonomy/9502 nex:ResourceMeta     ou484
..   ...             ...                                               ...              ...       ...
```


No idea if this is wise or not, but shows what I am thinking.  I'd like `get_taxa` to return a similar `data.frame`, and then include the `otu` attribute values in `get_characters`.  I think this permits an intelligent join for the desired tables but would be good to discuss.  In any event, we should be able to do something much more useful than the current methods, which really don't help much for this or any other non-trivial use case.  ",NA,NA,NA
129,150026224,hlapp,2015-10-21T21:15:01Z,2015-10-22T13:17:51Z,"> I'd like `get_taxa()` to return a similar `data.frame`, and then include the `otu` attribute values in `get_characters()`.

I guess I'm curious what you mean by _similar data.frame_. ID, label, and? And for `get_characters()`, are you thinking about returning a data.frame instead of a matrix? Not being sure what data structure you have in mind, I'll just note that I'd be wary of sticking too many columns into the matrix (or data.frame) that aren't part of the character matrix.",NA,NA,NA
129,150028680,cboettig,2015-10-21T21:25:50Z,2015-10-21T21:25:50Z,"Good questions, and please push back if I'm saying something silly; you, @xu-hong and @balhoff have a better idea than me about the actual use cases here.

For `get_taxa`, I'm thinking of returning the attribute values of the `otu` elements -- really that's just `id` and `label` (but could include `about` and `xsi:type`). For reference, this would probably also include a column with the parent id (e.g. which would identify if the `otu` values came from more than one `otus` block).  

For the characters matrix, I would probably only add the value of the `otu` attribute to the `<row>` element.  It seems like this is the right thing for joining with the other tables, rather than `label` which need not be unique.  Does that make sense?  

@rvosa does the `label` attribute of a `<row>` element have to match the `label` attribute of the corresponding `<otu>` element (that is, the element whose `id` corresponds to the row's `otu` attribute)?

",NA,NA,NA
132,151316796,sckott,2015-10-26T23:50:58Z,2015-10-26T23:50:58Z,"That file has mostly specific epithets within _Geospiza_, and two genera outside of _Geospiza_ (AFAIK) -  _Pinaroloxias_, and _Platyspiza_

Ideally, before searching, we'd have the fullest name possible, given the data, e.g., _Geospiza magnirostris_ instead of just _magnirostris_ - It doesn't look like the name _Geospiza_ is anywhere in that file though that I can see. other than the file name. 

Ranks would be nice to have to make searches faster, but then we'd need the user to specify that in their nex file

We can do searches for higher taxonomic names, but epithets themselves usually don't work out to well. Not sure what to do in that case. ",NA,NA,NA
132,151317712,cboettig,2015-10-26T23:57:28Z,2015-10-26T23:57:28Z,"Thanks!  right, looks like the data just isn't precise enough in this case then.  

Um, more generally, do higher taxonomic names work?  In similar vein, wondering if we should modify the function to return the two additional meta blocks like what @rvosa 's tool does [here](https://github.com/ropensci/RNeXML/blob/master/inst/examples/primates.xml#L14-L15), specifying whether the name is a Species or some other rank, and specifying what the species is a `rdfs:subClassOf`.  

@rvosa the value of knowing taxonRank is pretty intuitive, but what's a use case where you would also want the `subClassOf`?  I suppose a user could always determine both of these pieces of information from the taxon identifier directly, though I could see that it would often be more convenient to avoid having to make another query.  ",NA,NA,NA
129,151321420,cboettig,2015-10-27T00:18:47Z,2015-10-27T00:18:47Z,"@hlapp @xu-hong others what do you think of this approach (now implemented on the `drop-nex` branch): https://github.com/ropensci/RNeXML/blob/611de7caa9fc8335b82b29f664574b154ec09d9f/inst/examples/merge_data.md

Note that I've left the `get_characters` just returning the `labels` and have done that join on `labels` instead of `id`, though I'm still not sure if that's ideal or not, particularly since `label` need not be required.  I think `get_characters` might be better off returning `label` and `otu` id information to be explicit, but perhaps not.  ",NA,NA,NA
132,151559284,sckott,2015-10-27T16:28:03Z,2015-10-27T16:28:03Z,"Higher taxonomic names should work, yes.  

Searching for a higher taxonomic name should return rank as well. Getting parent might be another request though. 

```r
(res <- get_uid(""Platyspiza""))
#> [1] ""48887""
#> attr(,""class"")
#> [1] ""uid""
#> attr(,""match"")
#> [1] ""found""
#> attr(,""uri"")
#> [1] ""http://www.ncbi.nlm.nih.gov/taxonomy/48887""
```

```r
classification(res)
#> $`48887`
#>                    name         rank      id
#> 1    cellular organisms      no rank  131567
...
#> 28        Passeriformes        order    9126
#> 29          Passeroidea  superfamily  175121
#> 30         Fringillidae       family    9133
#> 31          Emberizinae    subfamily   62155
#> 32           Platyspiza        genus   48887
#> 
#> attr(,""class"")
#> [1] ""classification""
#> attr(,""db"")
#> [1] ""ncbi""
```

```r
# for the family Fringillidae, assuming that's what you want
as.uid(9133)
#> [1] ""9133""
#> attr(,""class"")
#> [1] ""uid""
#> attr(,""match"")
#> [1] ""found""
#> attr(,""uri"")
#> [1] ""http://www.ncbi.nlm.nih.gov/taxonomy/9133""
```

So we can get the info that way, presumably some smarter version of it though. 

I realized just now that `get.uid()` and related functions could return rank (if available), meaning one more piece of data avail. (meaning one less API call for users that want rank info). ",NA,NA,NA
126,151661096,cboettig,2015-10-27T22:13:22Z,2015-10-27T22:13:22Z,"@rvosa The new validator has been great, lemme know when the DNS records are updated, I've hardcoded the ip in the validator function temporarily.  ",NA,NA,NA
126,151818432,rvosa,2015-10-28T11:52:12Z,2015-10-28T11:52:12Z,"The DNS records are updated, the original url(s) are now in effect for the updated validator:
http://www.nexml.org/nexml/phylows/validator - of this url, the following fragments are actually optional: the `www` can be omitted, and the `nexml` path fragment also, e.g. http://nexml.org/phylows/validator works.",NA,NA,NA
126,151819271,rvosa,2015-10-28T11:54:10Z,2015-10-28T11:54:10Z,"Oh, and the issues I mentioned [here](https://github.com/ropensci/RNeXML/pull/126#issuecomment-146908614) have now been addressed: the other services work as intended, and the links in the right hand side menu have been updated.",NA,NA,NA
126,151887863,cboettig,2015-10-28T15:45:18Z,2015-10-28T15:45:18Z,"Awesome, thanks!",NA,NA,NA
134,151981881,cboettig,2015-10-28T20:33:30Z,2015-10-28T20:33:30Z,"Thanks for testing out, sorry about that.  I think you want: `get_metadata(nexml, ""characters"")`.  The second argument should be the (full) name of a nexml element.  To avoid ambiguity, the function actually expects you to give the full path to the element, e.g. `get_metadata(nexml, ""otus/otu"")`, but I mapped `otu` and `tree` separately for backwards-compatibility.  Looks like I forgot to do that for `char` (if that was previously an option).  This new approach should allow you to get metadata for arbitrary elements (including meta elements themselves, if they are nested).

The documentation could stand to be improved on this matter as well.  ",NA,NA,NA
134,151987017,hlapp,2015-10-28T20:53:35Z,2015-10-28T20:53:56Z,"We do want annotations for the `char` elements. If I spell out the path it doesn't work either:

```R
> get_metadata(nex,level=""characters/char"")
Error in slot(node, element) : 
  no slot of name ""char"" for this object of class ""characters""
> get_metadata(nex,level=""characters/format/char"")
Error in as.list.default(X) : 
  no method for coercing this S4 class to a vector
```

The second invocation is actually the correct path in the XML, so that the first doesn't work is I guess expected. But the second one _should_ work.

Here are the annotations as an example for one `<char/>` element:
```xml
<char id=""UBERON_2002002"" label=""anterior distal serration of pectoral fin spine"" about=""#UBERON_2002002"" states=""sa75ef9ac-e74e-4015-846d-27d793868951"">
     <meta xsi:type=""ResourceMeta"" rel=""obo:IAO_0000219"" href=""http://purl.obolibrary.org/obo/UBERON_2002002"" />
</char>
```",NA,NA,NA
134,151987968,cboettig,2015-10-28T20:57:34Z,2015-10-28T20:57:34Z,"oh right, those `char` elements.  That's a bug, I'll take a look.  Can you link me to a complete NeXML file that has `meta` annotations on `char` elements just for my testing?
",NA,NA,NA
134,152005924,hlapp,2015-10-28T21:52:44Z,2015-10-28T21:52:44Z,Here's an example file: https://github.com/phenoscape/rphenoscape/blob/char-annots-example/inst/examples/ontotrace-result.xml,NA,NA,NA
134,152011035,cboettig,2015-10-28T22:03:19Z,2015-10-28T22:03:19Z,"okay, just pushed a fix, try now.  ",NA,NA,NA
135,152273543,cboettig,2015-10-29T18:20:36Z,2015-10-29T18:20:36Z,"Okay, I think this is fixed in the above commit. Please re-open if the issue persists or otherwise needs re-working.  ",NA,NA,NA
129,152274098,cboettig,2015-10-29T18:22:10Z,2015-10-29T18:22:10Z,So I think this issue is now addressed by PR #133 and the fix to #135.  Please highlight any remaining problems as new issues so we don't lose track of them.  ,NA,NA,NA
128,152274394,cboettig,2015-10-29T18:22:56Z,2015-10-29T18:22:56Z,Should be fixed by PR #133 ,NA,NA,NA
125,152274549,cboettig,2015-10-29T18:23:36Z,2015-10-29T18:23:36Z,I think this is also fixed now since merging #133,NA,NA,NA
136,152275707,cboettig,2015-10-29T18:26:55Z,2015-10-29T18:26:55Z,"Do we need the ids of the `otus` element or just of the individual `otu` values?  The latter is now done via b7635997e5b615961070d5589423844ccb49c85a

If I understood correctly from the call, we just need the latter since the ids need to be unique anyhow.  Any user who wants the otus block ids as well can easily get them from the `get_taxa()` table, along with the labels, etc.  

I think this addresses the issue, so will close, but please re-open and elaborate if necessary.  ",NA,NA,NA
136,152282615,hlapp,2015-10-29T18:42:20Z,2015-10-29T18:42:20Z,"Is it difficult to return the `otus` value? It's much easier to subset a data.frame by one value than it is to do so by possibly hundreds or thousands. I.e., yes, I can match the `data.frame` returned by `get_taxa()` against a potentially very long list of `otu` IDs, or I can subset the `data.frame` by a single value. Why not allow the latter, unless it's somehow difficult to return the necessary ID value from the `get_characters()` result?",NA,NA,NA
136,152287729,cboettig,2015-10-29T19:00:55Z,2015-10-29T19:00:55Z,"No, certainly we could add it in automatically if that's preferred.  But note that the join is just 1 line and performance-wise quite fast:

e.g. 

```r
library(""dplyr"")
get_characters(nex, otu=TRUE) %>% 
  left_join(get_taxa(nex), by = c('otu' = 'id')) %>% 
  filter(otus == ""os2"")
```
isn't that much more onerous than:

```r
library(""dplyr"")
get_characters(nex, otu=TRUE) %>% 
  filter(otus == ""os2"")
```

and is more general, in the sense that I'd like to encourage users to learn the `join()` pattern because it's more general.  One person wants to filter on otus, but what if you want to filter on some aspect of the otu metadata, or other metadata? My thought was to avoid providing too many `key`/`id` columns by default, since they are apt to confuse more beginning users; advanced types using all the id hierarchies can probably manage the extra syntax.  

But I don't mean to be stubborn on this, we could of course add it in.  Just wanted to explain my reasoning here first.  


",NA,NA,NA
135,152766038,xu-hong,2015-10-31T19:40:42Z,2015-10-31T19:42:35Z,"I found the parameters are not working as designed. The resulting columns are somehow messed up:
```
> nex <- nexml_read(""https://raw.githubusercontent.com/phenoscape/rphenoscape/char-annots-example/inst/examples/ontotrace-result.xml"")
> get_characters(nex)
                        anterior dentation of pectoral fin spine anterior distal serration of pectoral fin spine
Ictalurus pricei                                               1                                               1
Ictalurus lupus                                                1                                               1
Ictalurus balsanus                                             0                                            <NA>
Ictalurus furcatus                                             0                                               1
Ictalurus punctatus                                            1                                               1
Ictalurus australis                                            1                                               1
Ictalurus sp. (Mo 1991)                                     <NA>                                            <NA>
Ictalurus dugesii                                           <NA>                                               1
Ictalurus mexicanus                                         <NA>                                               1
```
According to original file there should be three columns for anatomical entities - ""pelvic splint"" is missing here!

```otu_id``` is acting weird:
```
> get_characters(nex, otu_id = T)
                         otu anterior dentation of pectoral fin spine anterior distal serration of pectoral fin spine
Ictalurus pricei           1                                        1                                               1
Ictalurus lupus            1                                        1                                               1
Ictalurus balsanus         1                                        0                                            <NA>
Ictalurus furcatus         1                                        0                                               1
Ictalurus punctatus     <NA>                                        1                                               1
Ictalurus australis        1                                        1                                               1
Ictalurus sp. (Mo 1991)    0                                     <NA>                                            <NA>
Ictalurus dugesii          1                                     <NA>                                               1
Ictalurus mexicanus        1                                     <NA>                                               1
```
I think the values of ```otu``` column here should be ``` pelvic splint```'s. 

The following matrices are not working properly as well. 
```
> get_characters(nex, rownames_as_col =  T)
  pelvic splint anterior dentation of pectoral fin spine anterior distal serration of pectoral fin spine
1             1                                        1                                               1
2             1                                        1                                               1
3             1                                        0                                            <NA>
4             1                                        0                                               1
5          <NA>                                        1                                               1
6             1                                        1                                               1
7             0                                     <NA>                                            <NA>
8             1                                     <NA>                                               1
9             1                                     <NA>                                               1
> get_characters(nex, rownames_as_col = T,  otu_id = T)
                      otu pelvic splint anterior dentation of pectoral fin spine anterior distal serration of pectoral fin spine
1        Ictalurus pricei             1                                        1                                               1
2         Ictalurus lupus             1                                        1                                               1
3      Ictalurus balsanus             1                                        0                                            <NA>
4      Ictalurus furcatus             1                                        0                                               1
5     Ictalurus punctatus          <NA>                                        1                                               1
6     Ictalurus australis             1                                        1                                               1
7 Ictalurus sp. (Mo 1991)             0                                     <NA>                                            <NA>
8       Ictalurus dugesii             1                                     <NA>                                               1
9     Ictalurus mexicanus             1                                     <NA>                                               1
```
I suspect there is one common reason (mishandling of columns) for all of these.",NA,NA,NA
135,152774440,cboettig,2015-10-31T21:28:09Z,2015-11-04T18:20:23Z,"Thanks for the report!  Will investigate
",NA,NA,NA
135,153819754,cboettig,2015-11-04T18:25:01Z,2015-11-04T18:25:01Z,"Okay, sorry for the delay, I've pushed a fix to this in the new branch, https://github.com/ropensci/RNeXML/tree/fix-get-characters which should resolve this error.  (@hlapp I've also added the option to get otus id as well as the otu id now automatically).  

This does highlight the question of when the `get_characters` function should be substituting labels for ids and when it shouldn't.  As usual, this problem stems from the typical R package data structures where there are no ids (or rather, as is typical of domain researchers, columns such as the trait values are named with abbreviations that are not quite ids but not quite descriptive labels either).  Here we see this issue arise for both OTUs (id vs otu label) and for character traits.  I am not sure how best to handle it.  ",NA,NA,NA
135,153854200,hlapp,2015-11-04T20:33:14Z,2015-11-04T20:33:14Z,"@cboettig - just FYI, the committer shows as ""rstudio"" for the commits on that branch. Perhaps forgot to configure git?",NA,NA,NA
135,153855082,hlapp,2015-11-04T20:36:59Z,2015-11-04T20:36:59Z,"> This does highlight the question of when the get_characters function should be substituting labels for ids and when it shouldn't. As usual, this problem stems from the typical R package data structures where there are no ids (or rather, as is typical of domain researchers, columns such as the trait values are named with abbreviations that are not quite ids but not quite descriptive labels either). Here we see this issue arise for both OTUs (id vs otu label) and for character traits. I am not sure how best to handle it.

My take on this is to have the default behave comparable to what users are most likely to be used to or expect, even if that's not ideal in the case of labels, but to make it easy to get at the IDs for those that want to do something with them. It's the latter that's usually difficult or impossible and neglected, and getting ambiguous labels by default isn't a bad thing if it's easy to map these to identifiers fit for computational integration.",NA,NA,NA
135,153884528,cboettig,2015-11-04T22:07:31Z,2015-11-04T22:07:31Z,"@hlapp yeah, was running from a docker instance with default git config, whoops.  

Right, that makes sense.  I've set the thing to return labels whenever possible.  I've now added a mechanism to detect if the data lacks labels, or has any non-unique labels (which make it impossible to do the table joins one expects of ids), in which case RNeXML will return id values.  ",NA,NA,NA
137,153891249,cboettig,2015-11-04T22:34:18Z,2015-11-04T22:34:18Z,"Right, `get_characters` returns the characters matrix by default, since that's the object most people are probably familiar with.  And as you know, we know have options to get little bits of more metadata, such as the `otu` and `otus` value.  

I agree that it could behave more like `get_taxa`, but not quite sure what is needed.  Keep in mind there's _a lot of possibilities_ since the character data is _a lot_ more complex than the taxa data.  

I've added the (mostly) general function `get_level()`, which is used internally by all of these methods.  You'll see `get_taxa` is really just `get_level(nex, ""otus/otu"")`.  `get_level()` just returns a data.frame in which columns are the attributes of the specified level, and rows are the elements found at that level.  I haven't really polished it for generic end-user use but feel free to play around with it and let me know if it is useful.

The problem here is that `get_characters` data is a lot more complex than `get_taxa()` -- there's not just one obvious table representation, but really at least 4 tables of interest: `char`, `state` (somehow handling the data from polymorphic & uncertain types), `cell` (with some data from `row`), as well as the `otu` table.  You'll see all of these in play here: https://github.com/ropensci/RNeXML/blob/fix-get-characters/R/get_characters.R#L27-L43.  (And of course there could be metadata tables associated with any one of these)

I'm not sure if each of these tables should have there own user-level method  -- we do want to keep a reasonably consise namespace after all or it gets overwhelming to new users.  

I agree that there is perhaps some information in the chars or states tables that we still aren't exposing, but I'm not sure what else to expose.


",NA,NA,NA
137,154043355,rvosa,2015-11-05T12:16:23Z,2015-11-05T12:16:23Z,"Isn't it a bit of a misnomer to call a method that returns the matrix
""get_characters"". May expectation would probably be that it returns a list
(or structure like that) of the matrix columns, with whatever metadata is
attached to them.

On Wed, Nov 4, 2015 at 11:34 PM, Carl Boettiger <notifications@github.com>
wrote:

> Right, get_characters returns the characters matrix by default, since
> that's the object most people are probably familiar with. And as you know,
> we know have options to get little bits of more metadata, such as the otu
> and otus value.
>
> I agree that it could behave more like get_taxa, but not quite sure what
> is needed. Keep in mind there's *a lot of possibilities* since the
> character data is *a lot* more complex than the taxa data.
>
> I've added the (mostly) general function get_level(), which is used
> internally by all of these methods. You'll see get_taxa is really just get_level(nex,
> ""otus/otu""). get_level() just returns a data.frame in which columns are
> the attributes of the specified level, and rows are the elements found at
> that level. I haven't really polished it for generic end-user use but feel
> free to play around with it and let me know if it is useful.
>
> The problem here is that get_characters data is a lot more complex than
> get_taxa() -- there's not just one obvious table representation, but
> really at least 4 tables of interest: char, state (somehow handling the
> data from polymorphic & uncertain types), cell (with some data from row),
> as well as the otu table. You'll see all of these in play here:
> https://github.com/ropensci/RNeXML/blob/fix-get-characters/R/get_characters.R#L27-L43.
> (And of course there could be metadata tables associated with any one of
> these)
>
> I'm not sure if each of these tables should have there own user-level
> method -- we do want to keep a reasonably consise namespace after all or it
> gets overwhelming to new users.
>
> I agree that there is perhaps some information in the chars or states
> tables that we still aren't exposing, but I'm not sure what else to expose.
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/137#issuecomment-153891249>.
>
",NA,NA,NA
137,154088383,cboettig,2015-11-05T15:13:01Z,2015-11-05T15:13:01Z,"@rvosa Thanks for feedback.  I'm an afraid I'm really sure I understand what data you expect or how you'd like it to be formatted.  A few observations about the current format:

- To me it's not clear how `get_chatacters_matrix` is very different than the slightly less verbose `get_characters`.    
- I've tried to be consistent with the originally released version of this function, which returns the characters / traits matrix in the format used by the comparative methods R packages.  After all, this data combines information from all the child-elements of the `characters` block, not just the `matrix` block.
- I strongly recommend that we return data.frames and not lists.  R is a statistical language and very oriented to data.frames, and thus we save the user work.  A list of nested lists would more accurately reflect the hierarchical structure of XML of course, there's obviously not a 1:1 mapping from arbitrary XML to a data.frame, but that is why the function is more useful.  The user already has access to a native R list (well, S4 object, but can be iterated like a list) in the nex object or any of its sub-component, but I'm sure you'll agree that's a bit cumbersome to work with.  
- for metadata elements, we have `get_metadata` at an arbitrary level, including metadata for the state, char, or whatever else has metadata.  These return the identifiers of the parent element so one could join the relevant data tables, as we illustrate with otu + otu meta.  


",NA,NA,NA
137,154099468,hlapp,2015-11-05T15:49:49Z,2015-11-05T15:49:59Z,"Just to be clear about what one of the driving use-cases is from the rphenoscape point of view, we need to be able to map character labels to character annotations, including identifiers (not to be confused with the document-local IDs for `<char/>` and other elements, which are the IDs used in the XML document to tie together entities). We can now use `get_metadata(level=""characters/format/char"")` to extract the annotations for characters, but they can't yet be mapped to the columns of the data.frame returned by `get_characters()` because the document-local IDs needed to map are only included in the result from `get_metadata()` but not in the result from `get_characters()`. So we're back to relying on order, which is brittle and bad.

For OTUs, this issue is now addressed by `get_taxa()` returning the document-local OTU IDs as one of the columns in the returned data.frame. We can ask `get_characters()` to include OTU IDs as a column, which enables mapping rows in the data matrix to OTU annotations. There isn't yet a way to ask `get_characters()` to include column (= `<char/>`) IDs.

Is that understandable?  ",NA,NA,NA
137,154101195,cboettig,2015-11-05T15:55:35Z,2015-11-05T15:55:35Z,"Ah, thanks!  that makes perfect sense.  So we need char id values?  For
now, can you try `get_level(nex, ""characters/format/char"") ` (on the
fix-characters branch)?  I think that's the data you're looking for?

On Thu, Nov 5, 2015, 7:49 AM Hilmar Lapp <notifications@github.com> wrote:

> Just to be clear about what one of the driving use-cases is from the
> rphenoscape point of view, we need to be able to map character labels to
> character annotations, including identifiers (not to be confused with the
> document-local IDs for <char/> and other elements, which are the IDs used
> in the XML document to tie together entities). We can now use
> get_metadata(level=""characters/format/char"") to extract the annotations
> for characters, but they can't yet be mapped to the columns of the
> data.frame returned by get_characters() because the document-local IDs
> needed to map are only included in the result from get_metadata() but not
> in the result from get_characters(). So we're back to relying on order,
> which is brittle and bad.
>
> For OTUs, this issue is now addressed by get_taxa() returning the
> document-local OTU IDs as one of the columns in the returned data.frame. We
> can ask get_characters() to include OTU IDs as a column, which enables
> mapping rows in the data matrix to OTU annotations. There isn't yet a way
> to ask get_characters() to include column (= ) IDs.
>
> Is that understandable?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/137#issuecomment-154099468>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
137,154517136,xu-hong,2015-11-06T20:01:16Z,2015-11-06T20:01:16Z,"Thanks! But I cannot access ```get_level()``` function, on the ```fix-get-characters``` branch. I guess it's not exported? ",NA,NA,NA
137,154523770,cboettig,2015-11-06T20:30:35Z,2015-11-06T20:30:35Z,"Right, not exported yet since not documented or fully tested, by you can
always do RNeXML:::get_level

On Fri, Nov 6, 2015, 12:01 PM Hong Xu <notifications@github.com> wrote:

> Thanks! But I cannot access get_level() function, on the
> fix-get-characters branch. I guess it's not exported?
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/137#issuecomment-154517136>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
137,154547701,xu-hong,2015-11-06T21:31:12Z,2015-11-06T21:31:31Z,"Ah! Thanks. Yeah,  I believe it produces the result we wanted to see.
```
> RNeXML:::get_level(ne, level=""characters/format/char"")
Source: local data frame [3 x 6]

                                 states             id                                           label           about xsi.type format
                                  (chr)          (chr)                                           (chr)           (chr)    (lgl)  (chr)
1 sa75ef9ac-e74e-4015-846d-27d793868951 UBERON_2002002 anterior distal serration of pectoral fin spine #UBERON_2002002       NA   root
2 s99d94a8b-9bab-4b56-990a-a3fcc85900f4 UBERON_2001788                                   pelvic splint #UBERON_2001788       NA   root
3 sb29f0f18-addb-4e9b-bcef-833065cba124 UBERON_2002001        anterior dentation of pectoral fin spine #UBERON_2002001       NA   root
```
If I am understanding it right - the ```id``` column from above result  corresponds to the  ```char``` column in the following data frame right?
```
> RNeXML::get_metadata(ne, level=""characters/format/char"")
Source: local data frame [3 x 6]

     id             rel                                          href     xsi.type           char format
  (lgl)           (chr)                                         (chr)        (chr)          (chr)  (chr)
1    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2002002 ResourceMeta UBERON_2002002   root
2    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2001788 ResourceMeta UBERON_2001788   root
3    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2002001 ResourceMeta UBERON_2002001   root
```",NA,NA,NA
137,154558490,cboettig,2015-11-06T22:14:09Z,2015-11-06T22:14:09Z,"Correct, id is the id attribute of the specified level (char in this
case).  All col names (including id are just the attribute names from that
level, except the last column which has the id of the parent, and is named
using the parent's element.

Perhaps it would be cleaner to go ahead and rename the id column with the
element name?  I guess that would make joins easier, though it might not be
obvious that these are id attributes?

On Fri, Nov 6, 2015, 1:31 PM Hong Xu <notifications@github.com> wrote:

> Ah! Thanks. Yeah, I believe it produces the result we wanted to see.
>
> > RNeXML:::get_level(ne, level=""characters/format/char"")
> Source: local data frame [3 x 6]
>
>                                  states             id                                           label           about xsi.type format
>                                   (chr)          (chr)                                           (chr)           (chr)    (lgl)  (chr)
> 1 sa75ef9ac-e74e-4015-846d-27d793868951 UBERON_2002002 anterior distal serration of pectoral fin spine #UBERON_2002002       NA   root
> 2 s99d94a8b-9bab-4b56-990a-a3fcc85900f4 UBERON_2001788                                   pelvic splint #UBERON_2001788       NA   root
> 3 sb29f0f18-addb-4e9b-bcef-833065cba124 UBERON_2002001        anterior dentation of pectoral fin spine #UBERON_2002001       NA   root
>
> If I am understanding it right, the id column from above result
> corresponds to the char column in the following data frame right?
>
> > RNeXML::get_metadata(ne, level=""characters/format/char"")
> Source: local data frame [3 x 6]
>
>      id             rel                                          href     xsi.type           char format
>   (lgl)           (chr)                                         (chr)        (chr)          (chr)  (chr)
> 1    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2002002 ResourceMeta UBERON_2002002   root
> 2    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2001788 ResourceMeta UBERON_2001788   root
> 3    NA obo:IAO_0000219 http://purl.obolibrary.org/obo/UBERON_2002001 ResourceMeta UBERON_2002001   root
>
> —
> Reply to this email directly or view it on GitHub
> <https://github.com/ropensci/RNeXML/issues/137#issuecomment-154547701>.
>
-- 

http://carlboettiger.info
",NA,NA,NA
137,157223895,cboettig,2015-11-17T00:52:01Z,2015-11-17T00:52:01Z,"Okay, should be all fixed in master now.  Also has `get_level` exposed to the user.  ",NA,NA,NA
108,157224295,cboettig,2015-11-17T00:54:33Z,2015-11-17T00:54:33Z,"All good points here.  Just for the record, here's how we originally decided on what we have here

https://github.com/ropensci/RNeXML/issues/48",NA,NA,NA
138,117254435,cboettig,2015-11-17T00:49:19Z,2015-11-17T00:49:27Z,"- Merge the new `get_characters` method.
- expose the `get_level()` function
- be stricter about treating state symbols as integers
- some bugfixes to existing tests (resulting from stricter treatment)

Should close #135 and #137 ",closed,0,Fix get characters
137,115162550,xu-hong,2015-11-04T22:21:11Z,2015-11-17T00:52:01Z,"Currently what the ```get_characters``` function really does is ""get characters matrix"". There is no equivalent function to ```get_taxa``` for anatomical entities. 
```
> get_taxa(ne)
Source: local data frame [9 x 5]

           id                   label        about xsi.type                                  otus
        (chr)                   (chr)        (chr)    (lgl)                                 (chr)
1 VTO_0036225     Ictalurus punctatus #VTO_0036225       NA t0d4df580-2d92-4166-8518-a76116df5295
2 VTO_0061498     Ictalurus mexicanus #VTO_0061498       NA t0d4df580-2d92-4166-8518-a76116df5295
3 VTO_0061495     Ictalurus australis #VTO_0061495       NA t0d4df580-2d92-4166-8518-a76116df5295
4 VTO_0036221      Ictalurus balsanus #VTO_0036221       NA t0d4df580-2d92-4166-8518-a76116df5295
5 VTO_0036218        Ictalurus pricei #VTO_0036218       NA t0d4df580-2d92-4166-8518-a76116df5295
6 VTO_0036223      Ictalurus furcatus #VTO_0036223       NA t0d4df580-2d92-4166-8518-a76116df5295
7 VTO_0036220         Ictalurus lupus #VTO_0036220       NA t0d4df580-2d92-4166-8518-a76116df5295
8 VTO_0061497       Ictalurus dugesii #VTO_0061497       NA t0d4df580-2d92-4166-8518-a76116df5295
9 VTO_0061496 Ictalurus sp. (Mo 1991) #VTO_0061496       NA t0d4df580-2d92-4166-8518-a76116df5295
```
Users would want to see the mapping from ```label``` to ```char``` for anatomical entities as well.  There should be a function that returns the data frame similar to what ```get_taxa``` returns.
cc @hlapp 

",closed,10,"""get_characters"" function that is equivalent to get_taxa?"
136,113933488,hlapp,2015-10-28T21:55:47Z,2015-10-29T19:00:55Z,"NeXML as a format can contain multiple characters and otus blocks, and identifiers are used to tie them together. As per the brief conference call, there is currently no way to obtain the otus reference from a `<characters/>` block that would allow one to properly subset the data.frame returned by `get_taxa()`.",closed,3,Cannot get otus reference from characters block
135,113912436,hlapp,2015-10-28T20:14:01Z,2015-11-17T00:49:27Z,"The `rownames_as_col` parameter for `get_characters()` is documented as this:

> option to return character matrix rownames (with taxon ids) as it's own column in the data.frame. Default is FALSE for compatibility with geiger and similar packages.

However, the result only includes the taxon _names_, not the IDs:

```R
> get_characters(nex,rownames_as_col = TRUE)
                     taxa pelvic splint anterior dentation of pectoral fin spine
1        Ictalurus pricei             1                                        1
2         Ictalurus lupus             1                                        1
3      Ictalurus balsanus             1                                        0
4      Ictalurus furcatus             1                                        0
5     Ictalurus punctatus          <NA>                                        1
6     Ictalurus australis             1                                        1
7 Ictalurus sp. (Mo 1991)             0                                     <NA>
8       Ictalurus dugesii             1                                     <NA>
9     Ictalurus mexicanus             1                                     <NA>
  anterior distal serration of pectoral fin spine
1                                               1
2                                               1
3                                            <NA>
4                                               1
5                                               1
6                                               1
7                                            <NA>
8                                               1
9                                               1
```

The taxon IDs are missing. This means that matching rows with the value returned by `get_taxa()` remains ambiguous (because labels, i.e., taxon names, are not required to be unique). ",closed,7,rownames_as_col option for get_characters() not working as expected
134,113909328,hlapp,2015-10-28T19:57:48Z,2015-10-29T18:22:27Z,"The following call results in an error since #133 has been merged:

```R
> get_metadata(nex, level=""char"")
Error in slot(node, element) : 
  no slot of name ""char"" for this object of class ""nexml""
```

Level ""otu"" appears to work fine:

```R
> get_metadata(nex, level=""otu"")
Source: local data frame [10 x 6]

      id         rel                                       href     xsi.type         otu
   (lgl)       (chr)                                      (chr)        (chr)       (chr)
1     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0036225 ResourceMeta VTO_0036225
2     NA      parent http://purl.obolibrary.org/obo/VTO_0036217 ResourceMeta VTO_0036225
3     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0061498 ResourceMeta VTO_0061498
4     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0061495 ResourceMeta VTO_0061495
5     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0036221 ResourceMeta VTO_0036221
6     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0036218 ResourceMeta VTO_0036218
7     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0036223 ResourceMeta VTO_0036223
8     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0036220 ResourceMeta VTO_0036220
9     NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0061497 ResourceMeta VTO_0061497
10    NA dwc:taxonID http://purl.obolibrary.org/obo/VTO_0061496 ResourceMeta VTO_0061496
Variables not shown: otus (chr)
```",closed,5,"get_metadata() throws error for level ""char"""
133,113737253,cboettig,2015-10-28T03:38:23Z,2015-10-28T03:38:48Z,"Hopefully this should address several of the recently discussed issues.

- `get_metadata()`, `get_taxa()` now return much richer `data.frames` instead of named vectors. 
  This is potentially a non-backwards compatible change if scripts use the output of these
  functions as lists (#129).  See updated metadata vignette.  This also introduces new dependencies
  `dplyr` and `lazyeval`. 

- more robust `nexml_read()` method for URLs, (#123)

- Avoid assuming the namespace prefix `nex` for nexml elements (#51, #124, #126). Includes a
  fix server-side on the NeXML validator as well.

- `nexml_validate()` points to the new validator. (#126)

- Minor tweaks to documentation, streamlining some functions.

",closed,0,Merging dev branch
132,113471115,cboettig,2015-10-26T23:19:04Z,2015-10-27T16:28:03Z,"Hey @sckott ,

`taxize_nexml()` does a nice job of getting metadata when the labels are good species names.  Would it be possible to extend this to handle names that are higher-order taxonomy?  e.g. this nexml file gives otu labels as families I think:  https://github.com/ropensci/RNeXML/blob/master/inst/examples/geospiza.xml  

e.g.

```r
nex <- nexml_read(""https://raw.githubusercontent.com/ropensci/RNeXML/master/inst/examples/geospiza.xml"")
taxize_nexml(nex)
```

",open,3,taxize_nexml() identify higher-level taxonomic names automatically?
131,111527532,sckott,2015-10-15T01:36:31Z,2015-10-15T20:04:34Z,"switch to generic S3 function, with methods for character, XMLInternalDocument and XMLInternalNode
added more examples for all the possible inputs
changed character input checking to hopefully fail well when character input not appropriate

addresses #123

@cboettig feel free to not accept this - there may be good reason not to switch approaches that I'm not thinking of. Can add tests, where's the best place to put those?",closed,5,changes to nexml_read
130,111267168,hadley,2015-10-13T20:46:34Z,2015-10-21T04:32:10Z,"```
checking tests ... ERROR
Running the tests in ‘tests/test-all.R’ failed.
Last 13 lines of output:
  Retrieving data for taxon 'Myotis_nigricans'
  
  
  Retrieving data for taxon 'Myotis_sodalis'
  
  testthat results ================================================================
  OK: 143 SKIPPED: 0 FAILED: 1
  1. Error: we can coerce an ape::phylo tree with a 
            phytools:simmap extension into nexml 
  
  Error: testthat unit tests failed
  In addition: There were 49 warnings (use warnings() to see them)
  Execution halted
```

I'm submitting this afternoon, so you may want to prepare a new release in the near future",closed,1,Test failure with dev testthat
129,110307950,hlapp,2015-10-07T20:19:30Z,2015-10-29T18:22:10Z,"Perhaps there is an easy way in the API already - how does one get at the the taxon IDs as annotated, for example, in the form of dwc:taxonID metadata? Like here in the NeXML produced by the Phenoscape API:

```xml
<otu id=""VTO_0061495"" label=""Ictalurus australis"" about=""#VTO_0061495"">
      <meta xsi:type=""ResourceMeta"" rel=""dwc:taxonID"" href=""http://purl.obolibrary.org/obo/VTO_0061495"" />
</otu>
```

cc @xu-hong.",closed,32,How to access the taxon IDs if the NeXML source contains them
128,109184655,hlapp,2015-09-30T21:37:26Z,2015-10-29T18:22:56Z,"Here's the log:

```R
> nexml_validate(""./inst/examples/test_original.xml"")
[1] FALSE
Warning message:
In nexml_validate(""./inst/examples/test_original.xml"") :
  Validation failed, error messages: 
                    'http://purl.obolibrary.org/obo/VTO_0036225' is not a valid xml NCName for Bio::Phylo::Taxa::Taxon=SCALAR(0x1ce5440)            Validation failed, error messages: 
                    'http://purl.obolibrary.org/obo/VTO_0036225' is not a valid xml NCName for Bio::Phylo::Taxa::Taxon=SCALAR(0x1ce5440)
```

The [file](https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test_original.xml) is the original NeXML returned by the Phenocape API.

One thing that might come into play here is the use of HTTP URIs as local identifiers. I have filed issue phenoscape/phenoscape-kb-services#15 for whether this is on purpose, and what motivates it.",closed,8,nexml_validate issues warnings on validating valid NeXML
127,109078713,hadley,2015-09-30T12:42:14Z,2015-09-30T23:46:14Z,"With dev version of testthat, I see

```
checking package dependencies ... NOTE
Packages suggested but not available for checking: ‘rrdf’ ‘Sxslt’
```
```
checking tests ... ERROR
Running the tests in ‘tests/test-all.R’ failed.
Last 13 lines of output:
  Retrieving data for taxon 'Myotis_nigricans'
  
  
  Retrieving data for taxon 'Myotis_sodalis'
  
  testthat results ================================================================
  OK: 143 SKIPPED: 0 FAILED: 1
  1. Error: we can coerce an ape::phylo tree with a 
            phytools:simmap extension into nexml 
  
  Error: testthat unit tests failed
  In addition: There were 49 warnings (use warnings() to see them)
  Execution halted
```
```
DONE
Status: 1 ERROR, 1 NOTE
```",closed,1,R CMD check failures
126,107982319,sckott,2015-09-23T18:47:31Z,2015-10-28T15:45:18Z,"#125 

These changes fix `get_characters()` so that the fxn works more generally, with associated change to namespace map  ",closed,27,Fixes to get_characters 
125,107816824,xu-hong,2015-09-22T22:40:27Z,2015-10-29T18:23:36Z,"I tried the following code to parse the nexml (stored as [test.xml](https://raw.githubusercontent.com/xu-hong/rphenoscape/master/inst/examples/test.xml)) returned by the [OntoTrace API] (http://docs.phenoscapekb.apiary.io/#reference/ontotrace/ontotrace/generate-matrix-of-inferred-presence/absence-associations-for-anatomical-structures-subsumed-by-the-provided-entity-class-expression,-for-any-taxa-within-the-provided-taxon-class-expression?console=1) provided by Phenoscape Knowledgebase:
```r
nex <- nexml_read(""https://raw.githubusercontent.com/xu-hong/rphenoscape/master/inst/examples/test.xml"")
get_characters(nex)
```
But I was getting ```NULL``` as the matrix returned by ```get_characters(nex)```. The nexml file seems valid with matrix exists in it, but somehow the function was not able to correctly parse it. ",closed,21,get_characters() not detecting the matrix in nexml file
124,107816456,hlapp,2015-09-22T22:37:33Z,2015-10-28T03:38:42Z,"Perhaps RNeXML has a built-in expectation for the abbreviation of the NeXML namespace? The following lines result in an error, complaining about the `ns` namespace:

```xml
<nexml xmlns=""http://www.nexml.org/2009"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" version=""0.9"" xsi:schemaLocation=""http://www.nexml.org/2009 http://www.nexml.org/2009/nexml.xsd http://www.bioontologies.org/obd/schema/pheno http://purl.org/phenoscape/phenoxml.xsd"">
  <meta xmlns:ns=""http://www.nexml.org/2009"" xmlns:ter=""http://purl.org/dc/terms/"" xsi:type=""ns:LiteralMeta"" property=""ter:creator""/>
```

This shouldn't result in an error. If one changes `ns:LiteralMeta` to `nex:LiteralMeta` (with `nex` not defined anywhere!), the error goes away. So this seems backwards to me - what shouldn't give an error does, and what should give an error doesn't.

What prompts this is that the Phenoscape API (cc @balhoff) apparently returns NeXML with the NeXML namespace defined (by a `xmlns:ns=""http://www.nexml.org/2009""` attribute) from scratch for every single element for which it is needed, rather than once at the root element, and it always uses `ns` (which is legitimate, even if not pretty).

I have posted this over on the Phenoscape API too (phenoscape/phenoscape-kb-services#12) to declare this less verbose and using the standard prefix, but RNeXML should be able to read legitimately formatted NeXML.

For reference, [here is an original file](https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test_original.xml) as returned by the Phenoscape API, and here is an [edited file with the change throughout as per above](https://github.com/xu-hong/rphenoscape/blob/master/inst/examples/test.xml). The former raises an error with `nexml_read()`, the latter doesn't (but arguably should).",closed,4,Parsing of XML namespace declarations in XML input is incorrect
123,107814848,xu-hong,2015-09-22T22:24:37Z,2015-10-16T01:44:48Z,"If I give an ```XMLInternalDocument```object as input x,
the ```nexml_read(x)``` will raise:
Error in as.vector(x, ""character"") : 
  cannot coerce type 'externalptr' to vector of type 'character'

This is because the first if condition uses ```grep(""^https?://"", x)```, which do not accept an ```XMLInternalDocument``` type.

Should consider reordering the sequence of if statement.
@hlapp ",closed,7,"nexml_read functions complains about ""XMLInternalDocument"" as an input"
122,86821986,wcornwell,2015-06-10T03:39:04Z,2015-06-15T15:48:40Z,"Pretty cool project!  Looking forward to seeing where it's going, especially for plotting traits and phylogenies there is certainly the need for a general framework that people can build on.  

Anyway was just checking out the plotting and found the following: the example plotting code from the arxiv.org vignette:

```R
library(RNeXML)
tb_nex <- nexml_read(
""https://raw.github.com/TreeBASE/supertreebase/master/data/treebase/S100.xml"")
tb_phy <- get_trees_list(tb_nex)
plot(tb_phy[[1]])
```

At least on my system this crashes R.  This is R 3.1.3 on Mac OS with the CRAN version of the package.  

In terminal I get this error:

Error: segfault from C stack overflow
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf
5: In min(x) : no non-missing arguments to min; returning Inf
6: In max(x) : no non-missing arguments to max; returning -Inf
7: In min(x) : no non-missing arguments to min; returning Inf
8: In max(x) : no non-missing arguments to max; returning -Inf
9: In min(x) : no non-missing arguments to min; returning Inf
10: In max(x) : no non-missing arguments to max; returning -Inf
Error: C stack usage  140730498580684 is too close to the limit

Then it crashes completely.  ",open,4,Plotting crashes R--CRAN version
121,75659214,cboettig,2015-05-12T16:29:04Z,2015-05-29T23:32:17Z,"Overall, I think this package is a fantastic resource. This is a greatly needed tool
in biodiversity sciences and you have done a excellent job with the package, the
manuscript, and the supplementary materials. I look forward to seeing this published
and hope that it catches on in the community. I have a couple of criticisms that I
would I like to see addressed before I can recommend this for publication.

Major Comments on manuscript

I have two (related) critiques of this manuscript. The goal of the RNexML project is
to facilitate the use of NeXML standards in phylogenetics and comparative methods.
While the package certainly goes a long way towards this goal, I feel that the
manuscript could be better in this regard.

1. I think you need a better hook in the opening (and the abstract). Why should your
average empirical biologist care whether their files are in NeXMl format/why is it
worth bothering with (i.e., why not just deposit .tre and .csv files?) I can imagine
a few ""killer apps"", such as meta-analyses (both formal and informal) and populating
databases (such that it makes it easier to load trees into OpenTree) but these
aren't really described. While the manuscript describes why NeXML is superior to
NEXUS, I don't feel you provide sufficient examples or motivation as to why exactly
this is important. Perhaps this is not your role here -- you are not developing the
NeXML standards in this paper -- but if the goal is facilitating adoption among
empiricists, I think you need to be better marketers.

2. The manuscript is jargon-laced and in some places, unnecessarily so. Even though
I am a programming dork (or at least more so than the average biologist), I did not
understand what you were referring to in some places. I think this is another
barrier that will hinder adoption -- I am afraid that an empirist will take one look
at this and conclude it is not for them.  Here is a list of some examples (there are
others) where I think the terminology is confusing; in some places, I think the
jargon could be cut without loss, while in others I think some explanation in plain
language would go a long way.

line 10: forward-compatible

line 17: normative

line 60: validated

line 64: computable semantics

line 67: axiomated ontologies

line 202: subject-predicate-object triples

line 205: Dublin core

line 210: vocabularies

line 240: SKOS vocabulary

line 248: SPARQL


Minor comments on manuscript

line 12: **you** aim to provide, not the software

line 83: where is the branch length information stored (in topology or metadata)?

line 44: an extra sentence here would be useful explaining why the needs of
interoperability are greater now then they have been in the past

line 141: I would appreciate it if you would please use Pennell et al. 2014
Bioinformatics as the geiger citation

line 274: PDF weirdness


Comments on code

1. In your example of writing nexml files, you use the geospiza dataset from geiger.
In this dataset, the tip labels in the tree and the dataset do not perfectly match
```
data(geospiza) geiger::treedata(geospiza$phy, geospiza$dat)
```
Is this a feature or a bug of nexml? Either way, I think it is worth pointing out.

2. I tried running the function `nexml_validate` while offline and received an error
message (even though I had the XML package installed and loaded)
```
nexml_validate(""geospiza.xml"") Error in function (type, msg, asError = TRUE)  :
Could not resolve host: www.nexml.org
```

3. I love the idea of being able to programmatically archive data (in figshare or
wherever else) but am wondering whether there is a potential problem in that people
may inadvertantly archive the same data over and over again. If for example, one
sets up the workflow to be completely reproducible, will the function add a new
version of the dataset every time the script is run. Are there safeguards built in
for this?


But as I said above, overall I am very enthusiastic about this project. Great work.
Matt Pennell",closed,4,Comments from Reviewer 2
120,75658895,cboettig,2015-05-12T16:28:11Z,2015-05-25T17:45:29Z,"I have received reviews from two reviewers; both are overall very positive.  I share their enthusiasm and think that this has the potential to be an important and widely used package  The concerns that the reviewers express are very similar, however, and I would urge the authors to consider them carefully when making their revisions.

The article reads as if it is pitched to someone who has mostly bought into concepts of strictness that XML encourages, knows what an ontology is and is excited about things like RDF.  While I'm sure these things are all potentially very exciting things that can shape how people work, I honestly don't think that they are on the radar of most biologists.  It seems that metadata quality is enhanced by the formality and standardisation on one hand, and by the number of people using it on the other.  You can have the most beautiful annotations in the world but if it's difficult to users to use then they won't use it and the advantage of standardisation are lost.  Getting people excited to use them is probably more important here than speaking to the small minority who are already converts.

A bit more of a focus on how the file format and R package can help users, rather than statements that you can get more things into it would be useful.  The section on metadata (p8 - 13) is a prime example of this.  It's clear that this is something that is important to the authors, but it's framed starting from a set of arbitrary looking commands, rather than from a problem that is not currently solvable.

Similarly flagging which bits are for package developers (see below) might be helpful.  The strength of the ape package is that people have built other packages on top of it (~100 packages on CRAN).  Features pitched at package developers would necessarily be more technical in nature.

While the horse has well and truly bolted, I feel that S4 is the wrong technology for this sort of thing.  S4 classes will be a barrier for people to contribute to the package (personally I wish they could be removed from the language).  Nothing can be done about this, but that ape remains the primary way people interact with trees in R speaks to the benefits of ease of use and extension over formality for the R user and developer base at large (in contrast with ape, I see 4 declared dependencies on phylobase on CRAN).

Similarly, I wish the abstractions involved with XML were not so leaky.  Does the average user need to understand about Dublin Core and XML namespaces to be able to append metadata to their phylogenies?  Or do the authors imagine other user-friendly tools being built on top of RNeXML, with this package being some sort of solid low-level commands?  If one needs to deal with XML to read/write files that will be a serious barrier to use; most biologists should not need to care how their files are being loaded/saved.

Despite the focus on formal validity (ostensibly the benefit of XML), it's somehow disturbing to me that there are additional checks not captured by the schema (l. 150).  I didn't get a sense of what these additional checks are.

The package as explained in the title is for reading/writing XML files of a particular format.  It's not clear why this takes >2700 lines of code (excluding comments).  Perhaps this is the necessary verbosity of dealing with S4 and XML, but I wonder if the authors are underselling some of the functionality of the package.  If the latter is true, that is their call of course.

l. 183 ""a time-stamp of when a tree was produced"": is this always a good idea?  I presume ""produced"" here is when the tree is written to file.  So reading and immediately writing a tree would update the timestamp?  This would mean that it's impossible to verify the results of an analysis are unchanged by comparing file hashes even if the contents are substantially unchanged.

l. 196: for extending the syntax - will this not lead to downstream
incompatibilities as with the NEXUS format?  This section will be
quite opaque to most readers.  ""The RNeXML interface described above
for built-in metadata annotations perform this cast automatically
behind the scenes, including mapping metadata attributes to terms in
requisite common vocabularies (such as Dublin Core for ""title"",
""creator"", etc.) or ontologies"".

l. 272: I'm honestly not sure what this is meant to express.  I can't imagine that typing something like this is going to inspire people to get excited about using the package.  Presumably nobody would actually write such verbose commands, but package authors (e.g. Revell if using RNeXML storing data for reconstructions) would write functions that generate calls like this?
",closed,1,Comments from the Associate Editor (posted with permission from MEE & editor)
119,73350410,hadley,2015-05-05T15:42:02Z,2015-05-26T12:15:05Z,"```
checking tests ... ERROR
Running the tests in ‘tests/test-all.R’ failed.
Last 13 lines of output:
   Taxa: 	  ... 
  
   NeXML generated by RNeXML using schema version: 0.9 
   size: 21.7 Kb 
  Authentication successful
  Error in library(phytools) : there is no package called 'phytools'
  Calls: test_check ... lapply -> FUN -> sys.source2 -> eval -> eval -> library
  In addition: Warning messages:
  1: In merge.data.frame(dfs, ..., by = ""row.names"", all = TRUE, sort = FALSE) :
    column names 'cs15_log snout-vent length.x', 'cs15_log snout-vent length.y' are duplicated in the result
  2: In merge.data.frame(dfs, ..., by = ""row.names"", all = TRUE, sort = FALSE) :
    column names 'cs31_reef-dwelling.x', 'cs31_reef-dwelling.y' are duplicated in the result
  Execution halted
```

You can use `skip_if_not_installed()` to avoid this problem.",closed,2,Tests fail when suggested packages not installed
118,71385662,hlapp,2015-04-27T20:01:04Z,2015-10-28T03:40:05Z,"Somehow this got messed up, not sure when that happened. Also, making it so
that the supercript of the last author is not oddly out of order with the
alphabet.

The resubmission may not need to get fixed immediately, but we should make sure we catch this on the galley proofs.",closed,0,Fixes affiliation of HL.
117,71143166,hlapp,2015-04-27T00:53:07Z,2015-10-28T03:39:23Z,,closed,1,Edits to the manuscript revision
116,70465043,sckott,2015-04-23T17:20:05Z,2015-04-27T18:40:05Z,"* https://github.com/ropensci/RNeXML/blame/master/manuscripts/manuscript.Rmd#L177 Do we want to suggest people go to discuss.ropensci.org as an additional option?
* https://github.com/ropensci/RNeXML/blame/master/manuscripts/manuscript.Rmd#L179-L180 Is there a reason these vignettes aren't in the CRAN version?  They're here in github, so i guess they will be in next cran version
* https://github.com/ropensci/RNeXML/blame/master/manuscripts/manuscript.Rmd#L600 s/""such as those""/""such those""",closed,2,A few manuscript questions/comments
115,54709905,hlapp,2015-01-18T20:59:26Z,2015-10-28T03:39:24Z,"Perhaps this is a difference between OSs or systems, but for me the
argument `--volumes` results in an error. It needs to be `--volume=`
for mounting host directories, at least on MacOSX.",closed,1,Fixes argument for mounting volumes.
114,54709659,hlapp,2015-01-18T20:51:20Z,2015-01-18T21:49:20Z,,closed,0,Fixes working directory in Dockerfile instructions for manuscript rendering
113,54708850,hlapp,2015-01-18T20:26:55Z,2015-01-18T20:48:40Z,"At present the user has to provide the namespace URI for prefixes used in metadata attributes. But for well-known prefixes, the package could leverage the crowd-sourced resource [prefix.cc](http://prefix.cc). (I've also just registered the prefix `nex` there).",open,1,Add support for using prefix.cc for resolving new prefixes to namespace URIs
112,54708426,hlapp,2015-01-18T20:12:26Z,2015-09-22T22:25:21Z,"Too bad we missed this for initial submission, but let's make sure it's fixed for revision.",closed,1,References heading is missing from rendered manuscript
111,54708373,hlapp,2015-01-18T20:10:49Z,2015-01-18T21:09:55Z,"Here's the error I get:

```
Reigen:manuscripts (master) $ docker cp rnexml:/host/manuscript.pdf .
2015/01/18 12:10:18 Error response from daemon: Could not find the file /host/manuscript.pdf in container rnexml
```",closed,1,Dockerfile instructions contain incorrect directory
110,53641120,hlapp,2015-01-07T15:05:53Z,2015-01-08T18:13:38Z,"This tries to take the changes in the manuscript text into account and applies corresponding highlights and emphases.

_(Note that this necessarily also contains the commits from PRs #106 and #109. You may want to merge those first.)_",closed,0,Partial rewrite and edits for manuscript abstract
109,53394556,hlapp,2015-01-05T13:12:48Z,2015-01-08T18:13:21Z,"Nothing extensive or substantive cut out yet. Still, word count is now down to about 3700, of which about 260 are attributable to R code sections (and should thus arguably not count). Also not counting Acknowledgements, but every citation will count between 1-2 words (depending on containing an underscore or not).

Hence, we're pretty close to within 10% of the 3000 words target, and arguably close enough that we might try submitting after a final polish.

_(Note this PR necessarily contains all the commits for the first pass, which is in PR #106.)_ ",closed,0,Second pass of manuscript rewrite for application note
108,53285545,hlapp,2015-01-02T23:27:29Z,2015-11-17T00:54:33Z,"The following is the `simmap` example in the current manuscript draft:

```R
 m <- meta(""simmap:reconstructions"", children = c(
        meta(""simmap:reconstruction"", children = c(

          meta(""simmap:char"", ""cr1""),
          meta(""simmap:stateChange"", children = c(
            meta(""simmap:order"", 1),
            meta(""simmap:length"", ""0.2030""),
            meta(""simmap:state"", ""s2""))),
          
          meta(""simmap:char"", ""cr1""),
          meta(""simmap:stateChange"", children = c(
            meta(""simmap:order"", 2),
            meta(""simmap:length"", ""0.0022""),
            meta(""simmap:state"", ""s1"")))
          ))))
```

Questions:

1. Why do we need to have two `simmap:char` properties? Is it really possible that a branch can change state from one state of one character to a state of a different character? And even if that were possible, shouldn't the `simmap:char` then instead be a property of `simmap:stateChange`?
2. I am assuming that the reason we have to have a `simmap:char` to start with is because a NeXML state object may (in theory) be reused between different characters, and so which character we are talking about needs to be stated explicitly rather than letting it be determined implicitly?
3. Is there a reason the `simmap:stateChange` element is named that way? It sounds odd that a state change has a length (the status of being in a certain state may have a length, but the change to a state?), and if indeed what is being described is a state change, I would expect to see something like `fromState` and `toState` as properties. Is `stateChange` perhaps a misnomer?",open,3,simmap vocabulary issues: char and stateChange
107,53285013,hlapp,2015-01-02T23:15:08Z,2015-01-08T03:19:36Z,,closed,1,Improvements to simmap vocabulary definitions.
106,53210366,hlapp,2015-01-01T01:11:20Z,2015-01-08T18:13:03Z,"I'm putting this up here to close out the year, not because it's complete. That said, the word count is now down to 4800 from over 6000, and the remaining parts for finishing up the first pass will bring it down further towards 3000.

Feel free to leave open until the first pass is complete.",closed,1,First pass of manuscript rewrite for application note
105,51444636,sckott,2014-12-09T15:59:52Z,2014-12-09T16:18:22Z,"I just checked `devtools::revdep_check()`, and I get for `RNeXML` (this doesn't seem like a problem with taxize, but i wasn't sure):

```
* using log directory ‘/private/var/folders/gs/4khph0xs0436gmd2gdnwsg080000gn/T/RtmpMsC2do/check_cran52d34045f85/RNeXML.Rcheck’
* using R version 3.1.2 (2014-10-31)
* using platform: x86_64-apple-darwin13.4.0 (64-bit)
* using session charset: UTF-8
* using option ‘--no-codoc’
* checking for file ‘RNeXML/DESCRIPTION’ ... OK
* checking extension type ... Package
* this is package ‘RNeXML’ version ‘2.0.0’
* checking package namespace information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for executable files ... OK
* checking for hidden files and directories ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking whether package ‘RNeXML’ can be installed ... [10s/10s] OK
* checking installed package size ... OK
* checking package directory ... OK
* checking ‘build’ directory ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies ... OK
* checking whether the namespace can be unloaded cleanly ... WARNING
---- unloading
Error in .mergeMethodsTable(generic, mtable, get(tname, envir = env),  : 
  trying to get slot ""defined"" from an object of a basic class (""environment"") with no slots
Calls: unloadNamespace ... <Anonymous> -> .updateMethodsInTable -> .mergeMethodsTable
Execution halted
* checking dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd line widths ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... SKIPPED
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking contents of ‘data’ directory ... OK
* checking data for non-ASCII characters ... OK
* checking data for ASCII and uncompressed saves ... OK
* checking installed files from ‘inst/doc’ ... OK
* checking files in ‘vignettes’ ... OK
* checking examples ... [16s/16s] OK
* checking for unstated dependencies in tests ... OK
* checking tests ... ERROR
Running the tests in ‘tests/test-all.R’ failed.
Last 13 lines of output:
   	 0 taxonomic units 
   Taxa: 	  ... 
  
   NeXML generated by RNeXML using schema version: 0.9 
   size: 21.7 Kb 
  
  parsing : ...
  publish : Authentication successful
  5
  rdf : Loading required package: Sxslt
  .Loading required package: rrdf
  Loading required package: rJava
  No Java runtime present, requesting install.

```",closed,2,Question on taxize devtools::revdep_check
104,51115617,hadley,2014-12-05T16:11:57Z,2014-12-05T21:02:38Z,"```
checking R code for possible problems ... NOTE
get_rdf: no visible global function definition for
  ‘xsltApplyStyleSheet’
nexml_figshare: no visible global function definition for ‘fs_create’
nexml_figshare: no visible global function definition for
  ‘fs_add_authors’
nexml_figshare: no visible global function definition for
  ‘fs_add_categories’
nexml_figshare: no visible global function definition for ‘fs_add_tags’
nexml_figshare: no visible global function definition for ‘fs_upload’
nexml_figshare: no visible global function definition for
  ‘fs_make_private’
nexml_figshare: no visible global function definition for
  ‘fs_make_public’
```
",closed,4,CRAN check notes
103,51115570,hadley,2014-12-05T16:11:30Z,2014-12-05T20:41:24Z,Pointing to this repo,closed,0,DESCRIPTION should include URL and BugReports
102,50838108,hlapp,2014-12-03T13:38:58Z,2014-12-03T21:31:38Z,"See TreeBASE/supertreebase#9. Although presumably there are redirects in place that should keep the code sample working, should still change the path in the manuscript (and perhaps other places where it is used?).",closed,0,supertreebase location has changed
101,50528466,hlapp,2014-12-01T14:20:12Z,2014-12-28T20:01:19Z,Includes an additional reference (to TreeBASE).,closed,3,Various edits to the Intro to RNeXML section 
100,50324421,hlapp,2014-11-27T21:31:00Z,2014-11-28T17:02:22Z,"Overall, I tried to provide for better flow, less redudancy, and clearer motivation preceding or at least quickly following all statements about features and capabilities. Also, adds citation and reference for NEXUS.",closed,1,Edits to and partial rewrite of the Introduction
99,49749878,cboettig,2014-11-21T21:22:52Z,2015-01-18T20:00:19Z,"Hi @hlapp,

Wondering if you could take one more quick read over the sections I edited in response to today's call?

-  I've revised the introduction entirely, but in particular have tried to emphasize the semantic uses while still being brief (e.g. paragraph 3).  Let me know if you think we should expand that further.  

-  I've added a ""future directions"" section mentioning NexSON (but needs citation?) and the big files issue, though I'm not sure that my discussion is all that meaningful or if it fits in here.  (We also already point people to the rather populated [issues tracker](https://github.com/ropensci/RNeXML/milestones/Long%20term%20objectives) for future directions)

-  I've removed the part about treebase and tried to address the NEXUS parsing issue directly in the intro (para 2).  

I have to see where we stand on page limits, but might drop the 'future directions' and the 'map paragraph' from the intro to keep things shorter.  

Thanks!",closed,1,"Review edits on semantics, etc?"
98,49725780,hlapp,2014-11-21T17:41:24Z,2014-11-21T18:01:41Z,,closed,1,Resolved a number of comments during conference call.
97,49725470,cboettig,2014-11-21T17:38:24Z,2014-11-21T21:30:32Z,"- [x] `nexml` should be last argument, not first
- [x] Don't use `...` (misspelled/unrecognized fields should throw errors)
- [x] Update examples in manuscript

Note: Introduces a minor potential break in the API (if using unnamed arguments).  @hlapp @rvosa @sckott Should we bump the major version in our semantic versioning to reflect this?",closed,2,"add_basic_meta should take nexml as the last object, drop ..., update manuscript"
96,47747901,cboettig,2014-11-04T18:31:00Z,2015-09-22T22:24:36Z,"- Make sure that Zenodo copy syncs to latest version
- Update package CITATION file/function appropriately.  

",closed,8,Archive copy of repo on Zenodo
95,47747641,cboettig,2014-11-04T18:28:45Z,2015-01-18T19:58:56Z,"Hi team,

Good chat this morning. 

I merged @hlapp 's edits into `devel`, fixed the easy things, and added a few comments in reply to his comments.  I also removed old comment threads that have since been resolved.

I understand @hlapp is going to go through the manuscript to highlight:

- areas where a design decision deserves (further) discussion
- areas where we are too much in 'user manual' mode rather than merely illustrating a key conceptual use case.  
- and will also make edits / add discussion wherever appropriate.  

Feel free to push changes to your branch or `devel` so we can review them before next week's call.  

- Carl
 


",closed,1,Manuscript next steps
94,47743366,cboettig,2014-11-04T17:48:44Z,2014-11-04T18:38:31Z,"I've written to Github to request the change, as they describe at the bottom of this page:  https://help.github.com/articles/why-are-my-contributions-not-showing-up-on-my-profile/

We don't want to delete and re-create the repository as we would lose all the very nice discussions we have in both current and previous issues on the repo.  ",closed,2,Deal with fork
93,47736491,cboettig,2014-11-04T16:56:02Z,2015-01-18T21:22:31Z,"Various topics covered in the manuscript but not in the basic README / vignette could be added as advanced vignettes.  These include:

- Adding additional metadata
- Simmap extension
- SPARQL queries
- ....",closed,2,Advanced vignettes 
92,44980074,hlapp,2014-10-06T12:57:22Z,2014-10-06T16:27:26Z,"At least in the example that's in the README, CDAO is still listed with the old namespace, instead of http://purl.obolibrary.org/obo/cdao.owl.

Note that that is not a trivial difference - the OWL files at the two locations are very different. Hence there may still be locations in the code using the old CDAO term URIs instead of the new ones with slash-based opaque identifiers. I haven't checked this yet, but it needs to be.",closed,0,CDAO namespace is still the old one
91,40860912,sckott,2014-08-21T23:20:11Z,2014-08-25T16:21:52Z,"@cboettig made some changes, comments, etc. 

looks really great, sorry took me so long. 

also, started some issues as you've already seen",closed,1,scotts comments/changes to ms
90,40859616,sckott,2014-08-21T22:58:23Z,2015-01-18T20:30:24Z,"Seems that figshare is the only option right now. Correct @cboettig ?

* Perhaps we can include a options for github, either to repo, gist, or both?
* I imagine Dryad doesn't accept submissions programmatically?

Are there other places folks may want to share nexml files?",open,10,Other options for `nexml_publish()`
89,40855047,sckott,2014-08-21T21:58:52Z,2014-08-30T15:54:36Z,"In this example I wonder if it makes sense to return by default the taxa labels as a column in the data.frame, perhaps the first column. Not a huge deal to move row names to a column, but a bit easier perhaps for downstream use?  Maybe not, not sure

```r
comp_analysis <- system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML"")
nex <- nexml_read(comp_analysis)
get_characters(nex)
```

```r
         log snout-vent length reef-dwelling
taxon_8             -3.2777799             0
taxon_9              2.0959433             1
taxon_10             3.1373971             0
taxon_1              4.7532824             1
taxon_2             -2.7624146             0
taxon_3              2.1049413             0
taxon_4             -4.9504770             0
taxon_5              1.2714718             1
taxon_6              6.2593966             1
taxon_7              0.9099634             1
```

```r
str(get_characters(nex))
```

```r
'data.frame':	10 obs. of  2 variables:
 $ log snout-vent length: num  -3.28 2.1 3.14 4.75 -2.76 ...
 $ reef-dwelling        : Factor w/ 2 levels ""0"",""1"": 1 2 1 2 1 1 1 2 2 2
```",closed,12,By default give back taxa as a column in character data.frame
88,40827001,sckott,2014-08-21T17:16:48Z,2015-01-18T20:29:40Z,"If so, i can do, let me know",closed,8,Interested in adding windows builds with Appveyor?
87,39221646,cboettig,2014-07-31T18:13:43Z,2014-07-31T18:19:22Z,"This will provide a more satisfactory resolution to issue #11 as well, where we initially considered phylobase during a period of phylobase instability on CRAN...   ",open,0,add coercion methods to/from phylobase formats
86,39216932,cboettig,2014-07-31T17:21:34Z,2015-01-18T21:35:23Z,"Rutger does this in the PERL version, seems like it could be handy.  

I do worry a bit that there's a tendency not use any hierarchical organization of metadata (see #23) that things can get confusing. For instance, when associating publications with the NeXML they are currently just added as annotations at the document-level as well.  (e.g. https://github.com/ropensci/RNeXML/blob/master/inst/examples/geospiza.xml) 

Perhaps I should be more aggressive about using hierarchical / nested meta elements, though it raises the additional challenges discussed in #23.  ",closed,3,Automatically add value of $USER to document-level metadata (dc:creator)
85,39216089,cboettig,2014-07-31T17:11:26Z,2014-07-31T17:11:39Z,"A taxa block is added when trees or characters are added.
I guess it would make sense to be able to add taxa directly,
(e.g. a NeXML file containing only RDFa metadata about taxa, 
independent of characters or trees), but I worry about confusing
people into thinking they must add taxa blocks separately, and
about when we should merge or not merge taxa blocks of matching
species; see #43 

",open,0,How about `add_taxa`?
84,39214677,cboettig,2014-07-31T16:55:18Z,2014-07-31T16:55:25Z,,open,0,add coercion methods to/from caper's tree+data structure
83,38756590,fmichonneau,2014-07-25T18:20:21Z,2014-07-31T18:19:22Z,"Original comment:

it might be beyond the scope of the manuscript but there are some nice possibilities for phylobase and RNeXML to interact. As phylobase provides classes that store together trees + data (and has a slot to store  metadata), there are definitely some interesting possibilities to pass data around.
",closed,1,include discussion about phylobase?
82,38756547,fmichonneau,2014-07-25T18:19:49Z,2014-07-31T17:26:11Z,"Original comment:

- it's a detail but sometimes APE's `phylo` class is referred to as `ape::phylo` and other times as just `phylo`, and simmap is also sometimes `simmap`",closed,1,check consistency of formatting for `phylo` and `simmap`
81,38756483,fmichonneau,2014-07-25T18:19:08Z,2014-07-31T17:29:58Z,"Original comment: 
- I edited this in a couple of places in the manuscript, but I think in general that it's better to tell the reader what a command is going to do beforehand (see l. 508-510 of my commit)",closed,1,make sure to tell the reader what to expect from a command beforehand
80,38756371,fmichonneau,2014-07-25T18:17:52Z,2014-07-31T18:23:58Z,"original comment:
- in the same section, there is a discussion about prefixes. Providing a few sentences about the use of prefixes in XML would be useful. Currently, the reader is left wondering why there is a `dc`, a `prism` and a `skos` prefix and what could be the difference between them. Talking about the scope of each namespace, and why several need to be used would be useful. Maybe bringing in Darwin Core that many people would have heard of might also be worthwhile.",closed,1,include discussion about XML namespaces
79,38756317,fmichonneau,2014-07-25T18:17:08Z,2015-01-18T19:57:50Z,"Original comment:

I think the manuscript will benefit from having a quick paragraph about some details of the XML file format. The manuscript does a good job at emphasizing that XML is well suited to store data/metadata associated with phylogenetic studies, but the manuscript lacks a section on how a XML file is organized and the definitions of some concepts that are used in the manuscript. For instance, in the section ""Custom metadata extensions"", the second paragraph reads:

    ""We see the title appears as the value of the content attribute of this meta element.""

half of the words in this sentence are mentioned for the first time here (or have been used but not defined), and it is also the first time in the manuscript that the actual content of an XML file is shown. I realize that one of the advantages of this package is to not have to deal with XML files per se, but providing, in the introduction, a brief overview of the XML format and a definition of some of the concepts of the terms used would clarify the manuscript.
",closed,12,write about the XML format in introduction
78,38755269,fmichonneau,2014-07-25T18:03:57Z,2014-07-25T18:13:01Z,"Hi,

I went through the manuscript quickly, and provided some edits/comments. RNeXML is really exciting and the manuscript provides nice examples of how powerful and useful this package is. Below are a few additional comments.

- I think the manuscript will benefit from having a quick paragraph about some details of the XML file format. The manuscript does a good job at emphasizing that XML is well suited to store data/metadata associated with phylogenetic studies, but the manuscript lacks a section on how a XML file is organized and the definitions of some concepts that are used in the manuscript. For instance, in the section ""Custom metadata extensions"", the second paragraph reads:

    > ""We see the title appears as the value of the `content` attribute of this `meta` element.""

     half of the words in this sentence are mentioned for the first time here (or have been used but not defined), and it is also the first time in the manuscript that the actual content of an XML file is shown. I realize that one of the advantages of this package is to not have to deal with XML files _per se_, but providing, in the introduction, a brief overview of the XML format and a definition of some of the concepts of the terms used would clarify the manuscript.

- in the same section, there is a discussion about prefixes. Providing a few sentences about the use of prefixes in XML would be useful. Currently, the reader is left wondering why there is a `dc`, a `prism` and a `skos` prefix and what could be the difference between them. Talking about the scope of each namespace, and why several need to be used would be useful. Maybe bringing in Darwin Core that many people would have heard of might also be worthwhile.

- I edited this in a couple of places in the manuscript, but I think in general that it's better to tell the reader what a command is going to do beforehand (see l. 508-510 of my commit)

- it's a detail but sometimes APE's `phylo` class is referred to as `ape::phylo` and other times as just `phylo`, and simmap is also sometimes `simmap`

- it might be beyond the scope of the manuscript but there are some nice possibilities for phylobase and RNeXML to interact. As phylobase provides classes that store together trees + data (and has a slot to store  metadata), there are definitely some interesting possibilities to pass data around.

Let me know if you have any questions or need additional feedback.

",closed,2,a few (minor) edits/comments to manuscript
77,38200277,cboettig,2014-07-18T18:25:25Z,2014-07-21T20:54:28Z,"@rvosa CRAN tells me that RNeXML was failing several of the automated tests last night due to www.nexml.org timing out.  The tests are hitting the validator on the site there.  

I can rewrite the validation function to just perform XML schema validation if www.nexml.org is unreachable or the validator request times out.  That would either require adding a local copy of the schema to the package (perhaps that's bad practice) or seeing if we could still reach http://www.nexml.org/2009/nexml.xsd even when the online validator times out.  

There are also the previously identified caveats to using R's built-in (xmllint based) validator:

- First, as you told me earlier, schema-only validation doesn't do all the checks that online validation does (From #34).  
- Also, as Jim discovered, xmllint uses schema localization and thus thinks that some things are not valid when in fact they are: https://github.com/ropensci/RNeXML/issues/23#issuecomment-31784823",closed,2,www.nexml.org times out on many checks (validation)
76,38135383,cboettig,2014-07-17T23:11:15Z,2014-07-21T20:55:36Z,"Anyone have suggestions for the manuscript title?  

Currently we have: ""RNeXML: Parsing and Serializing the Next Generation of Phyloinformatic Data in R"", but that's not really all that informative for the average R phylogenetics user...  

Note also that the R package title is currently: `Implementing semantically rich I/O for NeXML format`; though that can change as well and people don't tend to pay all that much attention to R package titles...",closed,4,Manuscript title?
75,37691872,cboettig,2014-07-11T19:53:23Z,2014-07-11T19:53:23Z,,open,0,add_meta should error if abbreviation is not defined in namespaces
74,37495072,cboettig,2014-07-09T18:35:52Z,2014-07-17T17:20:10Z,"http://currents.plos.org/treeoflife/article/best-practices-for-data-sharing-in-phylogenetic-research/ does a great job of listing 10 ""best practices,"" most of which can be accomplished with a few lines of RNeXML.  

Eventually It would be nice to provide a small example that hits all 10, though we're a bit short on some of MIAPA (as discussed in #46)",closed,1,Add citation to Cranston et al
73,36563357,rvosa,2014-06-26T10:26:38Z,2014-07-31T18:24:21Z,"Now that it is so relatively painless to extract RDF and run SPARQL queries on it (incidentally: great job, supercool) I think it would be good to develop a more persuasive use case to demonstrate the power of this facility. 

Here's an idea: let's say we have a tree, some trait data and some occurrences for a set of species. As usual, after all the data cleaning, we find that the species in the tree, in the trait data and the occurrences are only partially overlapping. It ought to be possible to extract the union of the taxa across these different data sources by way of a query.

What do you guys think - is that the coolest we can come up with (hopefully not?) and do we have some published data lying around that we could use to demonstrate this?",closed,16,SPARQL use case
72,36105456,cboettig,2014-06-19T18:37:25Z,2014-07-17T22:52:52Z,"Looks like we're getting close to closing out our [Submit to CRAN milestone](https://github.com/ropensci/RNeXML/issues?milestone=4&page=1&state=closed)

Might be nice to get some other eyes on the package for a quick code review?  (e.g. I just noticed some documentation doesn't include examples, #71)  

Namespace-wise I think we've done a reasonable job with consistent and logical names for functions and arguments, but feedback always welcome.  

Can someone remind me, where's our ropensci package checklist live?",closed,2,Ready to submit to CRAN??
71,36105100,cboettig,2014-06-19T18:32:55Z,2014-07-17T19:03:23Z,Some but not all already have examples.  Examples needing an internet connection should be put in a `\donttest{ }` bracket.  Examples taking longer than a few seconds to run should be put in `\dontrun{ }` bracket.  ,closed,0,All exported functions should have an example in the documentation
70,33172879,rvosa,2014-05-09T13:42:29Z,2014-05-09T13:47:36Z,"I get this, not sure how to proceed:

Error in setClass(""Base"", slots = c(`xsi:type` = ""character"")) : 
  unused argument(s) (slots = c(`xsi:type` = ""character""))
Error : unable to load R code in package 'RNeXML'
ERROR: lazy loading failed for package 'RNeXML'
* removing '/Library/Frameworks/R.framework/Versions/2.15/Resources/library/RNeXML'",closed,4,install_github error
69,31752632,cboettig,2014-04-17T18:56:04Z,2014-07-17T20:59:03Z,"Apparently R-travis skips the vignette building by default.

@sckott found this https://github.com/csgillespie/travis-examples/tree/master/vignette

suggests adding

```
env:
   global:
     - R_BUILD_ARGS="" "" 
     - R_CHECK_ARGS=""--as-cran""
     - BOOTSTRAP_LATEX=""1""
```
",closed,1,Travis should build the vignettes
68,30805129,sckott,2014-04-03T19:21:17Z,2014-06-24T08:00:37Z,@cboettig What kind of provenance did you have in mind here?  Just a URI for the taxon reference from the source? Or something even more?,open,4,taxonomy - capturing provenance
67,30804881,sckott,2014-04-03T19:18:20Z,2014-04-03T19:18:20Z,"We can currently grab data from NCBI, ITIS, COL, GBIF, Tropicos, EOL

You can currently pass the source in as a parameter `get_ids('name', db = 'ncbi')` or use the function for that specific source `get_uid('name')`. 

You could simply do a `...` into `get_ids()` to let users choose source, or expose `db` parameter in the top level of your function to make it explicit that they can pick the source. 

If users want multiple sources they can easily do by `db=c('ncbi','eol')`, etc. ",open,0,taxonomy - handling alternative authority sources other than NCBI
66,30803836,sckott,2014-04-03T19:05:07Z,2014-04-03T19:05:07Z,Is the default interactive prompt okay?  Basically if more than one match is found now the user gets an interactive prompt where the user then enters the row name of the data.frame they want. ,open,0,taxonomy - taxize tool user interface (interactive prompts)
65,30803620,sckott,2014-04-03T19:02:52Z,2014-04-03T19:02:52Z,"What kind of error handling is best in the context of `RNeXML`. Perhaps the default taxize error handling is fine.

@cboettig let me know if there's anything in particular you want",open,0,taxonomy - taxize tool error handling
64,29966761,sckott,2014-03-22T17:03:39Z,2014-03-25T22:29:49Z,"@cboettig let me know if you want anything changed, and/or if you just want the test and not the new functions",closed,5,"added tests for taxize_nexml, added fxn to extract otu metadata elements"
63,29718003,craigcitro,2014-03-19T09:43:08Z,2014-07-11T13:00:08Z,Fixes #61.,closed,0,Install some apt packages *before* adding more apt repos.
62,29665530,sckott,2014-03-18T17:22:20Z,2014-03-25T22:30:05Z,"@cboettig These changes were sprouted off of devel branch, so merge should actually work this time",closed,2,changes to manuscript file
61,29661159,cboettig,2014-03-18T16:33:23Z,2014-03-25T22:29:49Z,"Travis is failing to build RNeXML now due to an error installing libgdal1-dev [see travis log](https://travis-ci.org/ropensci/RNeXML/builds/21021360)  It used to install this just fine, so I'm not sure what has happened; perhaps @craigcitro has some insight?  

@sckott points RNeXML's installation of this dependency is now different from that in taxize

https://github.com/ropensci/RNeXML/blob/master/.travis.yml#L8 compared to https://github.com/ropensci/taxize/blob/master/.travis.yml#L7  

But since craig changed the one in RNeXML https://github.com/ropensci/RNeXML/commit/4fcd5f43af8f964b6d7ec278e2af25f97713b063 perhaps his change should be correct. ",closed,7,And suddenly Travis is unhappy about libgdal1-dev
60,29650994,sckott,2014-03-18T14:47:09Z,2014-03-25T22:30:05Z,,closed,0,some additions to manuscript file
59,29608046,cboettig,2014-03-17T23:19:55Z,2014-03-25T22:29:49Z,"Part of the goal of `RNeXML` is to facilitate publishing phylogenetic trees with rich metadata in NeXML as supplements to publications and  facilitate sharing.  While it is relatively trivial to upload a file to a repository like Dryad or figshare, this usually involves repeating the entry of metadata that could have been extracted from the NeXML (or conversely, entering metadata in the repository system that would ideally also be entered into the NeXML file).  Automating the publishing step of NeXML from R might increase both the quality and frequency of submissions.  I imagine an interface looking something like:

```coffee
doi <- nexml_publish(birds, visibility = ""public"", repository = ""figshare"")
```

Rather than loading the data from some local file, a researcher could then always work from the deposited copy in their own scripts, ensuring that the data is not lost and that future users can run the script without getting some error about a local file not being found; something like:

```coffee
nexml <- nexml_read(doi)
```


",closed,16,Publish NeXML files to scientific repositories from R
58,29463472,cboettig,2014-03-14T19:28:43Z,2015-01-18T20:05:44Z,"Hi @rvosa @sckott @hlapp 

On the devel branch of the [inst/doc/pubs](https://github.com/ropensci/RNeXML/tree/master/inst/doc/pubs) directory you'll find the current draft of the [manuscript.Rmd](https://github.com/ropensci/RNeXML/blob/master/inst/doc/pubs/manuscript.Rmd) describing our RNeXML package.  I have in mind the format of a Methods in Ecology and Evolution applications note, though it may be too long for that and I'm more than open to other suggestions.  

While the draft is far from finished, I wouldn't mind getting some big-picture feedback at this stage.  Feel free to add inline comments either as text or html comments, and/or open issues with a tag for ""manuscript"".  

The manuscript is written in R-markdown, allowing us to embed the R code into the document so that it is run and its results displayed when compiled.  This works similarly to the README.Rmd you will see in the same directory, which is compiled to provide both the README for the github page and a pdf for the package vignette, both of which are generated using the Makefile (though the vignette will also be built during package install by default).  The manuscript can likewise be built as a markdown file or as a pdf using `make manuscript.pdf` or `make manuscript.md`, the former requiring pandoc in addition to the R libraries.  

I haven't tested all the examples yet, but mostly looking for feedback on what examples to include or move to an appendix, the overall organization/ordering of examples.  I think we need a lot more text explaining background/context too, which I'll get to soon but feel free to add since you all may do a better job framing that anyway.  


P.S. Note that we also now have continuous integration via Travis set up for the repo, so that all commits are tested against our unit test suite and R's built in checks (such that things like undocumented function arguments will also constitute a failing build).  

Cheers,

Carl",closed,37,Manuscript comments?
57,29074135,craigcitro,2014-03-10T05:56:19Z,2014-07-15T07:50:36Z,"This makes a few changes to get the travis configuration working:

* Move `bootstrap` to the beginning of the list, so that new apt repos are
added immediately.

* Drop an `apt-get update` (since `bootstrap` does it anyway).

* Add back `rrdf` to `Suggests`, since (based on the git history) that was
only dropped to make the travis build happy. Note that I did **not** revert
any of the other diffs in that commit.

* Last, I noticed that `.travis.yml` was now giving a warning when doing the
CRAN check; I added it to `.Rbuildignore`, which involved removing
`.Rbuildignore` from `.gitignore`. If it's in there for other reasons, I'm
happy to revert.",closed,1,Make a few travis-related tweaks.
56,29007000,cboettig,2014-03-07T23:22:23Z,2014-03-25T22:29:49Z,"Add travis integration, establish a passing build without warnings. ",closed,3,Travis integration
55,28988803,cboettig,2014-03-07T18:50:31Z,2014-07-17T20:59:33Z,"@rvosa @hlapp Is there some Perl or something we could wrap to convert phyloxml into nexml, such that R users could read in that format as well? ",open,8,phyloxml support?
54,24736802,cboettig,2013-12-24T06:35:01Z,2014-03-25T22:29:49Z,"Many of the data sets provided in the geiger package give traits as a named numeric, which most geiger functions accept as an alternative to data.frame.  Should `add_characters` accept this format?  Currently only accepts character traits as a`data.frame` or `matrix`.  

```coffee
library(geiger)
data(primates)
add_characters(primates$dat)
```
```
Error in format_characters(x) : 
  x must be a matrix, data.frame, or list thereof
```",closed,0,add_characters doesn't accept a named numeric
53,24736729,cboettig,2013-12-24T06:31:16Z,2014-03-25T22:29:49Z,"```coffee
library(RNeXML)
library(geiger)
data(caudata)
add_characters(as.data.frame(caudata$dat))
```

```
Error in .subset2(x, i, exact = exact) : subscript out of bounds
```

Check remainder of data sets in geiger.  
",closed,1,Problem writing certain traits to nexml
52,23623914,cboettig,2013-12-03T06:22:16Z,2014-03-25T22:29:49Z,"Should be able to concat meta elements instead of `new(""ListOfmeta"", list(meta1, meta2))`",closed,0,concatenate method for meta elements
51,23609369,cboettig,2013-12-02T23:15:27Z,2014-07-09T18:22:19Z,"Question for @duncantl 

The XML tools respect namespace definitions on XML-level content, but view attribute values as strings. Consequently, when parsing an element such as

```xml
    <meta xsi:type = ""nex:LiteralMeta"" id = ""m1""/>
```

What should we be doing such that we can successfully identify this as a `meta` element of type 'http://www.nexml.org/2009/LiteralMeta' regardless of whether the prefix is `nex = http://www.nexml.org/2009` or something else?  


It appears XML tools do respect the `xsi` prefix as just a prefix and not a string.  `newXMLNode` warns if the prefix is not defined, as below:

```coffee
m = newXMLNode(""meta"", attrs=c(""xsi:type"" = ""nex:LiteralMeta"", id = ""m1""), namespaceDefinitions=c(xsi=""http://www.w3.org/2001/XMLSchema-instance""))
```

and if we `setClass` with a slot named without the prefix, the default xmlToS4 handles it just fine:  

```coffee
setClass(""meta"", slots=c(type=""character""))
xmlToS4(m)
```

returning:

```
An object of class ""meta""
Slot ""type"":
[1] ""nex:LiteralMeta""
```

Now it would be nice if we had a way to resolve the prefix appropriately before checking the value of the string.  Currently RNeXML assumes the prefix is `nex`, e.g.

```coffee
if(meta@type == ""nex:LiteralMeta"")
...
```

@duncantl How would we modify this statement to use whatever namespace is defined for `nex`, if possible?  Should we just manually be splitting all attribute strings on the `:` symbol and querying against the namespaces list or is there something more clever?  

(Note that these namespaces assume the role of proper XML namespaces when we do RDFa extraction to get an RDF file).  

",open,3,Handle alternative namespaces on attribute values
50,23607999,cboettig,2013-12-02T22:49:55Z,2013-12-24T10:13:08Z,,closed,3,add show and summary methods for nexml class
49,23532052,cboettig,2013-12-01T05:41:35Z,2013-12-02T13:07:44Z,"We parse polymorphic states into the S4 version fine, but do not convert them into a matrix.  

I think `StandardCells` types with polymorphisms could cause `get_characters` to error.  Not clear what the return data-type should be for the polymorphic/uncertain character state anyhow.  

Not sure that this is a high priority, not sure how common this is in character data (e.g. vs just having a single explicit uncertain state).  ",open,1,handle polymorphic states appropriately
48,23526669,cboettig,2013-11-30T21:22:00Z,2014-03-25T22:29:49Z,"Tree ""paintings"" indicating different evolutionary regimes/modes along different parts of a phylogeny are a particularly common use case for comparative phylogenetics in R.  

The current 'standard' seems to be simmap's representation, e.g. see Liam's description:  http://blog.phytools.org/2010/12/reading-simmap-trees-into-r.html

Presumably this would be done with `meta` annotations on each edge indicating the state and length of time in that state along each branch?  

Any ideas or existing examples?  ",closed,15,How would we express a simmap tree in NeXML?
47,23513278,sckott,2013-11-30T01:10:33Z,2014-03-25T22:29:49Z,"The documentation for `setClass` states

> S3methods, representation, access, version:  All these arguments are deprecated from version 3.0.0 of R and should be avoided.

I noticed that you are using `representation` whereas in `spocc` I have been using `slots`. I don't know which is right, but it looks like combo of `slots` and `contains` is recommended 

> representation is an argument inherited from S that included both slots and contains, but the use of the latter two arguments is clearer and recommended.",closed,0,Slots vs. representation?
46,23512735,cboettig,2013-11-30T00:28:33Z,2014-07-17T20:59:33Z,"RNeXML should optionally be able to include all the basic metadata listed on the [MIAPA checklist](https://github.com/miapa/miapa/blob/master/checklist/MIAPA-checklist.md), hopefully guiding users that are unfamiliar with the process and being able to provide reasonable automated suggestions when possible (e.g. suggesting external identifiers based on OTU labels, #24)   A function might be provided that could check (and perhaps summarize/return) miapa compliance(?).  



I've reproduced the checklist below with notes added on how we're doing in RNeXML. 

For each item, I've either made a note on if/how we handle it in NeXML, or a question when I'm unsure how to handle it.  For instance, I can sometimes find a corresponding block in the example files in the miapa repo, but they are in OWL and the translation to NeXML's meta/RDFa isn't clear to me.  An example nexml file that satisfies all these requirements would be super helpful to me.  


Topology
------------
- [ ] The topology itself, possibly as an identifier of a database (such as a !TreeBASE) record.  _included in the nexml `tree` node_
- [ ] Is this a gene tree or species tree? _Do we use the treebase namespace to define this, or is there a better alternative?_

```xml
<meta content=""Species Tree"" datatype=""xsd:string"" id=""meta24059"" property=""tb:kind.tree"" xsi:type=""nex:LiteralMeta""/>
```

<meta content=""21"" datatype=""xsd:integer"" id=""meta24062"" property=""tb:ntax.tree"" xsi:type=""nex:LiteralMeta""/>
<meta content=""Unrated"" datatype=""xsd:string"" id=""meta24061"" property=""tb:quality.tree"" xsi:type=""nex:LiteralMeta""/>

- [ ] It is a tree or a network? _nexml defines this by using `<tree>` or `<network>`_
- [ ] Is topology rooted or not? _In nexml, defined by an attribute `root=""true""` on a member nod__.  _Should we consider declaring this in metadata too?_

- [ ] The type of consensus if this a consensus topology (that summarizes the topology inference in some way, rather than being directly provided by the inference method)

_Do we use the treebase namespace for this as well? e.g. _

```xml
<meta content=""Consensus"" datatype=""xsd:string"" id=""meta24060"" property=""tb:type.tree"" xsi:type=""nex:LiteralMeta""/>
```

- [ ] The topology should be ""well described"", as applicable to the inference method being used. For example, a likelihood for maximum likelihood analysis. For Bayesian analyses this should also include the burn-in period excluded, and the convergence of the chain(s). This may also include more then one topology, for example a sample from the posterior probability distribution for Bayesian, or equally scoring topologies for a maximum parsimony analysis.  _Examples?_

OTUs: 
----------
All terminal nodes should be appropriately labelled and referenced in one of the following ways. Internal nodes need not be.
- [ ] A meaningful external identifier (a combination of database or resource and identifier/accession within that database).
__We generate with taxize, #24 __
- [ ] For specimens, museum, collection (if applicable), and specimen identifier. Alternatively, if a specimen is not in a museum collection, use the laboratory, laboratory collection, and accession within that collection.

- [ ] Precise (GPS) georeferences for specimens are highly desirable (but not always available).  

- [ ] Branch lengths: Some measure of branch length required unless it is not applicable to the analysis method.. Further semantics of the measure should be implied by the tree inference method.  __length attribute in nexml is sufficient__
- [ ] Branch support: Some value of branch support should be provided, for example posterior probability, or bootstrap value, unless it is not applicable to the analysis method. __meta annotation of edge node.  example?__

Character matrix: 
----------------------

__I note that this description is entirely in reference to the character matrix being data from which the tree was derived.  It appears that the MIAPA standard doesn't refer to comparative trait data.  Further, it many not always be desirable to include a copy of the character matrix in the data file, where that alignment can be found in a separate file might suffice?__

- [ ] aligned data matrix that is the basis for the tree (by having been the input for the tree inference method)

_MIAPA shows an example how how to state that the tree  `wasDerivedFrom` the alignment, not sure whe corresponding rdfa in the nexml would look like_

```xml
 <owl:NamedIndividual rdf:about=""&Peters2011hymenoptera;tree0000001"">
        <rdf:type rdf:resource=""&obo;CDAO_0000012""/>
        <rdf:type rdf:resource=""&obo;CDAO_0000073""/>
        <prov:wasGeneratedBy rdf:resource=""&annot;InferenceOfPetersTree""/>
        <prov:wasDerivedFrom rdf:resource=""&annot;PetersAlignment""/>
    </owl:NamedIndividual>
```


- [ ] Data type must be provided, for example DNA, RNA, protein, morphology, etc.
For molecular matrices, the accession numbers (and respective database(s) if different from Genbank) of the sequences used for each row must be provided.

- [ ] a mapping that relates each row identifier to a tip of the topology __otu attribute present on row__
- [ ] a mapping that relates each accession number or specimen identifier to a row label __inverse of the above map__

Alignment method
-----------------------
- [ ] name of software used, version of program

MIAPA defines that the alignment `wasGeneratedBy` some software.  

```xml
    <owl:NamedIndividual rdf:about=""&annot;PetersMUSCLEAlignmentActivity"">
        <rdf:type rdf:resource=""&edamontology;operation_2928""/>
        <rdf:type rdf:resource=""&obo;MIAPA_0000003""/>
        <prov:wasAssociatedWith rdf:resource=""&annot;Muscle""/>
        <prov:used rdf:resource=""&obo;MIAPA_0000013""/>
    </owl:NamedIndividual>
```

- [ ] parameters used (or default if default values were used).
- [ ] whether alignment was manually corrected or edited

Character trait data
-------------------------
__This is not part of the draft MIAPA standard, but merely my own suggestions/brainstorm list, based on the required metadata for EML description of character traits__
- [ ] character trait name  (Or trait label/definition pair)
- [ ] possible states a discrete trait can have
- [ ] units (for continuous traits)
- [ ] methodological description of how the trait was measured

Tree inference method
-----------------------------

- [ ] name of software used, version of program

```xml
    <owl:NamedIndividual rdf:about=""&annot;RaXML_7.2.8"">
        <rdf:type rdf:resource=""&obo;MIAPA_0000016""/>
        <rdfs:label>RAxML_7.2.8</rdfs:label>
        <swo2:SWO_0000740 rdf:resource=""&annot;UseMaximumLikelihood""/>
        <swo:SWO_0004000 rdf:resource=""&obo;MIAPA_0000017""/>
    </owl:NamedIndividual>
```

- [ ] parameters used, including model of evolution, and optimality criterion

```xml
 <owl:NamedIndividual rdf:about=""&annot;UseMaximumLikelihood"">
        <rdf:type rdf:resource=""&obo;MIAPA_0000015""/>
        <rdfs:label>Maximum Likelihood algorithm</rdfs:label>
        <dc:description>The inference algorithm uses maximum likelihood as an optimality criterion. </dc:description>
    </owl:NamedIndividual>
```

- [ ] character weights if (normally then morphological) characters were weighted. ",open,1,Generate MIAPA checklist-compliant nexml
45,23409379,cboettig,2013-11-27T19:19:23Z,2014-03-25T22:29:49Z,"One can generate a nexml file with multiple characters or mulitple trees just by passing in a list of these things, e.g. `add_characters(list_of_characters, nexml)`, `add_trees(list_of_trees, nexml)`. But sometimes it might be useful to concatenate directly.  R defines the `c` method to concatenate objects, so perhaps a method that could concatenate nexml objects (e.g. append trees and characters).   Would error if all `id` values were not unique.  ",closed,0,Provide a concatenate method for nexml class
44,23284255,cboettig,2013-11-25T23:56:34Z,2014-03-25T22:29:49Z,"I'm intrigued by @rvosa's suggestion of showing how RNeXML can be used to document both the character data and phylogenetic data used in comparative phylogenetics, which accounts for many of the R package use cases.  


However, there may be a bit of a cultural ""stereotype"" to overcome in pitching this use case.  From my own interactions I'm under the impression that most researchers assume that any character data in a NeXML file is that which is coded for and used for phylogenetic inference of the tree below it.  I am afraid researchers might be hesitant to write comparative trait data to a nexml file for fear of making it look like their beautiful tree was inferred from some tiny character data set, instead some big file of sequence data.  


I'll ask some fellow practitioners about this, but perhaps there is something we can add metadata-wise to indicate that the phylogeny was/wasn't inferred from the character data provided?  


Any thoughts on this?  ",closed,8,Interpreting comparative data in nexml files
43,23200513,cboettig,2013-11-24T05:43:59Z,2014-07-31T17:11:26Z,"If I understand the schema correctly, nexml permits multiple otus blocks, though I haven't seen this used.  

In writing a function to add characters data to an existing `nexml` object, we run into the following cases.  Only the 3rd seems to involve a non-trivial case:  

- No `otus` node has yet been generated: so we generate one corresponding to the rownames in the matrix.

- All rownames in the matrix already match otu elements in an existing otus block.  Then we do nothing.  

- If only some match, we add the unmatched otus on the character matrix as new otu entries _in the (first) existing otus_ node.  (assuming the matches are found in the first otus node).  

@rvosa It appears the schema supports multiple otus blocks, though I have only ever seen one used.  Not sure why one would have multiple otus blocks, but it does raise a few questions about handling this third case: 

So, I just wanted to make sure that we were handling this third case appropriately.  We could instead add a new otus block in this case with all the otus for the characters, which would mean duplicate entries of certain otus.  I'm not sure just how problematic that would be?  

Because a characters node must refer to a single otus node for reference (I think), there's no point in checking for matches across multiple `otus` sets, or writing only the unmatched otu labels into a separate otus node.  I assume it's no trouble to have more otu nodes in an otus block than any one trees or characters block actually needs?  

",closed,3,When to create a new otus block?
42,23168390,cboettig,2013-11-22T21:24:59Z,2014-03-25T22:29:49Z,"Might imagine a user would want to extract character data that comes in nexus format (used by http://www.morphobank.org/, for instance) into NeXML. 

Unfortunately, though ape provides `read.nexus.data`, the function is extraordinarily limited.  For instance, it cannot handle spaces in species names or sequences, and appears to return only a list of elements named by taxa without any metadata about the traits themselves, at least in reading in my hand-edited nexus matrix from morpho.  read.nexus.data also fails to read in (after a minute of cpu effort) even the example nexus file produced by ape's own `write.nexus.data` ...

Guessing these ape functions are not widely used.  Perhaps there's a better alternative pipeline for getting the nexus data into NeXML that we can wrap?",closed,11,Compatibility with read.nexus.data and write.nexus.data
41,23168073,cboettig,2013-11-22T21:17:21Z,2013-11-22T21:17:21Z,"Probably not a high priority; might be worth discovering users of the DNAbin class to get feedback first.  

",open,0,Conversions for DNA character data into/from ape::DNAbin class
40,23167770,cboettig,2013-11-22T21:10:06Z,2014-07-17T20:59:33Z,"Given a csv (or excel?) file containing (phenotypic) character data and an associated EML metadata file describing it, can we completely serialize this csv file and associated metadata into RNeXML `characters` nodes?  ",open,2,Conversion between EML and NeXML (at least for character data)
39,23160075,cboettig,2013-11-22T18:59:33Z,2013-12-01T05:39:12Z,"@SChamberlain Thought I might tap some of your `plyr`/`reshape2` awesomeness here:  

`get_character_list` extracts a list of data.frames.  Each data frame has taxon names as the rownames and character traits as colnames, and may have one or more columns depending on how may traits are in the dataset.  The list has multiple data frames if either they correspond to different sets of taxa, or if they are different kinds of traits (continuous vs discrete).  For example:

```coffee
f <- system.file(""examples"", ""comp_analysis.xml"", package=""RNeXML"")
nex <- read.nexml(f)
char_list <- get_characters_list(nex)
```
returns a list of length 2, with a data frame for continuous trait, and a data.frame for a discrete trait (factor).  

```coffee
> char_list
$cs15
         log snout-vent length
taxon_8             -3.2777799
taxon_9              2.0959433
taxon_10             3.1373971
taxon_1              4.7532824
taxon_2             -2.7624146
taxon_3              2.1049413
taxon_4             -4.9504770
taxon_5              1.2714718
taxon_6              6.2593966
taxon_7              0.9099634

$cs31
         reef-dwelling
taxon_8              0
taxon_9              1
taxon_10             0
taxon_1              1
taxon_2              0
taxon_3              0
taxon_4              0
taxon_5              1
taxon_6              1
taxon_7              1
````

How best to merge these into a single data.frame: 

- [ ] in the general case of N list entries, and without assuming the rownames are in the same order?  

(If the rownames are in the same order, we can do `do.call(cbind, char_list)`.)

- [ ] The rownames could correspond to different taxa values entirely.  How then would we bind them into a single data.frame, such that each unique taxa gets a new row (and perhaps any taxon found in both lists would be combined?)    

I tried hacking this with `ldply`, see https://github.com/ropensci/RNeXML/blob/2f07e2f91e0e9bf08005fe2e220aeafff89e1c16/R/characters.R#L38 but that doesn't collapse the rows when the columns match, and has that ugly for loop too.  

Thanks!
",closed,10,Better merging of character data frames
38,23103745,cboettig,2013-11-21T22:44:59Z,2014-03-25T22:29:49Z,"In reading nexml to phylo objects, we take the liberty of converting tip node otu ids (the `otu` attribute on the nodes) to the taxonomic labels (the `label` attribute on the `otu` node with the matching id).  

This runs the risk of assuming the `otu` has a label attribute.  If it doesn't, we use the id instead.  (I believe ""label"" is always an optional attribute while ""id"" is always required when present -- at least for otu elements?)

It's unclear just how far to go with this logic, particularly given that labels are optional.  For instance, in extracting the character matrix, it makes sense to replace otu id numbers (used as row names) for the actual species names (`label` on the matching `otu` node).  

Likewise, I've applied this logic for characters.  Characters end up as columns in the character matrix. When we first do the extraction, columns are named by the character id values (just as rows are label by otu ids to begin with).  It seems to make sense to convert these to `label` provided in the matching `char` element (in `format`), if available.  Does that make sense?  Or should we be doing a different mapping?  

Lastly, we can apply this logic to states.  States are the values/cells of the matrix.  For continuous characters, it seems there is no `states` element in the `format`, and the numeric values already what we want.  But for discrete states, perhaps we should be replacing the ids (e.g. `s1`, `s2` in your [example]()) for the `symbol` attributes in the `state` elements?  Or maybe not?  


Automating these mappings make sense to match the matrix users expect to get out.  While the id data is still available in the S4 object (and in the parsed XML of course), not sure if we should be discarding the ids in this extraction process or not.  

",closed,4,(When to) substitute labels for ids? (character matrices)
37,23103729,cboettig,2013-11-21T22:44:42Z,2013-12-01T05:39:12Z,"
If we extract a list of character matrices for the same OTU set, it might make sense to combine them into the same `data.frame` (would have to be a `data.frame` and not a matrix, since some columns might be continuous traits and some might be discrete traits). Currently, extracting the character matrix from a file like comp_analysis.xml returns a list with 2 data frames, one of the continuous traits and 1 of the discrete traits.  While this maps cleanly to the nexml, it feels a bit cumbersome on the R end.  @rvosa how would you feel about collapsing these into a single data.frame whenever the `characters` blocks reference the same `otus` block?  

Likewise we have the reverse issue, where a user may have a data.frame with both continuous and discrete characters for the same set of taxa. We would have to break this into two separate characters nodes in serializing to nexml, right?  

Lastly is the same issue we had with multiple `trees` blocks.  A call to `characters(nexml)` will return a list of data.frames (or matrices), usually of length 1 unless their are multiple otus blocks.  Seems sure to be annoying to get a length 1 list when a user might rightfully expect a data.frame or a matrix.  

(I'm leaning to returning a data.frame rather than a matrix to represent the character matrix, as this seems most consistent with the phylogenetics R use, though many functions, like `geiger::fitContinuous` take either structure.)
",closed,2,Extraction and writing of mixed-type character data frames
36,22951229,rvosa,2013-11-19T21:35:59Z,2014-03-25T22:29:58Z,"This file contains a simulated Yule tree, on which I simulated a continuous and a categorical (0/1) character. The idea being that a well-functioning parser would be able to link up the character states with the tree tips (by way of the OTUs) in order to do, say, a comparative analysis.",closed,2,example character data
35,22933959,cboettig,2013-11-19T18:13:46Z,2013-11-29T23:30:49Z,"Necessary so that extracted RDF nodes still refer to the appropriate point in the DOM.  Currently we are not writing this, e.g. https://github.com/ropensci/RNeXML/blob/c04435b8a9759fdd3e21aa2527a7f454b3a166d7/inst/examples/ncbii.xml

Maybe we should just include an `about` attribute whenever we write an `id` attribute?  Alternatively we have to check if an `about` attribute is present whenever we add a `meta` annotation to a node.  ",closed,0,Include `about` property to any node containing metadata annotation
34,22669143,cboettig,2013-11-14T15:23:51Z,2014-07-18T18:25:25Z,"@rvosa Is the validator tool on the nexml website, http://www.nexml.org/nexml/phylows/validator, doing more checks than the standard XML schema validation?  If so, perhaps we could wrap this as an R function.

i.e. this is true of the EML validator, http://knb.ecoinformatics.org/emlparser/,  which checks that any ""references"" node matches some corresponding ""id"", etc.  For that reason we wrapped the validator in R using RHTMLForms, though a programmatic interface to the validator with structured output would be preferable.  

On the other hand, if it's just validating against the NeXML schema we can do that internally with R XML tools.  ",closed,1,online validator tests?
33,22549465,rvosa,2013-11-12T20:53:30Z,2014-03-24T16:37:36Z,"Hi guys,

I am quite keen to write a little blog post on http://biophylo.blogspot.com about your work. Would that be OK? Do you feel comfortable exposing this to my vast, vast readership?

Rutger",open,6,blog post?
32,22375007,sckott,2013-11-09T01:26:14Z,2013-11-18T17:59:43Z,... instead of a file using asText arg,closed,0,added ... to xmlParse inside nexml_read to allow passing in a xml object...
31,21621388,cboettig,2013-10-25T23:01:18Z,2013-12-01T05:33:22Z,"We can read in multiPhylo, but don't convert multiPhylo to single nexml:

```coffee
f <- system.file(""examples"", ""trees.xml"", package=""RNeXML"")
trees <- read.nexml(f, ""phylo"") # reads in multiPhylo of 2 trees
write.nexml(trees) # errors
```",closed,1,write.nexml methods for multiPhylo objects
30,21621048,cboettig,2013-10-25T22:52:07Z,2013-11-18T17:58:24Z,"As documented in #15, we should probably only provide a warning and just drop the trees that cannot parse rather than failing to convert the whole collection.  

This happens, for instance, when some of the trees contain only metadata (no nodes or edges).  ",closed,3,Don't error if we cannot convert only some <tree> elements in a list of <trees> to a multiPhylo
29,21563934,cboettig,2013-10-25T01:32:00Z,2013-11-22T01:20:06Z,"Some trees (e.g. Treebase ""S10327.xml"", ""S10334.xml"", ...) have branch lengths defined for only some edges, leading to the errors seen in #15.  RNeXML should simply write these as NAs in converting to `phylo` type.  Currently generates an error.  ",closed,0,ape conversion should handle case of some missing branch lengths
28,21428458,cboettig,2013-10-23T01:19:32Z,2013-11-13T05:07:37Z,rooted trees can become unrooted in converting from ape to nexml and back.  make sure to handle this more carefully!,closed,4,rooted vs unrooted trees
27,21428409,cboettig,2013-10-23T01:18:12Z,2013-11-13T04:09:31Z,"nexml can contain a single `<tree>` node inside the `<trees>` node, multiple `<tree>` nodes in a single `<trees>` node, or even multiple `<trees>` nodes.  The first two cases map naturally onto a ""phylo"" object and a ""multiPhylo"" object, defined as classes in `ape`.  In order to preserve the associations, we map the third case (multiple `<trees>` nodes) to a list of multiPhylo objects, which isn't something immediately reconizable as a phylogenetic tree class....

Consequently, we make this mapping automatically when asked to coerce a `nexml` file into a `phylo`, even though this means technically not returning the requested class (ask for `phylo` and get `multiPhylo`).  We should probably handle that differently.  

For instance, this current creates a problem when coercing a `nexml` file with multiple `<trees>` nodes into a `nexmlTree` class (because this includes a conversion to `phylo`.  Because `nexmlTree` is the defaul read-in format now, this can cause reading in of such nexml files to fail.  


Obviously it would be nice for a user to convert nexml to the ape classes without having to know how many trees are in the nexml file. Need to figure out the best way to do this.  ",closed,8,"nexmlTree class when as(obj, ""phylo"") is a list"
26,21177709,cboettig,2013-10-17T19:21:16Z,2014-03-25T22:29:58Z,"Thanks everyone for suggesting various ontologies we can use to start making our R-generated nexml more expressive (partly for my own record, I've compiled a list of those suggested in the issues tracker and replies to my nexml-discuss query below).  However, lacking experience in this area, I haven't been very successful at finding the terms I need in these.  Often I don't know where to start looking, and clearly not all of these are populated.  

For starters, it would be good to have a list of ontologies most commonly used in nexml files, as it would make sense to parse these for R users in cases where their interpretation might not be obvious.  I've started with those used by TreeBase (dc, prism, etc), e.g. #25. 

Still looking for lots of particular terms, e.g. the open check boxes from issue #21 .  

Any suggestions on how to go about discovering a term that I might need?  

For example, I can try to skim something like: http://cdao.cvs.sourceforge.net/viewvc/cdao/cdao/OWL/cdao.owl?revision=1.34 for a useful term.  e.g., it looks like I might declare the tree to be time calibrated with the term: http://www.evolutionaryontology.org/cdao/1.0/cdao.owl#TimeCalibratedLengthType, but I'm not sure quite how to do that.  adding a meta element to every edge element stating the same thing doesn't seem ideal... And scanning the owl file by hand for a term doesn't seem ideal either...

--------------------

### Ontologies mentioned so far: 

Ones we include by default (e.g. from TreeBase), which I think I mostly understand pretty well (except for cdao)

    ""nex""   = ""http://www.nexml.org/2009"",
    ""xsi""   = ""http://www.w3.org/2001/XMLSchema-instance"",
    ""xml""   = ""http://www.w3.org/XML/1998/namespace"",
    ""cdao""  = ""http://www.evolutionaryontology.org/cdao/1.0/cdao.owl#"",
    ""xsd""   = ""http://www.w3.org/2001/XMLSchema#"",
    ""dc""    = ""http://purl.org/dc/elements/1.1/"",
    ""dcterms"" = ""http://purl.org/dc/terms/"",
    ""prism"" = ""http://prismstandard.org/namespaces/1.2/basic/"",
    ""cc""    = ""http://creativecommons.org/ns#"",


Additional ones recently mentioned, which I don't have a good grasp for exactly what kind of terms they provide or how to characterize their intersection...

- https://github.com/phylotastic/ontologies

which also points to:
- http://sourceforge.net/projects/cdao/
- https://github.com/miapa/miapa/tree/master/examples
- https://github.com/phylotastic/ontologies/tree/master/tnrs

Darwin core, 

Karen suggests: http://opentree.wikispaces.com/NexSON
Rutger mentioned: http://edamontology.org/EDAM.owl

(will continue to update this as my running list)",closed,4,Navigating ontologies
25,21176707,cboettig,2013-10-17T19:05:16Z,2014-07-17T20:59:33Z,"In addition to adding useful metadata, it would be helpful to be aware of the ontologies most often used in existing NeXML, such that we can attempt to parse and serve this data to the R user in native R formats without assuming knowledge of the database. Doing so is sometimes challenging.

For instance, we might want to extract citation information, author, title, etc, and wrap it up as an R `bibentry` object, which existing R tools can then generate a bibtex file for, or format in various ways (such as text or html).  Unfortunately, this harder as a parsing activity then it is to serialize an R bibentry into NeXML, since we don't have a way to identify which `dc:creator`s are authors of which other cited resources or just creators of the nexml file.  (For instance, consider how we might annotate the `bird.orders` data set in ape -- the data is from Sibley, but compiled into ape from Paradis and written into nexml by us).  

Currently, the `get_citation` function sidesteps this by just returning the content of dcterms:bibliographicCitation content, since this data isn't otherwise hierarchical (though it could be).  
",open,0,Parsing citation information
24,21038893,cboettig,2013-10-15T19:33:00Z,2014-06-20T22:35:37Z,"Goal 2 from Kseniia's list, mentioned in https://github.com/ropensci/RNeXML/issues/21#issuecomment-25735531 

Will be a good example for the manuscript, once gov't shutdown ends and the taxize servers are back up...",closed,28,add TSNs from species names using taxize
23,20631989,cboettig,2013-10-07T19:04:05Z,2014-10-01T03:10:14Z,"Can a `<meta>` element have child `meta` elements?  Do we have support for `typeof` and `resource`?  

For example, one might want to declare a citation of a paper together with the data set in some really verbose SPAR RDFa as:

```html
<li prefix=""
        fabio: http://purl.oeg/spar/fabio/
        datacite: http://purl.org/spar/datacite/
        dcterms: http://purl.org/dc/terms/
        foaf: http://xmlns.com/foaf/0.1/
        prism: http://prismstandard.org/namespaces/basic/2.0/
        frbr: http://purl.org/vocab/frbr/core#
        ex: http:///www.carlboettiger.info/example/"" 
    about=""ex:work-early-warning-signals"" typeof=""fabio:ResearchArticle"">
    <span rel=""dcterms:creator"">
        <span about=""http://www.carlboettiger.info#me"" typeof=""foaf:Person"">
            <span property=""foaf:givenName"">Carl</span> 
            <span property=""foaf:familyName"">Boettiger</span>
        </span>, 
        <span about=""http://two.ucdavis.edu/~me"" typeof=""foaf:Person"">
            <span property=""foaf:givenName"">Alan</span>
            <span property=""foaf:familyName"">Hastings</span>
        </span>
    </span>
    <span rel=""frbr:realization"" resource=""ex:expr-early-warning-signals""  typeof=""fabio:JournalArticle"">
        (<span property=""fabio:hasPublicationYear"">2012</span>).
        <span property=""dcterms:title"" rel=""frbr:partOf"" resource=""ex:RSB-279-1748"">Early Warning Signals and the Prosecutor's Fallacy</span> 
    </span>
    <span about=""ex:RSB-279"" typeof=""fabio:JournalVolume"" 
        property=""prism:volume"" rel=""frbr:partOf"" resource=""ex:RSB"">279</span>
    (<span about=""ex:RSB-279-1748"" typeof=""fabio:JournalIssue"" 
        property=""prism:issueIdentifier"" rel=""frbr:partOf"" resource=""ex:RSB-279"">1748</span>) 
    <span about=""ex:man-early-warning-signals"" typeof=""fabio:PrintObject"">
        <span property=""prism:startingPage"">4734</span>-
        <span property=""prism:endingPage"">4739</span>
    </span>. 
    <em><span about=""ex:RSB"" typeof=""fabio:Journal"" property=""dcterms:title"">Proceedings of the Royal Society B</span> </em>
    <a href=""http://dx.doi.org/10.1098/rspb.2012.2085"" typeof=""fabio:WebPage"">
        <span rel=""frbr:embodimentOf"">
            <span about=""ex:expr-doi-redirect-metadata"" 
                typeof=""fabio:MetadataDocument"" rel=""frbr:realizationOf"">
                    <span about=""ex:work-doi-redirect-metadata"" 
                        type=""fabio:MetadataEntity"" rel=""frbr:subject"" 
                        resource=""ex:work-early-warning-signals"">doi:</span>
                    <span about=""ex:expr-early-warning-signals"" property=""prism:doi"">10.1098/rspb.2012.2085</span>
            </span>
        </span>
    </a>
    (<a href=""http://dx.doi.org/10.5061/dryad.2k462"" typeof=""fabio:Manifestation"">
        <span rel=""frbr:embodimentOf"">
            <span about=""ex:expr-data"" 
                typeof=""fabio:DataFile"" rel=""frbr:realizationOf"">
                    <span about=""ex:work-data"" 
                        type=""fabio:Dataset"" rel=""datacite:hasDescription"" 
                        resource=""ex:expr-early-warning-signals"">dryad doi:10.5061/dryad.2k462</span>
            </span>
        </span>
    </a>)
</li>
```

",closed,37,hierarchical metadata?
22,19164994,cboettig,2013-09-08T18:42:38Z,2013-11-18T17:59:16Z,"Now that we can do the basics (substantial testing #15 aside, ) it might be good to reach out to r-sig-phylo and the nexml-discuss mailing lists for input, critique and feature requests?  What exactly do we want to write that would be concise and specific enough to perhaps get some reply?  Do we need any prequel about the motivation for the package (particularly about nexml to the R list?)  Should that just appear in the package README?",closed,3,Reach out to R and NeXML lists
21,19164668,cboettig,2013-09-08T18:16:12Z,2014-06-16T20:21:30Z,"Many R-based tools need ultrametric / time-calibrated phylogenies.  R also provides several tools to do this.  A good use case for metadata reading and writing might be to work out what metadata we might add if we: read in an uncalibrated phylogeny, use a given function (and parameter choice potentially) in a given software to perform the time-calibration, and then write out the time-calibrated tree. For instance, we might annotate:

- [ ] statement that tree is ultrametric
- [ ] software used to calibrate the tree
- [ ] function call used (with parameters, maybe CDATA the r code??)
- [ ] reference to source file on which calibration was based
- [ ] ... what else?",open,4,more metadata use cases
20,19164598,cboettig,2013-09-08T18:12:09Z,2014-07-01T20:06:29Z,"We will want either/both of:

- A function to extract all the metadata nodes from the S4 object and summarize this data neatly (more obvious for top-level metadata, less clear how to present the annotations of individual nodes)

- RDFa based tool for extraction/reasoning on the ontological terms?

Additionally, might allow some automatic calculation of metadata such as the number of trees in a file, number of taxa, names of taxa, etc (e.g. along the lines of the TreeBase metadata) / PhyloWS terms.  Perhaps we should add this summary data in meta nodes or is that asking for trouble?

Really need to enumerate the use-cases for leveraging this metadata (may involve thinking more about additional metadata we want to add).  ",closed,21,Implement metadata extraction/parsing tools
19,19130558,cboettig,2013-09-06T21:54:42Z,2013-10-16T21:13:21Z,"
Crazy idea: when reading into a phylo, should we create a new RNeXML environment, store the full nexml tree in there, and add a new slot to the phylo object storing an unevaluated `get(""<unique_tree_id>"", envir=RNeXML)` that methods could use to access the full NeXML??

This would let us do something like:

```coffee
tr <- nexml_read(""tree.xml"")
metadata(tr)
```

instead of 

```coffee
tr <- nexml_read(""tree.xml"", type=""nexml"")
metadata(tr)
```

That is, reading in as the default (ape) type, and still calling functions that need the full nexml metadata, while also having an ape tree object that can still be passed around to the usual R packages.  

Or maybe that's stupid and asking for trouble, and we should be explicit about what type of object we want.  
",closed,8,Attaching nexml metadata to phylo objects
18,19127011,cboettig,2013-09-06T20:36:41Z,2013-10-15T18:10:35Z,"There's a variety of `meta` elements we might want to attach to the top of most nexml documents we write 

- [x] Creator, with contact information
(Not providing contact info in default configuration due to spam concerns.  Contact information can be added as additional metadata, including things like `foaf:homepage` or `foaf:account` = ""https://github.com/cboettig"")
- [x] Title
- [x] Description
- [x] License declaration (e.g. CC0)
- [x] Timestamp
- [x] Information about where the file is released / published (e.g. Github, Dryad, etc)
- [x] Journal citation information of an associated article

Will give us some good practice writing RDFa style `meta` elements before we tackle more serious annotation. @rvosa @hlapp might you point to a good model NeXML files we can template off of for these?  (e.g. the treebase nexmls are a good example of journal citation info, and a couple others. Not sure if I've seen a license example). Clearly this involves identifying the ontology for most terms here (though dublin core may cover most of it).  

Some of these (license, timestamp) we might consider adding by default(?).  

A good implementation will allow the user to pass R's native objects where relevant (e.g. `person`, `citation`) to be included.  

",closed,11,Implement R support for standard metadata elements
17,19125911,cboettig,2013-09-06T20:14:32Z,2013-11-18T19:10:29Z,,closed,0,Write a knitr readme / vignette showing basic reading and writing
16,19119736,cboettig,2013-09-06T18:08:16Z,2013-11-18T17:58:54Z,"@rvosa @hlapp I'm not really clear what attributes belong to Base. I've stuck `xsi:type` there because it seemed to make sense....

I'm still confused about `set`. I don't see why I'd want to use this; maybe I need a more flushed-out example?

I'm also not exactly sure how I tell if something is ""referenced"" anyway: I realize that `<node otu = ""t1""/>` ""references"" `<otu id=""t1""/>`, so that the otu element must appear first; correct? 

But what is it that makes this a reference? I can think of two possible differing definitions:

- The fact that node has both an attribute matching the name of an element and the attribute has a value matching the attribute of an element of that name? 

- Or is it sufficient just to have any attribute whose value matches the id attribute of another element (e.g. does `<foo bar=""t1""/>` reference the `<otu id =""t1""/>` element?)
",closed,2,Understanding set and referencing
15,18930413,cboettig,2013-09-03T18:35:25Z,2014-03-25T22:29:49Z,"@SChamberlain  Hey Scott, sorry about the bugs this morning.  I think all the tests should be working now.  I think this counts as our first real milestone!


Like you say, they could use a lot of `expect_that` tests still.  It's not necessary to go too crazy with the expect_that tests though, thanks to the validator (xmlSchemaValidate).  This is the really nice thing about the schema-based data structure, it comes with this really rigorous check that we've done things right. 

Checking the schema is valid doesn't check that we have accurately read in a tree, of course.  Rather than the more ""unit"" unit tests of checking each line, we'd probably get some really solid tests just by going back and forth between formats and then seeing if the objects were identical or not; starting both with a bunch of ape trees and with a bunch of NeXML trees (which you can grab from the treebase github repo: https://github.com/rvosa/supertreebase/tree/master/data/treebase )

Of course RNeXML doesn't completely implement all of NeXML (character matrices, networks, and other things still missing), so these are silently dropped when being read in.  There are also a few things the schema validation does not check, like consistent use of ids (see https://github.com/ropensci/RNeXML/issues/8#issuecomment-22867085 )

Post bugs as you hit them, should help us flush out special cases.  A few I can anticipate already (e.g. #9 ) which one of us should get around too..",closed,20,Testing
14,17959623,cboettig,2013-08-12T19:25:38Z,2013-11-27T23:17:46Z,"Need to generate ids for nodes such as `<otus>` and `<trees>`, etc.  Should we use `uuid` for this?  ",closed,11,"All elements need id(?), strategy for generating ids"
13,17956028,cboettig,2013-08-12T18:18:58Z,2013-11-18T17:59:31Z,"Warn or error on special cases (e.g. some valid nexml trees probably cannot be completely valid phylo objects.  For instance, `network` with horizontal transfer events.  ",closed,1,"Tackling ""special cases"""
12,17955842,cboettig,2013-08-12T18:15:43Z,2013-12-01T05:39:12Z,"NeXML, like nexus, can contain a lot of character matrix (e.g. sequence) data.  Current approach, like the `read.nexus` functions, simply ignores this.  

We will want to be able to read and manipulate R objects without having to carry around the weight of the character data.  This can probably be controlled through the `read_nexml` top-level api, e.g. `nexml_read(""file.nexml"", type=""phylo"")` vs `type = character_matrix`.  

We need to figure out what R object we want to coerce character matrices to, if any.  Not familiar with many R functions that use sequence data, so learning what functions exist and what formats they expect would be a first step.  Meanwhile, we will presumably just read it into our S4 object equivalent.  Methods can always be added later.  

Comparative methods, which dominate the phylogenetics R tools, have the notion of character data as well, but usually as phenotypic data that is not meant to be informative of the tree inference, has no notion of alignment, etc.  It would seem strange to represent this data in the NeXML in the same way.  @rvosa What is the best way to go about this?  Presumably this is related to the phenoscape project, but I haven't looked at that.  Advice / strategies welcome.  ",closed,8,character matrix strategies
11,17955534,cboettig,2013-08-12T18:09:21Z,2014-07-31T18:19:14Z,"We'll want to support coercion into phylobase trees (phylo4, etc).  

On one hand, since these trees are S4 objects, are more carefully defined than ape::phylo trees, richer, and more extensible, we could build our entire strategy around going from `RNeXML::nexml => phylobase::phylo4 => ape::phylo`.  

On the other hand, speaking to ben bolker at ESA, phylobase uptake is low (though does have reverse dependencies), and more troublingly, NCL (Nexus Class Library) is kinda a weak point that has made maintenance challenging.  

I suspect the ideal solution given this issue is to support direct coercion into ape::phylo, and include phylobase as ""suggests"" only, with separate methods to go from `nexml => ape::phylo` and `nexml => phylobase`.  Package could then be used without installing `phylobase`, which would only be needed for the phylobase methods.  

Obviously we will want to write a phylobase coercion method in any event. Can reuse many of the same elements, but will also have slots for additional data which could make our life easier (or harder -- in the end it might be better to support adding annotations directly to the RNeXML S4 objects, which map 1:1 to the schema, rather than first figuring out how they map to phylobase objects...)

Thoughts? ",closed,2,phylobase strategies
10,17955211,cboettig,2013-08-12T18:02:57Z,2013-09-06T20:51:39Z,"Think we need an `importFrom(ape, ""phylo"")` etc in the NAMESPACE not quite sure if that's correct and what the roxygen would look like.  

Resolution of this issue should deal with the warnings on `document` and `install` (on clean R session without `ape` already loaded) about these classes not being defined.

Coercion between S4 and S3 classes feels a bit funny, but it seems such methods are provided in phylobase...  ",closed,1,"import ""phylo"" and ""multiPhylo"" classes"
9,17954683,cboettig,2013-08-12T17:53:08Z,2013-09-06T20:51:32Z,"- [ ] Pretty sure current `setAs(""phylo"", ""tree"")` will be unhappy if `phylo` doesn't have edge.length defined.  Fix and write unit test showing this works.  

- [ ] Likewise, write unit test for tree to phylo when we don't have length data in the nexml.  

- [ ] nexml probably supports missing data better, e.g. lengths on only some edges.  RNeXML needs to do something intelligent (e.g. NAs and warning?) on coercing this case to phylo (with unit test).  

",closed,0,phylo to tree methods handling when phylo doesn't have edge lengths
8,17950668,cboettig,2013-08-12T16:32:25Z,2013-09-06T20:51:32Z,"Validator says we need `meta` element or `otus` element before a `trees` element.  (see `inst/tests/test_serializing.R`).  

When coercing from `ape::phylo` to S4 `tree`, we put `tip.label` (e.g. taxanomic names) in the `otu` attribute of the node labels.  This can be extracted to generate the otus element (possibly just a coercion from `ListOfnode` class into `otus`, unless defining such a method is convoluted...).     

Need to think about user workflow in (optionally/automatically) providing additional annotation for these nodes (e.g. could query the names against `taxize` and add this data to the `otus` element.  

Need also to think about strategy for post-hoc extending this annotation. 

@rvosa It appears that annotation of species information could occur at the node level in the tree or in the `otus` level.  Presumably most generic annotation about the taxanomic unit should be at the `otus` level?  
",closed,3,Generate otus element when coercing from tree to nexml
7,17950644,sckott,2013-08-12T16:32:04Z,2013-09-06T20:51:32Z,"In `setAs(""tree"", ""nexml"", function(from) ... )` (coercing tree to nexml), we need to generate the `<otus>` node still.",closed,1,Generate otus node
6,17950520,cboettig,2013-08-12T16:30:04Z,2013-09-06T20:51:32Z,"Does the current conversion to ape lose element id information?  Can we program around this while still maintaining valid phylo objects?

E.g. once I have coerced a nexml file to a phylo tree and identified a node of interest in the phylo object, can I unambiguously query for metadata on that node id, or the corresponding otu?  

Related: trying to wrap my head around the use of having both `label` and `id` attributes on most elements...",closed,4,Does the current conversion to ape lose element id information?
5,17949869,sckott,2013-08-12T16:18:42Z,2013-11-18T17:59:16Z,"Lots of my class definitions are missing slots for optional attributes. This doesn't break anything, we simply don't read that information out of the XML and into the S4 when we don't find a slot for it (we = `xmlToS4` method). Ideally we'll want to support the full schema, so all classes should be expanded. (The cool thing about the S4 approach is this is relatively easy to do without breaking anything).",closed,1,Flushing out the class slots
4,17949836,sckott,2013-08-12T16:18:09Z,2014-03-25T22:29:48Z,"Lots of classes / XML node types not yet written. Would be good to write these for some practice (@rvosa might be able to suggest best which ones to prioritize? Or just look at the sample nexml files in `inst/examples/` to see any nodes we haven't defined ...) In principle, once Duncan has the `XMLSchema` package robustly working, we can generate these classes, along with coercion methods to write them back to XML etc, automatically, which will save a lot of effort. But since it's quite mechanical writing them by hand doesn't take very long.",closed,1,Flushing out the remaining classes
3,17949772,sckott,2013-08-12T16:17:10Z,2013-11-18T18:00:04Z,,closed,4,Aliases write.nexml and read.nexml aren't being registered
2,17949733,sckott,2013-08-12T16:16:44Z,2014-03-25T22:29:48Z,,closed,1,Write roxygen documentation for all functions
1,17925756,sckott,2013-08-12T06:24:20Z,2013-11-18T17:59:16Z,@cboettig Is there anything I can help with?  ,closed,9,Where can I help?
