<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content=""/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




	<link rel="stylesheet" href="http://www.carlboettiger.info/assets/css/bootstrap.min.css" type="text/css"/>
	<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
	<link rel="stylesheet" href="http://www.carlboettiger.info/assets/css/academicons.css" />
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="http://www.carlboettiger.info/blog.xml" />
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  class="active" >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="http://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Lab Notebook</h1>
        <h2>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h2>
      </header>

      <div class="row postpreview">
  <div class="col-md-11 col-md-offset-1">
    <div class="row">
			<h4> <a href="/2015/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/06/18/RAM-explore.html">Further exploration of RAM Legacy Stock Assessment data</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 18 Jun 2015</p>

<article>
<div class="excerpt">
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>({
<span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;RPostgreSQL&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;devtools&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)
})

## Perform this in data_raw to keep package dependencies minimal
mydb &lt;-<span class="st"> </span><span class="kw">src_postgres</span>(<span class="dt">dbname =</span> <span class="st">&quot;srdb&quot;</span>, 
                     <span class="dt">host=</span><span class="st">&quot;nautilus-vm.mathstat.dal.ca&quot;</span>, 
                     <span class="dt">user =</span> <span class="st">&quot;srdbuser&quot;</span>, 
                     <span class="dt">password =</span>  <span class="st">&quot;srd6us3r!&quot;</span>, 
                     <span class="dt">port =</span> <span class="dv">5432</span>)

timeseries &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries&quot;</span>)))
values &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries_values_view&quot;</span>)))
units &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries_units_view&quot;</span>)))
assessment &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessment&quot;</span>)))
area &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.area&quot;</span>)))
stock &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.stock&quot;</span>)))
method &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessmethod&quot;</span>)))
assessor &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessor&quot;</span>)))
management  &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.management&quot;</span>)))
taxonomy &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.taxonomy&quot;</span>)))
lmerefs &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.lmerefs&quot;</span>)))
lmestock &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.lmetostocks&quot;</span>)))
biometrics  &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.biometrics&quot;</span>)))
bioparams &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.bioparams&quot;</span>)))
tsmetrics &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.tsmetrics&quot;</span>)))</code></pre>
<h2 id="north-atlantic-cod-data">North Atlantic Cod data</h2>
<p>Select North Atlantic Cod, <em>Gadus morhua</em>:</p>
<pre class="sourceCode r"><code class="sourceCode r">cod_ids &lt;-
<span class="st">  </span>assessment %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(stock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(scientificname==<span class="st">&quot;Gadus morhua&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(assessid) %&gt;%
<span class="st">  </span><span class="kw">unlist</span>() %&gt;%<span class="st"> </span><span class="kw">unname</span>() <span class="co"># we need a char string, not a data.frame</span></code></pre>
<p>(Note we could have selected on the <code>tsn==164712</code> to be less ambiguous but also less semantic, or on <code>commonname==&quot;Atlantic cod&quot;</code> to be more reader friendly but even more ambiguous. Fortunately the common and scientific names are well aligned with the <code>tsn</code> ids in this case and we get the same set of 22 stock assessments.)</p>
<p>Before we can combine across these, we must verify that each assessment measures the quantities of interest using the same units, or otherwise correct those that do not:</p>
<pre class="sourceCode r"><code class="sourceCode r">units %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span><span class="kw">select</span>(assessid, catch_landings_unit) %&gt;%<span class="st"> </span><span class="kw">group_by</span>(catch_landings_unit) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="kw">length</span>(catch_landings_unit))</code></pre>
<pre><code>Source: local data frame [1 x 2]

  catch_landings_unit length(catch_landings_unit)
1                  MT                          21</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">units %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span><span class="kw">select</span>(assessid, total_unit) %&gt;%<span class="st"> </span><span class="kw">group_by</span>(total_unit) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="kw">length</span>(total_unit))</code></pre>
<pre><code>Source: local data frame [3 x 2]

  total_unit length(total_unit)
1        E03                  1
2         MT                 18
3         NA                  2</code></pre>
<p>All catches are in metric tons, so no concern there.</p>
<p>Landing data we can plot immediately:</p>
<pre class="sourceCode r"><code class="sourceCode r">values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(tsyear) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">catch =</span> <span class="kw">sum</span>(catch_landings, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)) %&gt;%<span class="st"> </span>## all units are metric tons
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, catch)) +<span class="st"> </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Catch/Landings (MT)&quot;</span>) +<span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Year&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-4-1.png" />
</figure>
<p>Note that missing data is removed, such that any assessment without catch data is treated as zero catch. This could be the case (maybe not all assessments correspond to unique catch zones.) We also assume catch reported in one assessment is not also reported in a different assement (e.g. no double-counting). Lastly, we must bear in mind that this is catch/landings data, which may include bycatch, underreporting, etc.</p>
<hr />
<h2 id="handling-unit-conversions">Handling unit conversions</h2>
<p>The units for <code>total</code> are more problematic. The <code>NA</code> simply indicates stocks that do not have the an estimate for <code>total</code>, but we also see one assessment has totals in <code>E03</code> (thousands) instead of metric tons.</p>
<hr />
<p><em>Sidebar</em> how do we know for sure that <code>E03</code> is abundance counts in thousands of fish?</p>
<p>The database does not provide metadata for these unit definitions directly. the <code>values</code> data and its associated <code>units</code> metadata are actually derived tables from the raw <code>timeseries</code> table and the associated <code>tsmetrics</code> unit metadata, so we would have to dive in there to confirm this interpretation of <code>E03</code> in this case.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># tidy up the tsmetrics table:</span>
unit_defs &lt;-<span class="st"> </span>tsmetrics %&gt;%<span class="st"> </span><span class="kw">rename</span>(<span class="dt">tsid =</span> tsunique) %&gt;%<span class="st"> </span><span class="kw">select</span>(tsid, tslong, tsunitslong) 

<span class="co"># Find the assessid of the cod stock assessment that measures total in units of E03</span>
who &lt;-<span class="st"> </span>units %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span><span class="kw">select</span>(assessid, total_unit) %&gt;%<span class="st"> </span><span class="kw">filter</span>(total_unit==<span class="st">&quot;E03&quot;</span>)

<span class="co"># Find that assessid in the timeseries table, where units are written in different notation</span>
ts_who &lt;-<span class="st"> </span>timeseries %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>who$assessid) %&gt;%<span class="st"> </span><span class="kw">select</span>(assessid, tsid) %&gt;%<span class="st">  </span><span class="kw">distinct</span>(tsid)

<span class="co"># Join the tables to see the definitions</span>
<span class="kw">left_join</span>(ts_who, unit_defs)</code></pre>
<pre><code>Source: local data frame [5 x 4]

                      assessid   tsid
1 NAFO-SC-COD3M-1959-2008-BAUM SSB-MT
2 NAFO-SC-COD3M-1959-2008-BAUM TN-E03
3 NAFO-SC-COD3M-1959-2008-BAUM  R-E03
4 NAFO-SC-COD3M-1959-2008-BAUM  F-1/T
5 NAFO-SC-COD3M-1959-2008-BAUM  TC-MT
Variables not shown: tslong (chr), tsunitslong (chr)</code></pre>
<p>and we can confirm <code>E03</code> is in this case <code>TN-E03</code> (total number, in thousands).</p>
<hr />
<p>Converting this to metric tons will require an average weight for cod. FishBase gives us a maximum weight (in grams):</p>
<pre class="sourceCode r"><code class="sourceCode r">rfishbase::<span class="kw">species</span>(<span class="st">&quot;Gadus morhua&quot;</span>, <span class="dt">fields=</span><span class="st">&quot;Weight&quot;</span>)</code></pre>
<pre><code>Error in loadNamespace(name): there is no package called &#39;rfishbase&#39;</code></pre>
<p>Wikipedia says the average is 5-12 kilograms, so let’s take 8.5 Kg for sake of argument. Clearly a more programmatic and more accurate solution is needed here.</p>
<p><em>Sidenote</em> the database has some very limited data on biometrics by assessment, including some assessments that record a maximum (but not an average) weight (sometimes pulled from FishBase anyway). Even pooling across all Atlantic Cod assessments we can’t find even a maximum weight.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Find the unit code for max weight</span>
biometrics %&gt;%<span class="st"> </span><span class="kw">filter</span>(biolong ==<span class="st"> &quot;Maximum weight&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">select</span>(biounique) %&gt;%<span class="st"> </span><span class="kw">unlist</span>() %&gt;%<span class="st"> </span><span class="kw">unname</span>() -&gt;<span class="st"> </span>max_weight
<span class="co"># show the unit code:</span>
max_weight</code></pre>
<pre><code>[1] &quot;MAX-WGT-g&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Look up all max weight values for illustration: (not filtering on cod_ids since there are no hits)</span>
bioparams %&gt;%<span class="st"> </span><span class="kw">filter</span>(bioid %in%<span class="st"> </span>max_weight)</code></pre>
<pre><code>Source: local data frame [17 x 5]

                                  assessid     bioid  biovalue
1      INIDEP-ARGANCHOSARG-1992-2007-Parma MAX-WGT-g        51
2      INIDEP-ARGANCHONARG-1989-2007-Parma MAX-WGT-g        48
3       INIDEP-ARGHAKESARG-1985-2008-Parma MAX-WGT-g   5300.00
4       INIDEP-ARGHAKENARG-1985-2007-Parma MAX-WGT-g   5900.00
5  INIDEP-PATGRENADIERSARG-1983-2006-Parma MAX-WGT-g      2940
6            ICCAT-ALBANATL-1929-2005-WORM MAX-WGT-g     60000
7         ICCAT-ATBTUNAEATL-1969-2007-WORM MAX-WGT-g    684000
8         ICCAT-ATBTUNAWATL-1969-2007-WORM MAX-WGT-g    684000
9   AFSC-SABLEFEBSAIGA-1956-2008-MELNYCHUK MAX-WGT-g      6200
10           IPHC-PHALNPAC-1988-2009-Parma MAX-WGT-g available
11     AFSC-REYEROCKBSAI-1974-2009-STANTON MAX-WGT-g      2047
12            NEFSC-ATHAL5YZ-1800-2007-COL MAX-WGT-g    337000
13     NEFSC-SCUPNWATLC-1960-2007-TERCEIRO MAX-WGT-g      3000
14     NEFSC-MONKGOMNGB-1964-2006-RICHARDS MAX-WGT-g    337000
15      NEFSC-SURFMATLC-1965-2008-JACOBSON MAX-WGT-g      600+
16   CSERG-ANCHOVYKILKACS-1991-2007-JENSEN MAX-WGT-g      18.4
17        ASMFC-PANDALGOM-1960-2009-IDOINE MAX-WGT-g        23
Variables not shown: bioyear (chr), bionotes (chr)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">e03_to_MT &lt;-<span class="st"> </span><span class="fl">7.5</span> *<span class="st"> </span><span class="fl">1e-3</span>

tmpA &lt;-<span class="st"> </span>
<span class="st">  </span>values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>who$assessid) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">total_mt =</span> total *<span class="st"> </span>e03_to_MT)

everyone_else &lt;-<span class="st"> </span>cod_ids[!(cod_ids %in%<span class="st"> </span>who$assessid)]
tmpB &lt;-
<span class="st">  </span>values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>everyone_else) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">total_mt =</span> total)

std_values &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(tmpA,tmpB)</code></pre>
<p>(Not sure if there is a more consise way to change the values in a given column for a subset of the rows). Well, perhaps it would be simpler to treat non-standard units as missing data, but at least this illustrates a mechanism for handling the conversion.</p>
<pre class="sourceCode r"><code class="sourceCode r">biomass &lt;-
<span class="st">  </span>std_values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(tsyear) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">biomass =</span> <span class="kw">sum</span>(total_mt, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)) %&gt;%<span class="st"> </span>## WARNING -- should check units!
<span class="st">  </span><span class="kw">filter</span>(biomass &gt;<span class="st"> </span><span class="dv">0</span>) 

biomass_dropped &lt;-
<span class="st">  </span>values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>everyone_else) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(tsyear) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">biomass =</span> <span class="kw">sum</span>(total, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)) %&gt;%<span class="st"> </span>## WARNING -- should check units!
<span class="st">  </span><span class="kw">filter</span>(biomass &gt;<span class="st"> </span><span class="dv">0</span>) 

biomass_wrong &lt;-
<span class="st">  </span>values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(tsyear) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">biomass =</span> <span class="kw">sum</span>(total, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)) %&gt;%<span class="st"> </span>## WARNING -- should check units!
<span class="st">  </span><span class="kw">filter</span>(biomass &gt;<span class="st"> </span><span class="dv">0</span>) 

<span class="kw">ggplot</span>(biomass, <span class="kw">aes</span>(tsyear, biomass)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span>biomass_wrong, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span>biomass_dropped, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lty=</span><span class="dv">2</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Biomass (MT)&quot;</span>) +<span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Year&quot;</span>)
  
<span class="co"># they may look identical but they aren&#39;t:</span>
<span class="kw">identical</span>(biomass_dropped$biomass, biomass$biomass)</code></pre>
<pre><code>[1] FALSE</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-9-1.png" />
</figure>
<p>In this case, the contribution is negligible (red vs black). Even failing to convert units (blue) makes a hardly visible difference, though in general the difference could have been quite large.</p>
<pre class="sourceCode r"><code class="sourceCode r">values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids, total &gt;<span class="st"> </span><span class="dv">0</span>) %&gt;%
<span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, total, <span class="dt">color=</span>assessid)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>() +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Biomass (MT)&quot;</span>) +<span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Year&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-10-1.png" />
</figure>
<hr />
<h2 id="stock-recruitment-time-series">Stock-recruitment &amp; time-series</h2>
<pre class="sourceCode r"><code class="sourceCode r">values %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids[[<span class="dv">1</span>]]) %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +<span class="st"> </span><span class="kw">geom_point</span>()
values %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid==<span class="st">&quot;AFWG-CODNEAR-1943-2006-MINTO&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +<span class="st"> </span><span class="kw">geom_point</span>()

values %&gt;%
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(r), !<span class="kw">is.na</span>(ssb)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +
<span class="st">    </span><span class="kw">geom_point</span>() +
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)


values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>cod_ids) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(total)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, total)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(tsyear, ssb), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<p><img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-11-1.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-11-2.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-11-3.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-11-4.png" /></p>
<p>Note that the spawning stock biomass, red, can often be significantly less than the total stock (black).</p>
<pre class="sourceCode r"><code class="sourceCode r">herring &lt;-
<span class="st">  </span>assessment %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(stock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(commonname==<span class="st">&quot;Herring&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(assessid) %&gt;%
<span class="st">  </span><span class="kw">unlist</span>() %&gt;%<span class="st"> </span><span class="kw">unname</span>() <span class="co"># we need a char string, not a data.frame</span>

values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>herring) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(r), !<span class="kw">is.na</span>(ssb)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)

values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>herring) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(total)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, total)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(tsyear, ssb), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<p><img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-12-1.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-12-2.png" /></p>
<pre class="sourceCode r"><code class="sourceCode r">anchovy &lt;-
<span class="st">  </span>assessment %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(stock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(commonname==<span class="st">&quot;Anchovy&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(assessid) %&gt;%
<span class="st">  </span><span class="kw">unlist</span>() %&gt;%<span class="st"> </span><span class="kw">unname</span>() <span class="co"># we need a char string, not a data.frame</span>

values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>anchovy) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(r), !<span class="kw">is.na</span>(ssb)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)

values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>anchovy) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(total)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, total)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(tsyear, ssb), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<p><img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-13-1.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-13-2.png" /></p>
<pre class="sourceCode r"><code class="sourceCode r">bluefin &lt;-
<span class="st">  </span>assessment %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(stock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(commonname==<span class="st">&quot;Atlantic bluefin tuna&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(assessid) %&gt;%
<span class="st">  </span><span class="kw">unlist</span>() %&gt;%<span class="st"> </span><span class="kw">unname</span>() <span class="co"># we need a char string, not a data.frame</span>

values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>bluefin) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(r), !<span class="kw">is.na</span>(ssb)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssb, r)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)


values %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid %in%<span class="st"> </span>bluefin) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(total)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, total)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(tsyear, ssb), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">facet_wrap</span>(~assessid, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<p><img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-14-1.png" /> <img src="/2015/assets/figures/posts/2015-06-18-RAM-explore/unnamed-chunk-14-2.png" /></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/06/18/RAM-explore.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/06/16/daniel-gp-example.html">Daniel Gp Example</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 16 Jun 2015</p>

<article>
<div class="excerpt">
<h3 id="setup">Setup</h3>
<pre class="sourceCode r"><code class="sourceCode r">devtools::<span class="kw">install_github</span>(<span class="st">&#39;nimble-dev/nimble/packages/nimble@devel&#39;</span>)
<span class="kw">library</span>(nimble)
<span class="kw">set.seed</span>(<span class="dv">0</span>)</code></pre>
<p>Randomly generate some sinusoidal data</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="dv">100</span>
y &lt;-<span class="st"> </span><span class="kw">sin</span>(x/<span class="dv">5</span>) +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="fl">0.1</span>)
ind &lt;-<span class="st"> </span><span class="kw">sort</span>(<span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">100</span>, <span class="dv">40</span>))</code></pre>
<p>The next three lines are the only inputs required.</p>
<pre class="sourceCode r"><code class="sourceCode r">xObs &lt;-<span class="st"> </span>x[ind]                ## input
yObs &lt;-<span class="st"> </span>y[ind]                ## input
xPred &lt;-<span class="st"> </span><span class="kw">c</span>(x, <span class="dv">101</span>:<span class="dv">120</span>)        ## input</code></pre>
<p>Some initial processing</p>
<pre class="sourceCode r"><code class="sourceCode r">nObs &lt;-<span class="st"> </span><span class="kw">length</span>(xObs)
nPred &lt;-<span class="st"> </span><span class="kw">length</span>(xPred)
f &lt;-<span class="st"> </span>function(xi, xj) (xi-xj)^<span class="dv">2</span>
diffOO &lt;-<span class="st"> </span><span class="kw">outer</span>(xObs,  xObs,  f)
diffPP &lt;-<span class="st"> </span><span class="kw">outer</span>(xPred, xPred, f)
diffPO &lt;-<span class="st"> </span><span class="kw">outer</span>(xPred, xObs,  f)</code></pre>
<h3 id="nimble-function-for-gp-prediction">NIMBLE function for GP prediction</h3>
<p>Here’s the main function for doing the prediction from the GP model.</p>
<p>It takes the MCMC samples as a <em>runtime</em> argument, so this can be iterated with running the MCMC for different numbers of iterations, initial values, or even different datasets!</p>
<pre class="sourceCode r"><code class="sourceCode r">gpPred &lt;-<span class="st"> </span><span class="kw">nimbleFunction</span>(
    <span class="dt">setup =</span> function(model, params) {
        calcNodes &lt;-<span class="st"> </span>model$<span class="kw">getDependencies</span>(params, <span class="dt">determOnly =</span> <span class="ot">TRUE</span>)
        nPred &lt;-<span class="st"> </span><span class="kw">dim</span>(model$SigPP)[<span class="dv">1</span>]
        E &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(nPred, <span class="dv">1</span>))
        C &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="kw">c</span>(nPred, nPred))
    },
    <span class="dt">run =</span> function(<span class="dt">samples =</span> <span class="kw">double</span>(<span class="dv">2</span>)) {
        E &lt;&lt;-<span class="st"> </span>E *<span class="st"> </span><span class="dv">0</span>
        C &lt;&lt;-<span class="st"> </span>C *<span class="st"> </span><span class="dv">0</span>
        nSamples &lt;-<span class="st"> </span><span class="kw">dim</span>(samples)[<span class="dv">1</span>]
        for(i in <span class="dv">1</span>:nSamples) {
            <span class="kw">values</span>(model, params) &lt;&lt;-<span class="st"> </span>samples[i,]
            <span class="kw">calculate</span>(model, calcNodes)
            intermediate &lt;-<span class="st"> </span>model$SigPO %*%<span class="st"> </span><span class="kw">inverse</span>(model$SigOO)
            Etemp &lt;-<span class="st"> </span>intermediate %*%<span class="st"> </span><span class="kw">asCol</span>(model$yObs)
            Ctemp &lt;-<span class="st"> </span>model$SigPP -<span class="st"> </span>intermediate %*%<span class="st"> </span><span class="kw">t</span>(model$SigPO)
            E &lt;&lt;-<span class="st"> </span>E +<span class="st"> </span>Etemp
            C &lt;&lt;-<span class="st"> </span>C +<span class="st"> </span>Ctemp
        }
        E &lt;&lt;-<span class="st"> </span>E /<span class="st"> </span>nSamples
        C &lt;&lt;-<span class="st"> </span>C /<span class="st"> </span>nSamples
    },
    <span class="dt">methods =</span> <span class="kw">list</span>(
        <span class="dt">getE =</span> function() { <span class="kw">returnType</span>(<span class="kw">double</span>(<span class="dv">1</span>)); <span class="kw">return</span>(E[,<span class="dv">1</span>]) },
        <span class="dt">getC =</span> function() { <span class="kw">returnType</span>(<span class="kw">double</span>(<span class="dv">2</span>)); <span class="kw">return</span>(C[, ]) }
    )
)</code></pre>
<h3 id="gp-model">GP model</h3>
<p>GP model defined here. Basically the same as your original, but I renamed some paramters more to my liking =)</p>
<p>This is <em>not</em> as elegant as I had hoped. It still requires repeating (essentially) the same code three times. I discovered some limitations of NIMBLE while trying other approaches.</p>
<p>Bottom line:<br />- This achieves relatively nice simplicity.<br />- There’s an efficiency hit to the MCMC sampling, but it doesn’t seem too bad.<br />- This works.</p>
<pre class="sourceCode r"><code class="sourceCode r">code &lt;-<span class="st"> </span><span class="kw">nimbleCode</span>({
   rho ~<span class="st"> </span><span class="kw">dgamma</span>(<span class="dv">10</span>, <span class="dv">1</span>)
   sigGP ~<span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>, <span class="fl">1e5</span>)
   sigOE ~<span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>, <span class="fl">1e5</span>)
   SigOO[<span class="dv">1</span>:nObs, <span class="dv">1</span>:nObs ] &lt;-<span class="st"> </span>sigGP^<span class="dv">2</span>*<span class="kw">exp</span>(-<span class="dv">1</span>/<span class="dv">2</span>*diffOO[<span class="dv">1</span>:nObs, <span class="dv">1</span>:nObs ]/rho^<span class="dv">2</span>) +<span class="st"> </span>sigOE^<span class="dv">2</span>*IOO[<span class="dv">1</span>:nObs, <span class="dv">1</span>:nObs ]
   SigPP[<span class="dv">1</span>:nPred,<span class="dv">1</span>:nPred] &lt;-<span class="st"> </span>sigGP^<span class="dv">2</span>*<span class="kw">exp</span>(-<span class="dv">1</span>/<span class="dv">2</span>*diffPP[<span class="dv">1</span>:nPred,<span class="dv">1</span>:nPred]/rho^<span class="dv">2</span>) +<span class="st"> </span>sigOE^<span class="dv">2</span>*IPP[<span class="dv">1</span>:nPred,<span class="dv">1</span>:nPred]
   SigPO[<span class="dv">1</span>:nPred,<span class="dv">1</span>:nObs ] &lt;-<span class="st"> </span>sigGP^<span class="dv">2</span>*<span class="kw">exp</span>(-<span class="dv">1</span>/<span class="dv">2</span>*diffPO[<span class="dv">1</span>:nPred,<span class="dv">1</span>:nObs ]/rho^<span class="dv">2</span>)
   yObs[<span class="dv">1</span>:nObs] ~<span class="st"> </span><span class="kw">dmnorm</span>(mu[<span class="dv">1</span>:nObs], <span class="dt">cov =</span> SigOO[<span class="dv">1</span>:nObs,<span class="dv">1</span>:nObs])
})

constants &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">nObs=</span>nObs, <span class="dt">nPred=</span>nPred, <span class="dt">diffOO=</span>diffOO, <span class="dt">diffPP=</span>diffPP, <span class="dt">diffPO=</span>diffPO,
                  <span class="dt">IOO=</span><span class="kw">diag</span>(nObs), <span class="dt">IPP=</span><span class="kw">diag</span>(nPred), <span class="dt">mu=</span><span class="kw">rep</span>(<span class="dv">0</span>,nObs))

data &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">yObs =</span> yObs)

inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">rho =</span> <span class="dv">1</span>, <span class="dt">sigGP =</span> <span class="dv">1</span>, <span class="dt">sigOE =</span> <span class="dv">1</span>)

Rmodel &lt;-<span class="st"> </span><span class="kw">nimbleModel</span>(code, constants, data, inits)</code></pre>
<h3 id="create-compile-and-run">Create, compile, and run</h3>
<pre class="sourceCode r"><code class="sourceCode r">## MCMC specification with no samplers
spec &lt;-<span class="st"> </span><span class="kw">configureMCMC</span>(Rmodel, <span class="dt">nodes =</span> <span class="ot">NULL</span>)

## this will be used for some checking, and setting up block sampler:
params &lt;-<span class="st"> </span>Rmodel$<span class="kw">getNodeNames</span>(<span class="dt">topOnly =</span> <span class="ot">TRUE</span>)

## NOTE: the next line shouldn&#39;t work for you, since the MCMC API has changed.
## you can rebuild from source off nimble branch &#39;devel&#39;.
## otherwise, using last public release of NIMBLE (0.3-1), use this line instead:
## spec$addSampler(&#39;RW_block&#39;, control = list(targetNodes = params))
spec$<span class="kw">addSampler</span>(params, <span class="st">&#39;RW_block&#39;</span>)</code></pre>
<pre><code>[1] RW_block sampler: rho, sigGP, sigOE,  adaptive: TRUE,  adaptScaleOnly: FALSE,  adaptInterval: 200,  scale: 1,  propCov: identity</code></pre>
<p>We can debate about univariate vs. block sampling at some point.</p>
<pre class="sourceCode r"><code class="sourceCode r">## MCMC function
Rmcmc &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(spec)

## GP prediction function
## also uses the &#39;params&#39; variable for specialization
Rpred &lt;-<span class="st"> </span><span class="kw">gpPred</span>(Rmodel, params)

## compile everything
Cmodel &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmodel)
Cmcmc  &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmcmc, <span class="dt">project =</span> Rmodel)
Cpred  &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rpred, <span class="dt">project =</span> Rmodel)

## MCMC sampling
## 100,000 iterations
<span class="kw">system.time</span>(Cmcmc$<span class="kw">run</span>(<span class="dv">100000</span>))</code></pre>
<pre><code>   user  system elapsed 
 65.848   0.035  66.044 </code></pre>
<p>About 25 seconds on my computer</p>
<p>That can be improved if necessary</p>
<pre class="sourceCode r"><code class="sourceCode r">samples &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(Cmcmc$mvSamples)

## quick check
if(!<span class="kw">identical</span>(params, <span class="kw">colnames</span>(samples))) <span class="kw">stop</span>(<span class="st">&#39;problem&#39;</span>)

## predict from GP model using posterior MCMC samples
<span class="kw">system.time</span>(Cpred$<span class="kw">run</span>(samples))</code></pre>
<pre><code>   user  system elapsed 
 85.653   0.004  85.815 </code></pre>
<p>About 40 seconds on my computer</p>
<p>Again, could streamline the gpPred() function if necessary</p>
<pre class="sourceCode r"><code class="sourceCode r">## extract predictions: E and C
E &lt;-<span class="st"> </span>Cpred$<span class="kw">getE</span>()
C &lt;-<span class="st"> </span>Cpred$<span class="kw">getC</span>()</code></pre>
<h3 id="output">Output</h3>
<pre class="sourceCode r"><code class="sourceCode r">E</code></pre>
<pre><code>  [1]  1.048953470  1.063690923  1.056571565  1.025025296  0.967727602
  [6]  0.885088092  0.779046134  0.652750089  0.510403944  0.357145489
 [11]  0.198827230  0.041501513 -0.109026506 -0.247533773 -0.369716151
 [16] -0.472313950 -0.553105378 -0.610874554 -0.645461105 -0.657719603
 [21] -0.649076810 -0.621198765 -0.575868588 -0.514737033 -0.439105417
 [26] -0.349971602 -0.248371381 -0.135451833 -0.012707283  0.117353661
 [31]  0.251084159  0.383920114  0.510567530  0.625303732  0.722419735
 [36]  0.796925448  0.845259818  0.865448082  0.857113606  0.821872152
 [41]  0.763535592  0.687360014  0.599297100  0.505480001  0.411259520
 [46]  0.320288380  0.234175561  0.152695050  0.074286902 -0.003167262
 [51] -0.081466127 -0.161638385 -0.243673849 -0.325876291 -0.404833854
 [56] -0.476477835 -0.536583186 -0.580993801 -0.606153844 -0.609554981
 [61] -0.590206477 -0.548974521 -0.488316837 -0.411928777 -0.324540013
 [66] -0.231641132 -0.139114920 -0.052860394  0.021550784  0.079331411
 [71]  0.117042000  0.132978712  0.127078948  0.100689033  0.056355647
 [76] -0.002485485 -0.071873133 -0.147591543 -0.225248038 -0.300383786
 [81] -0.368679284 -0.425886710 -0.467685571 -0.489815787 -0.488669528
 [86] -0.462038368 -0.409587331 -0.332776473 -0.234523765 -0.119090537
 [91]  0.008395849  0.142692615  0.278921123  0.412628846  0.539726698
 [96]  0.656454950  0.759426449  0.845730518  0.912939607  0.959256645
[101]  0.984015990  0.987978885  0.972988593  0.941606557  0.896909969
[106]  0.842215301  0.780777080  0.715559458  0.649099436  0.583448236
[111]  0.520171088  0.460385520  0.404821033  0.353887176  0.307741235
[116]  0.266350221  0.229544512  0.197062243  0.168584714  0.143763668</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag</span>(C)</code></pre>
<pre><code>  [1] 1.2679882 1.2064883 1.1541432 1.1116728 1.0784248 1.0524884
  [7] 1.0317576 1.0147224 1.0007923 0.9900904 0.9827438 0.9787769
 [13] 0.9777564 0.9783522 0.9785871 0.9766328 0.9714366 0.9630053
 [19] 0.9522229 0.9402332 0.9284669 0.9183767 0.9109672 0.9068412
 [25] 0.9062843 0.9093517 0.9158928 0.9254797 0.9372421 0.9497874
 [31] 0.9614992 0.9705821 0.9757483 0.9766685 0.9740220 0.9691475
 [37] 0.9633160 0.9577090 0.9532083 0.9500621 0.9480639 0.9471172
 [43] 0.9473233 0.9485876 0.9506984 0.9530274 0.9546481 0.9549896
 [49] 0.9542985 0.9535398 0.9539394 0.9568409 0.9630692 0.9727686
 [55] 0.9850166 0.9979048 1.0093360 1.0177498 1.0224490 1.0235779
 [61] 1.0216894 1.0172186 1.0108482 1.0037543 0.9975825 0.9940451
 [67] 0.9942810 0.9988192 1.0071728 1.0181157 1.0297591 1.0394083
 [73] 1.0443944 1.0429170 1.0346484 1.0209019 1.0041130 0.9869394
 [79] 0.9713413 0.9580174 0.9466908 0.9370265 0.9291060 0.9233148
 [85] 0.9204774 0.9213396 0.9262437 0.9349512 0.9465634 0.9595347
 [91] 0.9721773 0.9829212 0.9902883 0.9935894 0.9933386 0.9913798
 [97] 0.9906718 0.9946403 1.0070336 1.0312845 1.0694759 1.1218007
[103] 1.1866870 1.2612294 1.3418003 1.4247225 1.5067538 1.5853383
[109] 1.6586720 1.7256456 1.7857277 1.8388290 1.8851737 1.9251909
[115] 1.9594282 1.9884878 2.0129814 2.0334994 2.0505931 2.0647637</code></pre>
<p>Black dots are the original ‘xObs’ and ‘yObs’</p>
<p>Red dots are the predictions made at each ‘xPred’</p>
<p>Red lines are plus/minus one standard error</p>
<figure>
<img src="/2015/assets/figures/posts/2015-06-16-daniel-gp-example/unnamed-chunk-13-1.png" />
</figure>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/06/16/daniel-gp-example.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/05/08/ram-legacy-database-explore.html">Ram Legacy Database Explore</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 08 May 2015</p>

<article>
<div class="excerpt">
<h2 id="accessing-the-database">Accessing the database</h2>
<p>Connect to the database (connection info is <a href="http://ramlegacy.marinebiodiversity.ca/ram-legacy-stock-assessment-database/accessing-the-live-database">public</a>), works fine:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;RPostgreSQL&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mydb &lt;-<span class="st"> </span><span class="kw">src_postgres</span>(<span class="dt">dbname =</span> <span class="st">&quot;srdb&quot;</span>, 
                     <span class="dt">host=</span><span class="st">&quot;nautilus-vm.mathstat.dal.ca&quot;</span>, 
                     <span class="dt">user =</span> <span class="st">&quot;srdbuser&quot;</span>, 
                     <span class="dt">password =</span>  <span class="st">&quot;srd6us3r!&quot;</span>, 
                     <span class="dt">port =</span> <span class="dv">5432</span>)
mydb</code></pre>
<pre><code>src:  postgres 8.4.10 [srdbuser@nautilus-vm.mathstat.dal.ca:5432/srdb]
tbls: area, assessment, assessmethod, assessor, biometrics,
  bioparams, brptots, fishbasesaupcodes, geometry_columns, lmerefs,
  lmes, lmetostocks, management, mostrecent, recorder, referencedoc,
  reference_point_units_view, reference_point_values_view, risfields,
  risfieldvalues, spatial_ref_sys, stock, taxonomy, timeseries,
  timeseries_units_view, timeseries_values_view, tsmetrics,
  tsrelative_explicit_view</code></pre>
<p>However, the expected mechanism for accessing a complete table seems to fail:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tbl</span>(mydb, <span class="st">&quot;stock&quot;</span>)</code></pre>
<pre><code>Error in postgresqlExecStatement(conn, statement, ...): RS-DBI driver: (could not Retrieve the result : ERROR:  relation &quot;stock&quot; does not exist
LINE 1: SELECT * FROM &quot;stock&quot; WHERE 0=1
                      ^
)</code></pre>
<p>Filed as a bug report in <a href="https://github.com/rstats-db/RPostgres/issues/32">RPostgres/#32</a>.</p>
<p>Meanwhile, direct sql queries work (note we need the full table address, e.g. <code>dbname.tablename</code>.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.stock&quot;</span>))</code></pre>
<pre><code>Source: postgres 8.4.10 [srdbuser@nautilus-vm.mathstat.dal.ca:5432/srdb]
From: &lt;derived table&gt; [?? x 8]

      stockid    tsn scientificname   commonname
1        COD1 164712   Gadus morhua Atlantic cod
2    COD2J3KL 164712   Gadus morhua Atlantic cod
3  COD2J3KLIS 164712   Gadus morhua Atlantic cod
4       COD3M 164712   Gadus morhua Atlantic cod
5      COD3NO 164712   Gadus morhua Atlantic cod
6      COD3Ps 164712   Gadus morhua Atlantic cod
7   COD3Pn4RS 164712   Gadus morhua Atlantic cod
8       COD4T 164712   Gadus morhua Atlantic cod
9     COD4VsW 164712   Gadus morhua Atlantic cod
10    COD4TVn 164712   Gadus morhua Atlantic cod
..        ...    ...            ...          ...
Variables not shown: areaid (chr), stocklong (chr), inmyersdb (int),
  myersstockid (chr)</code></pre>
<p>Since these tables easily fit into memory, it is generally faster to just import them into R rather than leaving <code>dplyr</code> to just work with them remotely. The <code>dplyr::collect()</code> function does this. So we create local copies of each table of interest like so:</p>
<pre class="sourceCode r"><code class="sourceCode r">timeseries &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries&quot;</span>)))
values &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries_values_view&quot;</span>)))

units &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.timeseries_units_view&quot;</span>)))
assessment &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessment&quot;</span>)))
area &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.area&quot;</span>)))
stock &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.stock&quot;</span>)))
method &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessmethod&quot;</span>)))
assessor &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.assessor&quot;</span>)))
management  &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.management&quot;</span>)))
taxonomy &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.taxonomy&quot;</span>)))

lmerefs &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.lmerefs&quot;</span>)))
lmestock &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.lmetostocks&quot;</span>)))


biometrics  &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.biometrics&quot;</span>)))
bioparams &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.bioparams&quot;</span>)))

tsmetrics &lt;-<span class="st"> </span><span class="kw">collect</span>(<span class="kw">tbl</span>(mydb, <span class="kw">sql</span>(<span class="st">&quot;SELECT * FROM srdb.tsmetrics&quot;</span>)))</code></pre>
<p>Many of the tables contain observations of variables that describe each given assessment (<code>assessid</code>), including the species <code>stock</code> assessed, <code>area</code> assessed, the method used, and so forth. Since these all follow the same schema of a row being a unique stock assessment and a column being an attribute of that assessment, it makes sense to combine this into a single metadata table. (Especially as these datasets fit so easily into memory anyway.)</p>
<pre class="sourceCode r"><code class="sourceCode r">meta &lt;-<span class="st"> </span>assessment %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">methodshort =</span> assessmethod) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(method) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(stock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(area) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(units) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(assessor) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(management) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(taxonomy) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">all_areas &lt;-<span class="st"> </span>stock %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(stockid, areaid) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(area) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">right_join</span>(lmestock) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(lmerefs)

<span class="kw">sapply</span>(all_areas, function(x) <span class="kw">length</span>(<span class="kw">levels</span>(<span class="kw">factor</span>(x))))</code></pre>
<pre><code>           stockid             areaid            country 
               391                174                 10 
          areatype           areacode           areaname 
                24                167                167 
 alternateareaname         lme_number stocktolmerelation 
                 5                 34                  5 
          lme_name 
                34 </code></pre>
<ul>
<li><code>bioparams</code>: Fixed parameter values of a study.</li>
<li><code>biometrics</code>: definitions of said parameters.</li>
</ul>
<p>The column is called <code>biounique</code> in <code>biometrics</code> table but <code>bioid</code> in <code>bioparams</code> table, so we fix that:</p>
<pre class="sourceCode r"><code class="sourceCode r">parameters &lt;-<span class="st"> </span>biometrics %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">bioid =</span> biounique) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(bioparams) </code></pre>
<ul>
<li><code>tsmetrics</code> defines the factor levels and the units used in <code>timeseries</code> <code>tsid</code> column.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">tsmetrics &lt;-<span class="st"> </span>tsmetrics %&gt;%<span class="st"> </span><span class="kw">rename</span>(<span class="dt">tsid =</span> tsunique)</code></pre>
<p>For example, we can see what measurements are available</p>
<pre class="sourceCode r"><code class="sourceCode r">ids &lt;-<span class="st"> </span>timeseries %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;NWFSC-COWCODSCAL-1900-2007-BRANCH&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">distinct</span>(tsid) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(tsid)
ids</code></pre>
<pre><code>Source: local data frame [7 x 1]

      tsid
1   SSB-MT
2    R-E03
3   F-1/yr
4    TB-MT
5    TC-MT
6    TL-MT
7 STB1+-MT</code></pre>
<p>Looking up these ids in the <code>tsmetrics</code> table tells us what these seven time series are:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inner_join</span>(ids, tsmetrics) %&gt;%<span class="st"> </span><span class="kw">select</span>(tsshort, tslong, tsunitsshort, tsunitslong)</code></pre>
<pre><code>Source: local data frame [7 x 4]

  tsshort
1     SSB
2       R
3       F
4      TB
5      TC
6      TL
7   STB1+
Variables not shown: tslong (chr), tsunitsshort (chr), tsunitslong
  (chr)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">cowcod &lt;-<span class="st"> </span>timeseries %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;NWFSC-COWCODSCAL-1900-2007-BRANCH&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">left_join</span>(tsmetrics) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(tsyear, tsvalue, <span class="dt">col=</span>tsid)) +<span class="st"> </span><span class="kw">geom_line</span>() 
cowcod</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-05-08-ram-legacy-database-explore/unnamed-chunk-12-1.png" />
</figure>
<pre class="sourceCode r"><code class="sourceCode r">cowcod +<span class="st"> </span><span class="kw">scale_y_log10</span>()</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-05-08-ram-legacy-database-explore/unnamed-chunk-13-1.png" />
</figure>
<p>(Note TC (total catch) and TL (total landings) are equivalent in this context, implying neglible discards.)</p>
<p>Unfortunately, there is a lot of heterogeneity in the metrics measured by each assessment: <code>tsmetrics</code> defines 151 units, (though only 93 appear in timeseries)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(<span class="kw">unique</span>(tsmetrics$tsid))</code></pre>
<pre><code>[1] 151</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(<span class="kw">table</span>(timeseries$tsid))</code></pre>
<pre><code>[1] 93</code></pre>
<p>Most are variations differing only by units, as we see from the most commonly used metrics:</p>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs &lt;-<span class="st"> </span>
timeseries %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(tsid) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(assessid) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">occurs =</span> <span class="kw">n</span>()) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(tsmetrics) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(occurs)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(tsid, tslong, tsunitsshort, occurs)
unit_occurs</code></pre>
<pre><code>Source: local data frame [93 x 4]

                      tsid
1                    TB-MT
2                   SSB-MT
3                    R-E03
4                    TC-MT
5                    TL-MT
6                    F-1/T
7                   F-1/yr
8                 ER-ratio
9  Yield-SSB-dimensionless
10                 YEAR-yr
..                     ...
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<p>These are all variations of the same several variables, but measured in different units. For instance, we see many series use a catch to biomass ratio (ER) instead of a fishing mortality.</p>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs %&gt;%<span class="st"> </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;^SSB&quot;</span>, tsid))</code></pre>
<pre><code>Source: local data frame [12 x 4]

                tsid
1             SSB-MT
2        SSB-E03eggs
3      SSB-STDDEV-MT
4           SSB-1-MT
5           SSB-2-MT
6       SSB-relative
7            SSB-E03
8      SSB-E06larvae
9           SSB-3-MT
10          SSB-4-MT
11     SSB-E03pertow
12 SSB-FemaleGonadMT
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs %&gt;%<span class="st"> </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;^R&quot;</span>, tsid))</code></pre>
<pre><code>Source: local data frame [7 x 4]

        tsid
1      R-E03
2    R-1-E03
3    R-2-E03
4       R-MT
5 R-relative
6    R-3-E03
7    R-4-E03
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs %&gt;%<span class="st"> </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;^TC&quot;</span>, tsid))</code></pre>
<pre><code>Source: local data frame [7 x 4]

      tsid
1    TC-MT
2   TC-E03
3   TC-E00
4 TC-1-E03
5  TC-1-MT
6  TC-2-MT
7 TC-2-E03
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs %&gt;%<span class="st"> </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;^TL&quot;</span>, tsid))</code></pre>
<pre><code>Source: local data frame [5 x 4]

     tsid
1   TL-MT
2 TL-1-MT
3 TL-2-MT
4 TL-3-MT
5  TL-E00
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">unit_occurs %&gt;%<span class="st"> </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;^CPUE&quot;</span>, tsid))</code></pre>
<pre><code>Source: local data frame [10 x 4]

                   tsid
1         CPUE-kgpertow
2       CPUEstand-1-C/E
3       CPUEstand-2-C/E
4         CPUEstand-C/E
5           CPUEraw-C/E
6       CPUEstand-3-C/E
7       CPUEstand-4-C/E
8  CPUEsmooth-E00pertow
9       CPUEstand-5-C/E
10      CPUEstand-6-C/E
Variables not shown: tslong (chr), tsunitsshort (chr), occurs (int)</code></pre>
<p>The <code>values</code> table appears to be derived from the <code>timeseries</code> table, presumably standardizing on consistent metrics(?)</p>
<pre class="sourceCode r"><code class="sourceCode r">values</code></pre>
<pre><code>Source: local data frame [16,308 x 9]

                        assessid tsyear pt_avail       ssb       r
1  ADFG-HERRPWS-1980-2006-COLLIE   1980        5  48270.35  414070
2  ADFG-HERRPWS-1980-2006-COLLIE   1981        5  51090.88  335200
3  ADFG-HERRPWS-1980-2006-COLLIE   1982        5  47402.54  112300
4  ADFG-HERRPWS-1980-2006-COLLIE   1983        5  56449.01  103740
5  ADFG-HERRPWS-1980-2006-COLLIE   1984        5  64461.28 1062360
6  ADFG-HERRPWS-1980-2006-COLLIE   1985        5  79124.61   99630
7  ADFG-HERRPWS-1980-2006-COLLIE   1986        5  65601.06   74880
8  ADFG-HERRPWS-1980-2006-COLLIE   1987        5  70646.42   84820
9  ADFG-HERRPWS-1980-2006-COLLIE   1988        5  93508.20 1006440
10 ADFG-HERRPWS-1980-2006-COLLIE   1989        5 105135.41  119970
..                           ...    ...      ...       ...     ...
Variables not shown: total (dbl), f (dbl), cpue (dbl), catch_landings
  (dbl)</code></pre>
<p>We can see this by transforming our example:</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>timeseries %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;NWFSC-COWCODSCAL-1900-2007-BRANCH&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(tsid, tsvalue) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">ssb=</span><span class="st">`</span><span class="dt">SSB-MT</span><span class="st">`</span>, <span class="dt">r =</span> <span class="st">`</span><span class="dt">R-E03</span><span class="st">`</span>, <span class="dt">total =</span> <span class="st">`</span><span class="dt">TB-MT</span><span class="st">`</span>, <span class="dt">f =</span> <span class="st">`</span><span class="dt">F-1/yr</span><span class="st">`</span>, <span class="dt">catch_landings =</span> <span class="st">`</span><span class="dt">TL-MT</span><span class="st">`</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(assessid, tsyear, ssb, r, total, f, catch_landings)</code></pre>
<p>which is indeed identical to corresponding assessment in the <code>values</code> table</p>
<pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>values %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;NWFSC-COWCODSCAL-1900-2007-BRANCH&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">select</span>(-pt_avail, -cpue)
<span class="kw">identical</span>(x,y)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>So what happens when the units differ?</p>
<pre class="sourceCode r"><code class="sourceCode r">timeseries %&gt;%<span class="st"> </span><span class="kw">filter</span>(tsid==<span class="st">&quot;SSB-E03eggs&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">distinct</span>(<span class="st">&quot;assessid&quot;</span>)</code></pre>
<pre><code>Source: local data frame [1 x 5]

                               assessid        tsid tsyear  tsvalue
1 TAFI-TASGIANTCRABTAS-1990-2007-JENSEN SSB-E03eggs   1998 188.9256
Variables not shown: &quot;assessid&quot; (chr)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>timeseries %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;TAFI-TASGIANTCRABTAS-1990-2007-JENSEN&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(tsid, tsvalue) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="dt">ssb=</span><span class="st">`</span><span class="dt">SSB-E03eggs</span><span class="st">`</span>)

y &lt;-<span class="st"> </span>values %&gt;%<span class="st"> </span><span class="kw">filter</span>(assessid ==<span class="st"> &quot;TAFI-TASGIANTCRABTAS-1990-2007-JENSEN&quot;</span>) %&gt;%<span class="st"> </span><span class="kw">select</span>(ssb)
<span class="kw">identical</span>(x,y)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>No transformation has been done, hence the units of the <code>values</code> columns vary depending on the assessment id. Nonetheless it is quite useful to have the metrics split into their corresponding 5 types rather than as 93 unique subtypes. As long as we are not comparing magnitudes across different assessments directly though, this should not be an issue.</p>
<hr />
<p>It would probably be useful to reconstruct the code to generate the <code>values</code> table from the timeseries table directly. One might hope that the mappings between <code>tsid</code> values and the five column headings in the <code>values</code> table would be defined in the database, e.g. in perhaps the <code>tscategory</code> column of <code>tsmetrics</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unique</span>(tsmetrics$tscategory)</code></pre>
<pre><code>[1] &quot;FISHING MORTALITY&quot;                                                            
[2] &quot;TOTAL BIOMASS&quot;                                                                
[3] &quot;TIME UNITS&quot;                                                                   
[4] &quot;SPAWNING STOCK BIOMASS or CPUE&quot;                                               
[5] &quot;RECRUITS (NOTE: RECRUITS ARE OFFSET IN TIME SERIES BY THE AGE OF RECRUITMENT)&quot;
[6] &quot;CATCH or LANDINGS&quot;                                                            
[7] &quot;OTHER TIME SERIES DATA&quot;                                                       </code></pre>
<p>but alas this does not quite appear to be the case (e.g. CPUE and SSB are a single category.) Some combination of this information and splitting on the <code>tsid</code> strings would probably suffice.</p>
<hr />
<pre class="sourceCode r"><code class="sourceCode r">ts &lt;-<span class="st"> </span>meta %&gt;%<span class="st"> </span><span class="kw">select</span>(assessid, commonname) %&gt;%<span class="st"> </span><span class="kw">right_join</span>(values)</code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/05/08/ram-legacy-database-explore.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2015/04/28/rfishbase-notes.html">Rfishbase Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 28 Apr 2015</p>

<article>
<div class="excerpt">
<h3 id="kalman-filtering">kalman filtering</h3>
<h3 id="updates-to-drat-repo">updates to drat repo</h3>
<ul>
<li>rescript personal deploy.R script</li>
<li>pull request</li>
</ul>
<h3 id="rfishbase">rfishbase</h3>
<p><code>rfishbase</code> queries from users: getting “Resilience,” “Vulnerability” and “Price Category” data:</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">species_info</span>(<span class="st">&quot;Labroides bicolor&quot;</span>, <span class="dt">fields =</span> <span class="kw">c</span>(<span class="st">&quot;SpecCode&quot;</span>, <span class="st">&quot;Vulnerability&quot;</span>, <span class="st">&quot;PriceCateg&quot;</span>))</code></pre>
<p>It so happens that “Resilience” is not in that table, but in the “stocks” table instead:</p>
<pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">stocks</span>(<span class="st">&quot;Labroides bicolor&quot;</span>, <span class="dt">fields=</span><span class="kw">c</span>(<span class="st">&quot;SpecCode&quot;</span>, <span class="st">&quot;Resilience&quot;</span>))</code></pre>
<p>You can now merge the results:</p>
<pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">merge</span>(x,y)</code></pre>
<p>In general, you can see a list of all the columns in a given table by just omitting the “fields” argument:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">species_info</span>(<span class="st">&quot;Labroides bicolor&quot;</span>)</code></pre>
<p>Since the nearly 100 columns don’t fit in the page, the function just summarizes the column names for the ones that don’t fit. You can read through that list and spot the words “Vulnerability” and “PriceCateg”, and then use them in the ‘fields’ argument to just get those results.</p>
<p>Note that all of these functions can take a long list of species names instead of a single species, and thus will return a table with a row for each species and the desired columns.</p>
<p>Also note that we use “SpecCode”, the species code, to identify a species on fishbase. You can use the function “speciesnames” to transform this numeric code into a species name; e.g.</p>
<pre class="sourceCode r"><code class="sourceCode r">data$SpecCode &lt;-<span class="st"> </span><span class="kw">speciesnames</span>(data$SpecCode)</code></pre>
<ul>
<li>Improved sql helper script recipe.</li>
</ul>
<h4 id="searching-sql-for-a-field">searching SQL for a field</h4>
<pre class="sourceCode sql"><code class="sourceCode sql">
<span class="kw">select</span> <span class="kw">distinct</span> table_name <span class="kw">from</span> information_schema.columns <span class="kw">where</span> column_name <span class="kw">in</span> (<span class="st">&#39;Resilience&#39;</span>) <span class="kw">and</span> table_schema=<span class="st">&#39;fbapp&#39;</span>;</code></pre>
<p>and then we can do the usual</p>
<pre class="sourceCode sql"><code class="sourceCode sql">describe stocks</code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/04/28/rfishbase-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/04/20/open-science-post-doc.html">Open Science Post Doc</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 20 Apr 2015</p>

<article>
<div class="excerpt">
<p>This post is a response to the query posted by Titus Brown on <a href="http://ivory.idyll.org/blog/2015-how-to-find-openscience-advisor.html">advice for doing an Open Science Post doc</a>.</p>
<p>Open Science is a broad tent, and I believe there are many ways to engage in open science without crossing boundaries of collaborators or PIs. Some of the most valuable open science practices are those least likely to cross boundaries: in particular, those practices associated with post-publication of academic papers. Many widely regarded journals, including <em>Nature</em> and <em>Science</em>, have relatively strong data publication requirements, increasingly strong code publication expectations, and are compatible with the use of pre-print archives. Yes, their are those who would hesitate even to comply with the most minimal interpretation of these expectations; but there are many more who, given the expectation to do this at all, would appreciate your knowledge and effort on doing these things well and consistent with best practices. Using data repositories instead of supplemental material; exhibiting good management of data and code; providing good metadata in consistent formats; citing software and data appropriately.</p>
<p>Many of the practices promoted by open scientists work almost as well in a setting that is closed until you ‘flip the switch’ to make them public; even if that is long after publication. Good data management, a private Github repository, or a private electronic lab notebook are all ways to leverage best practices tools and approaches in a setting that can either be shared securely or made open later. Attitudes to post-publication sharing are rarely black-and-white, and having everything curated and ready to go ahead of time can help nudge collaborators in the direction of best practices.</p>
<p>I’ve been a post-doc for just over 2 years while enjoying a relatively open-science approach to my research: I’ve kept an open lab notebook, posted my papers ahead of publication on pre-print archives, released code, data, and knitr versions of my papers, discuss my work on social media, sign reviews, shared grant applications, contributed open source software and been active in open science communities.</p>
<p>I was fortunate to have independent funding for most but not all of my post-doc, and to work in a field where researchers are often given substantial independence and in which open practices are common. Nonetheless these were not practices shared by either of my two excellent co-advisers, who gave only a neutral or vaguely positive response to these ideas.</p>
<p>Nevertheless, I learned more about <em>old-school</em> open science from them than I had ever imagined. When I sent Marc the first draft of our paper, I had buried almost all of the equations in a curt appendix with minimal and jargon-laden supporting text. No sir, those equations not only had to appear in the main text, but I must endeavor to explain the meaning and relevance of each one in a language clear and concise enough for any ecologist to follow. I won’t claim to have succeeded, but boy did continuous integration on my unit tests feel like a low bar for openness by comparison.</p>
<p>Meanwhile, I also felt I had the support and mentorship of an online community of open scientists even without going to work for one of them. I am thankful that my mentors have always been tolerant of my open science experimentation, but I would have enjoyed working with them even if it had been otherwise. There was much to learn from them, much to learn from the open science community, and after all, a post-doc position doesn’t last forever.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/04/20/open-science-post-doc.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/04/15/misc-notes-on-cloud-providers.html">Misc Notes On Cloud Providers</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 15 Apr 2015</p>

<article>
<div class="excerpt">
<p><em>ongoing notes comparing computing resources</em></p>
<p>Comparing compute resources:</p>
<ul>
<li><p>AWS EC2, DigitalOcean, and Google Compute Engine look significantly cheaper than Rackspace, Azure, etc. (The Economist has estimated that AWS EC2 prices are roughly 3% <em>below</em> cost).</p></li>
<li><p>DigitalOcean tends to have the lowest price point for on-demand use of a given set of resources; usually comparable to the Amazon or EC2 persistent (e.g. monthly) use. All-inclusive pricing (storage, networking etc) and limited options make choices simple and total costs easy to anticipate, though lack the flexibility to fine-tune a configuration to pay for exactly what you need.</p></li>
<li><p>Google offers the best rate for higher-cpu instances, (e.g. 16 cores); primarily by provisioning them with less memory (0.9 GB/core) than DO or EC2.</p></li>
<li><p>Google configures disk space separately from instance type. Cost of $0.04 per GB for spinning disk storage, is quite a bit cheaper than the ~ $0.10/GB for AWS EBS, and in fact nearly S3 price ~ $0.03. This makes it a potentially compelling platform for high storage, low compute instances.</p></li>
</ul>
<p>Presumably this is non-local storage like EBS, since they also offer a (very expensive) local SSD option (limited to 375 GB increments, each inc at $81.75 / mo). Though if the non-local nature creates a significant latency, it isn’t clear why one would buy non-local SSD option for $0.17/GB.</p>
<h2 id="using-google-compute-engine">Using Google Compute Engine</h2>
<p>Web interface is cleaner but much less flexible than Amazon’s, most tasks must be done with the commandline SDK tool instead, <code>gcloud</code> (such as modifying firewall settings other than port 80 and port 443). For instance, <a href="https://developer.ubuntu.com/en/snappy/start/#snappy-google">this tutorial</a> on running an Ubuntu Snappy Core image instead of the usual defaults.</p>
<p>Docker-machine makes this a bit easier, as usual. The user needs to create a project name and project id on the Google Cloud Engine web interface. Only the project-name is required as an argument to docker-machine (e.g. no authentication token), auth must be done interactively through a web terminal. It doesn’t seem that there is a way to turn on <code>http</code> port or otherwise configure the firewall. By default, all inbound ports are shut. By mapping to port <code>80</code> and checking ‘allow http’ in the web interface one can still access an app like RStudio-server (my mapping docker ports appropriately), but there doesn’t seem to be any way to automate this. (In contrast, with Amazon EC2, docker-machine automatically attaches a ‘security-group’ called <code>docker-machine</code>, so a user can customize the ports permitted on that security group to have, e.g. 8787 open by default.)</p>
<h2 id="performance-comparisons">Performance comparisons</h2>
<p>CPU performance varies within a single provider.</p>
<ul>
<li>DO CPUs appear 2.3 - 2.4 Ghz with ~ 15MB cache,</li>
<li>Google CPUs around 2.6 Ghz with ~ 20MB cache,</li>
<li>Amazon ~ 2.8 Ghz with ~ 25 MB cache</li>
</ul>
<p>network i/o speeds seem reasonable on all.</p>
<hr />
<h2 id="using-resources-with-docker-machine">Using resources with docker-machine</h2>
<p>docker-machine with docker save: after committing the container, this saves the container locally rather than on the host. With even reasonable download speeds ~ 0.5MB/s this is quite slow. DigitalOcean download speeds are ~ 680 Mb/s, and upload about half that. Better yet, pushing the container back to the Hub only pushes the changed layers anyway, so is nearly instantaneous. The Hub also provides a private repo for free.</p>
<p>This provides a pretty compelling workflow of</p>
<ul>
<li><code>docker-machine create ...</code></li>
<li><code>docker run &lt;...&gt; user/private</code> and do stuff</li>
<li><code>docker commit container user/private</code>, <code>docker push user/private</code>, <code>docker-machine rm -f ...</code></li>
</ul>
<p>in order to deploy one’s work on temporary machine with appropriate power, and then save the work and close the machine. Using docker instead of the standard image ‘snapshots’ is probably faster and nicely independent of the machine and provider; and in this case the snapshot storage is free of cost as well.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/04/15/misc-notes-on-cloud-providers.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2015/04/09/gpdd-and-kalman-exploration-continued.html">Gpdd And Kalman Exploration Continued</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 09 Apr 2015</p>

<article>
<div class="excerpt">
<p>Load libraries and data as before</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;knitcitations&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rgpdd&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;FKF&quot;</span>)</code></pre>
<h2 id="parallel-version-of-dplyrdo">Parallel version of <code>dplyr::do</code></h2>
<pre class="sourceCode r"><code class="sourceCode r">do_parallel &lt;-<span class="st"> </span>function(df, f, ...){

  <span class="co"># supports only one group for now</span>

  <span class="kw">require</span>(<span class="st">&quot;parallel&quot;</span>)
  <span class="kw">require</span>(<span class="st">&quot;lazyeval&quot;</span>)
  <span class="kw">require</span>(<span class="st">&quot;reshape2&quot;</span>)
  <span class="kw">options</span>(<span class="dt">mc.cores =</span> <span class="kw">detectCores</span>())

  grps &lt;-<span class="st"> </span><span class="kw">groups</span>(df)
  ids &lt;-<span class="st"> </span><span class="kw">sapply</span>(grps, function(i) <span class="kw">unique</span>(df[[<span class="kw">as.character</span>(i)]]))
  <span class="kw">names</span>(ids) &lt;-<span class="st"> </span><span class="kw">as.character</span>(ids)
  ## turn grouped data.frame to a list of data.frames by MainID
  list_data &lt;-<span class="st"> </span><span class="kw">lapply</span>(ids, 
                      function(id){ 
                        .dots &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">interp</span>(~y ==<span class="st"> </span>x, <span class="dt">.values =</span> <span class="kw">list</span>(<span class="dt">y =</span> grps[[<span class="dv">1</span>]], <span class="dt">x =</span> id)))
                        <span class="kw">filter_</span>(df, <span class="dt">.dots =</span> .dots)
                      })

  ## Actually do the fitting in parallel
  list_out &lt;-<span class="st"> </span><span class="kw">mclapply</span>(list_data, f, ...)

  ## reshape outputs back to a data.frame
  <span class="kw">melt</span>(list_out, <span class="dt">id=</span><span class="kw">names</span>(list_out[[<span class="dv">1</span>]])) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">rename_</span>(<span class="dt">.dots =</span> <span class="kw">setNames</span>(<span class="kw">list</span>(<span class="st">&quot;L1&quot;</span>), <span class="kw">as.character</span>(grps[[<span class="dv">1</span>]])) ) %&gt;%
<span class="st">              </span><span class="kw">as_data_frame</span>()
}</code></pre>
<h2 id="prepare-data">Prepare data</h2>
<p>Prepare data, as before: we filter on the stated criteria</p>
<pre class="sourceCode r"><code class="sourceCode r">gpdd_main %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(SamplingProtocol ==<span class="st"> &quot;Count&quot;</span>,
         SourceDimension %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Count&quot;</span>, <span class="st">&quot;Index&quot;</span>), 
         SamplingFrequency ==<span class="st"> &quot;1&quot;</span>,
         DatasetLength &gt;=<span class="st"> </span><span class="dv">15</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(MainID) %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(MainID) -&gt;
filtered</code></pre>
<p>and select data matching this filter. We add a column for the log of the population size and group by data ID:</p>
<pre class="sourceCode r"><code class="sourceCode r">gpdd_data %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(MainID %in%<span class="st"> </span>filtered$MainID) %&gt;%
<span class="st">  </span><span class="kw">select</span>(MainID, Population, SampleYear) %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">logN =</span> <span class="kw">log</span>(Population)) -&gt;
df</code></pre>
<p>Lastly, we replace <code>-Inf</code> (introduced from <code>log(0)</code> terms) with smallest finite values observed. (arbitrary, authors do not specify how these values are handled.)</p>
<pre class="sourceCode r"><code class="sourceCode r">i &lt;-<span class="st"> </span><span class="kw">which</span>(df$logN ==<span class="st"> </span>-<span class="ot">Inf</span>)
df$logN[i] &lt;-<span class="st"> </span><span class="kw">min</span>(df$logN[-i])-<span class="dv">1</span></code></pre>
<p>We may test on a subset of the data first:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#not run</span>
some &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">unique</span>(df$MainID), <span class="dv">10</span>)
df %&gt;%<span class="st"> </span><span class="kw">filter</span>(MainID %in%<span class="st"> </span>some) -&gt;<span class="st"> </span>df</code></pre>
<h2 id="import-function-definitions">Import function definitions</h2>
<p>We import our previous model definitions:</p>
<pre class="sourceCode r"><code class="sourceCode r">downloader::<span class="kw">download</span>(<span class="st">&quot;https://github.com/ropensci/rgpdd/raw/master/inst/scripts/knape-de-valpine.R&quot;</span>, <span class="st">&quot;knape-de-valpine.R&quot;</span>)
<span class="kw">source</span>(<span class="st">&quot;knape-de-valpine.R&quot;</span>)
<span class="kw">unlink</span>(<span class="st">&quot;knape-de-valpine.R&quot;</span>)</code></pre>
<h2 id="simulating">Simulating</h2>
<p>FKF package doesn’t bother to define a simulation method, so we can simply define one directly from the state equations. Though a C implementation would be preferrable, fitting will always be much more rate-limiting. (We will also ignore the multi-variate definition for simplicity here).</p>
<pre class="sourceCode r"><code class="sourceCode r">use &lt;-<span class="st"> </span>function(x, default){
  if(<span class="kw">is.null</span>(x))
    default
  else
    x
}

sim_fkf &lt;-<span class="st"> </span>function(fit){
  n &lt;-<span class="st"> </span>fit[[<span class="st">&quot;n&quot;</span>]]
  dt &lt;-<span class="st"> </span>fit[[<span class="st">&quot;dt&quot;</span>]]
  HHt &lt;-<span class="st"> </span>fit[[<span class="st">&quot;HHt&quot;</span>]]
  Tt &lt;-<span class="st"> </span><span class="kw">use</span>(fit[[<span class="st">&quot;Tt&quot;</span>]], <span class="dv">1</span>)
  GGt &lt;-<span class="st"> </span><span class="kw">use</span>(fit[[<span class="st">&quot;GGt&quot;</span>]], <span class="dv">0</span>)
  a0 &lt;-<span class="st"> </span>fit[[<span class="st">&quot;a0&quot;</span>]]
  ct &lt;-<span class="st"> </span><span class="dv">0</span>
  Zt &lt;-<span class="st"> </span><span class="dv">1</span>
  
  a &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
  y &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
  eta &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, dt, <span class="kw">sqrt</span>(HHt))
  epsilon &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, ct, <span class="kw">sqrt</span>(GGt))
  a[<span class="dv">1</span>] &lt;-<span class="st"> </span>a0
    for(t in <span class="dv">1</span>:(n<span class="dv">-1</span>)){
      a[t<span class="dv">+1</span>] &lt;-<span class="st"> </span>Tt *<span class="st"> </span>a[t] +<span class="st"> </span>eta[t]
      y[t] &lt;-<span class="st"> </span>Zt *<span class="st"> </span>a[t] +<span class="st"> </span>epsilon[t]
    }
        y[n] &lt;-<span class="st"> </span>Zt *<span class="st"> </span>a[n] +<span class="st"> </span>epsilon[n]
  y
}</code></pre>
<p>The study also creates simulated datasets based on the real data but explicitly making the assumption of either density independence (DI) or density dependence (DD). For each dataset, a density-independent simulated dataset is created by simulating under the SSRW model that was fit. The density-dependent model is created by explicitly fixing the density dependent parameter (<span class="math">\(c\)</span> in the language of the paper, <code>Tt</code> in FKF notation) to 0.8 and estimating the other parameters of this modified SSG model. We can define this model analgously to the others, only this time fixing <code>Tt = 0.8</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">fit_dd &lt;-<span class="st"> </span>function(y, 
                   <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>), <span class="dt">GGt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>)),
                   ...){
    
    o &lt;-<span class="st"> </span><span class="kw">optim</span>(init,
                 <span class="dt">fn =</span>  function(par, ...)
                   -<span class="kw">fkf</span>(<span class="dt">dt =</span> <span class="kw">matrix</span>(par[<span class="dv">1</span>]), <span class="dt">HHt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">2</span>])), 
                        <span class="dt">GGt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">3</span>])), ...)$logLik,
                 <span class="dt">Tt =</span> <span class="kw">matrix</span>(<span class="fl">0.8</span>), <span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">P0 =</span> <span class="kw">matrix</span>(<span class="dv">10</span>), 
                 <span class="dt">ct =</span> <span class="kw">matrix</span>(<span class="dv">0</span>), <span class="dt">Zt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>), <span class="dt">yt =</span> <span class="kw">rbind</span>(y), 
                 <span class="dt">check.input =</span> <span class="ot">FALSE</span>, ...)
  o$par[[<span class="st">&quot;HHt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;HHt&quot;</span>]])
  o$par[[<span class="st">&quot;GGt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;GGt&quot;</span>]])
  <span class="kw">c</span>(o, <span class="kw">list</span>(<span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">n =</span> <span class="kw">length</span>(y)))
   
}</code></pre>
<p>The script adds a method for this to <code>robust_fit()</code> as well; though given the computational cost it is not clear if a robust fit is actually used in generating the data.</p>
<pre class="sourceCode r"><code class="sourceCode r">sim_di &lt;-<span class="st"> </span>function(df) <span class="kw">data.frame</span>(<span class="dt">logN =</span> <span class="kw">sim_fkf</span>(<span class="kw">robust_fit</span>(<span class="st">&quot;ssrw&quot;</span>, df$logN, <span class="dt">N =</span> <span class="dv">3</span>)))
sim_dd &lt;-<span class="st"> </span>function(df) <span class="kw">data.frame</span>(<span class="dt">logN =</span> <span class="kw">sim_fkf</span>(<span class="kw">robust_fit</span>(<span class="st">&quot;dd&quot;</span>, df$logN, <span class="dt">N =</span> <span class="dv">3</span>)))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
df %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(sim_di) -&gt;<span class="st"> </span>DI
)</code></pre>
<pre><code>   user  system elapsed 
123.079   7.039   8.836 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  df %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(sim_dd) -&gt;<span class="st"> </span>DD
)</code></pre>
<pre><code>   user  system elapsed 
120.578   5.209   8.023 </code></pre>
<p>We can then use these two collections of datasets just as before:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  DD %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(kalman, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>) -&gt;<span class="st"> </span>DD_fits
)</code></pre>
<pre><code>    user   system  elapsed 
9218.572  248.985  324.883 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  DI %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(kalman, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>) -&gt;<span class="st"> </span>DI_fits
)</code></pre>
<pre><code>    user   system  elapsed 
8074.330  230.513  280.989 </code></pre>
<p>and from before:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
df %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(kalman, <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>) -&gt;<span class="st"> </span>fits
)</code></pre>
<pre><code>    user   system  elapsed 
7761.519  201.922  256.863 </code></pre>
<h4 id="figure-2">Figure 2</h4>
<p>From these simulations and corresponding parameter estimates of the density-dependent parameter, we can create our version of Figure 2:</p>
<pre class="sourceCode r"><code class="sourceCode r">order &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;real&quot;</span>, <span class="st">&quot;independent&quot;</span>, <span class="st">&quot;dependent&quot;</span>)

combined &lt;-<span class="st"> </span><span class="kw">rbind</span>(
  DD_fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;g&quot;</span>), parameter ==<span class="st"> &quot;Tt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> <span class="kw">factor</span>(<span class="st">&quot;dependent&quot;</span>, <span class="dt">levels=</span>order)),
  
  DI_fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;g&quot;</span>), parameter ==<span class="st"> &quot;Tt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> <span class="kw">factor</span>(<span class="st">&quot;independent&quot;</span>, <span class="dt">levels=</span>order)),
  
  fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;g&quot;</span>), parameter ==<span class="st"> &quot;Tt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">type =</span> <span class="kw">factor</span>(<span class="st">&quot;real&quot;</span>, <span class="dt">levels=</span>order))) %&gt;%
<span class="st">  </span>
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%<span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">uncertainty =</span> 
              plyr::<span class="kw">revalue</span>(model, 
                            <span class="kw">c</span>(<span class="dt">ssg =</span> <span class="st">&quot;accounting for uncertainty&quot;</span>,
                              <span class="dt">g =</span> <span class="st">&quot;ignoring uncertainty&quot;</span>)),
            type, value, MainID)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(combined) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(value), <span class="dt">binwidth=</span><span class="fl">0.2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(uncertainty ~<span class="st"> </span>type) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(value)), <span class="dt">lwd=</span>.<span class="dv">5</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="kw">median</span>(value)), <span class="dt">lwd=</span>.<span class="dv">5</span>, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>) +
<span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(-<span class="fl">1.1</span>,<span class="fl">1.1</span>)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;c value&quot;</span>) +
<span class="st">  </span><span class="kw">theme_bw</span>(<span class="dv">16</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-09-gpdd-and-kalman-exploration-continued/Figure2-1.png" />
</figure>
<hr />
<h2 id="bootstrapping">Bootstrapping</h2>
<p>With fitting and simulating functions in place, defining the bootstrap is straight forward. We define these separately for the state-space Gompertz (ssg; i.e. the model with both density dependence and observational errors) and the Gompertz (g; density dependence, no observational error). We compare in each case to the simulations of the corresponding model without density dependence.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap &lt;-<span class="st"> </span>function(df, <span class="dt">null_model =</span> <span class="st">&quot;ssrw&quot;</span>, <span class="dt">test_model =</span> <span class="st">&quot;ssg&quot;</span>, <span class="dt">N=</span><span class="dv">100</span>){
  y &lt;-<span class="st"> </span>df$logN
  
  ssg &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(test_model, y)
  ssrw &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(null_model, y)
  sims &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(<span class="kw">replicate</span>(N, <span class="kw">sim_fkf</span>(ssrw))))
  
  <span class="co"># We use a relaxed version of robust_fit, with N=3</span>
  sims %&gt;%<span class="st"> </span><span class="kw">rowwise</span>() %&gt;%<span class="st"> </span><span class="kw">do</span>(<span class="kw">robust_fit</span>(null_model, <span class="dt">y =</span> <span class="kw">as.numeric</span>(.), <span class="dt">N =</span> <span class="dv">3</span>)) %&gt;%<span class="st"> </span><span class="kw">select</span>(mloglik) -&gt;<span class="st"> </span>null
  
  <span class="co"># compute p value of observed LR statistic relative to null distribution</span>
  lr &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>(ssrw$mloglik -<span class="st"> </span>ssg$mloglik)
  null_dist &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>(null$mloglik -<span class="st"> </span>ssg$mloglik) 
  <span class="kw">data.frame</span>(<span class="dt">p =</span> <span class="kw">sum</span>(null_dist &lt;<span class="st"> </span>lr)/N)
}</code></pre>
<p>With these functions defined, we can perform the actual analysis.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  df %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;ssrw&quot;</span>, <span class="st">&quot;ssg&quot;</span>) -&gt;<span class="st"> </span>ssg_p_values
  )</code></pre>
<pre><code>     user    system   elapsed 
18552.515   509.365   630.503 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  df %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;rw&quot;</span>, <span class="st">&quot;g&quot;</span>) -&gt;<span class="st"> </span>g_p_values
  )</code></pre>
<pre><code>    user   system  elapsed 
7958.974  215.100  259.174 </code></pre>
<p>We can also do the bootstrapping for the simulated data:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
 DD %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;ssrw&quot;</span>, <span class="st">&quot;ssg&quot;</span>) -&gt;<span class="st"> </span>dd_ssg_p_values
)</code></pre>
<pre><code>     user    system   elapsed 
20739.616   533.335   704.335 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
 DD %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;rw&quot;</span>, <span class="st">&quot;g&quot;</span>) -&gt;<span class="st"> </span>dd_g_p_values
)</code></pre>
<pre><code>    user   system  elapsed 
9970.254  285.473  332.748 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
 DI %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;ssrw&quot;</span>, <span class="st">&quot;ssg&quot;</span>) -&gt;<span class="st"> </span>di_ssg_p_values
)</code></pre>
<pre><code>     user    system   elapsed 
18631.331   479.485   622.542 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
  DI %&gt;%<span class="st"> </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span><span class="kw">do_parallel</span>(bootstrap, <span class="st">&quot;rw&quot;</span>, <span class="st">&quot;g&quot;</span>) -&gt;<span class="st"> </span>di_g_p_values
)</code></pre>
<pre><code>    user   system  elapsed 
8021.423  227.704  264.113 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">P &lt;-<span class="st"> </span><span class="kw">rbind</span>(
  ssg_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;real&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;ssg&quot;</span>),
  g_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;real&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;g&quot;</span>),
  di_ssg_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;DI&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;ssg&quot;</span>),
  di_g_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;DI&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;g&quot;</span>),
  dd_g_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;DD&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;g&quot;</span>),
  dd_ssg_p_values %&gt;%<span class="st"> </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="st">&quot;DD&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;ssg&quot;</span>))


<span class="kw">ggplot</span>(P) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(p)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(model ~<span class="st"> </span>data) +<span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>(<span class="dv">16</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-09-gpdd-and-kalman-exploration-continued/Figure3-1.png" />
</figure>
<hr />
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/04/09/gpdd-and-kalman-exploration-continued.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/04/06/gpdd-explore.html">Gpdd Explore</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 06 Apr 2015</p>

<article>
<div class="excerpt">
<h3 id="setup">setup</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;tidyr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rgpdd&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;FKF&quot;</span>)</code></pre>
<p>Working through <a href="http://doi.org/10.1111/j.1461-0248.2011.01702.x">10.1111/j.1461-0248.2011.01702.x</a> provides a nice way to play around with the GPDD data and Kalman filtering. More interested in exploring the data and methods than in just replicating the results, which are important but also rather intuitive and thus I expect rather robust – as we add (observational) uncertainty, or indeed, any additional parameters that must be ended, we should expect to have less power to pin down a particular parameter associated with density dependence, as the paper illustrates rather nicely.</p>
<hr />
<h2 id="data-preparation">Data preparation</h2>
<blockquote>
<p>627 time series with population indices obtained from the GPDD (NERC Centre for Population Biology 1999). Data sets were filtered out from the database by removing harvest and non-index based data, data sampled at non-annual intervals and time series taking less than 15 unique values.</p>
</blockquote>
<p>Excluding time-series shorter than a minimum length is intuitive. Excluding harvest data makes some sense, as these aren’t scientific samples; in particular, they do not necessarily reflect a uniform sampling effort over time. Not quite clear why one would exclude non-annual intervals. Not really clear what “non-index based data” even means. Note that this 2012 paper still cites the original 1999 version instead of the 2010 version, which adds 123 datasets (for a total of 5,156).</p>
<p>Anyway, we can roughly infer what these filters mean in terms of the columns and values defined in the “MAIN” table of the GPDD, as described in the <a href="http://www3.imperial.ac.uk/cpb/databases/gpdd">GPDD User Manual</a>. <code>dplyr</code> makes it quick to implement these filters in R:</p>
<pre class="sourceCode r"><code class="sourceCode r">gpdd_main %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(SamplingProtocol ==<span class="st"> &quot;Count&quot;</span>,
         SourceDimension %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Count&quot;</span>, <span class="st">&quot;Index&quot;</span>), 
         SamplingFrequency ==<span class="st"> &quot;1&quot;</span>,
         DatasetLength &gt;=<span class="st"> </span><span class="dv">15</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(MainID) %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(MainID) -&gt;
filtered</code></pre>
<p>Note that we might imagine different selection criteria, looking a bit more closely at the relevant fields.</p>
<hr />
<p>Unfortunately these don’t quite align with the paper, even allowing for the 123 additional datasets. Most obviously, we have 1749 matches instead of 627. Not only have we somehow grabbed more datasets than expected, but the Knape et al list includes quite a few datasets that do not meet these criteria:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;http://ropensci.github.io/rgpdd/data/knape.R&quot;</span>)
gpdd_main %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(MainID %in%<span class="st"> </span>knape_ids) %&gt;%
<span class="st">  </span><span class="kw">select</span>(MainID, SamplingProtocol, SourceDimension, SamplingFrequency, DatasetLength)  %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">as.tbl</span>() -&gt;<span class="st"> </span>knape_data

<span class="kw">tail</span>(<span class="kw">sort</span>(<span class="kw">table</span>(knape_data$SourceDimension)))</code></pre>
<pre><code>
Count (estimated)        Mean Count             Index 
                5                 8                15 
          Density Transformed Count             Count 
               20               110               459 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(<span class="kw">sort</span>(<span class="kw">table</span>(knape_data$SamplingProtocol)))</code></pre>
<pre><code>
    Count (millions)              Harvest              Unknown 
                   1                    1                    1 
  Index of abundance Index of territories                Count 
                   2                    6                  616 </code></pre>
<p>Those summaries show data with attributes we excluded, including Harvest as a sampling protocol. We see over 100 such data sets:</p>
<pre class="sourceCode r"><code class="sourceCode r">gpdd_main %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(MainID %in%<span class="st"> </span>knape_ids) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(SamplingProtocol ==<span class="st"> &quot;Count&quot;</span>,
         SourceDimension %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Count&quot;</span>, <span class="st">&quot;Index&quot;</span>), 
         SamplingFrequency ==<span class="st"> &quot;1&quot;</span>,
         DatasetLength &gt;=<span class="st"> </span><span class="dv">15</span>) %&gt;%<span class="st"> </span><span class="kw">dim</span>()</code></pre>
<pre><code>[1] 468  25</code></pre>
<p>The reason for this discrepancy isn’t clear, but we can proceed with our filtered data instead.</p>
<hr />
<p>Selecting the time-series identified by our filter, we also add a column for <span class="math">\(\log(N)\)</span> population:</p>
<pre class="sourceCode r"><code class="sourceCode r">gpdd_data %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(MainID %in%<span class="st"> </span>filtered$MainID) %&gt;%
<span class="st">  </span><span class="kw">select</span>(MainID, Population, SampleYear) %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(MainID) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">logN =</span> <span class="kw">log</span>(Population)) -&gt;
df</code></pre>
<p>Interestingly there are no missing data reported:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">sapply</span>(df$Population, is.na))</code></pre>
<pre><code>[1] 0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">df %&gt;%<span class="st"> </span><span class="kw">filter</span>(Population &lt;<span class="st"> </span><span class="dv">0</span>) <span class="co"># -9999 is elsewhere used for missing data</span></code></pre>
<pre><code>Source: local data frame [0 x 4]
Groups: MainID

Variables not shown: MainID (int), Population (dbl), SampleYear
  (int), logN (dbl)</code></pre>
<p>but some population values are equal to 0, creating some <code>-Inf</code> terms in our log data, which will create trouble in fitting the models. The authors don’t say how they handled this case. We will manually set them to the smallest value observed:</p>
<pre class="sourceCode r"><code class="sourceCode r">i &lt;-<span class="st"> </span><span class="kw">which</span>(df$logN ==<span class="st"> </span>-<span class="ot">Inf</span>)
df$logN[i] &lt;-<span class="st"> </span><span class="kw">min</span>(df$logN[-i])-<span class="dv">1</span></code></pre>
<h2 id="gompertz-model">Gompertz model</h2>
<blockquote>
<p>We use the stochastic Gompertz population model to analyse the strength of density dependence in the data.The model is defined through</p>
</blockquote>
<p><span class="math">\[N_{t+1} = N_t \exp(a - b \log N_t + \epsilon_t)\]</span></p>
<blockquote>
<p>where <span class="math">\(N_t\)</span> is population density or size in year <span class="math">\(t\)</span>, <span class="math">\(a\)</span> is an intercept, <span class="math">\(b\)</span> is a measure of the strength of density dependence and <span class="math">\(\eta\)</span> is normally distributed process error with mean zero and standard deviation <span class="math">\(\tau\)</span>. By log transforming the population abundance and putting <span class="math">\(x_t = \log N_t\)</span> this simplifies to</p>
</blockquote>
<p><span class="math">\[x_{t+1} = a + c x_t + \epsilon_t\]</span></p>
<blockquote>
<p>where <span class="math">\(c = 1 - b\)</span> is the lag 1 autocorrelation of the log transformed population abundance when the process is stationary.</p>
</blockquote>
<p>and uncertainty in measurements, <span class="math">\(y_t\)</span> are simply normal random variates around <span class="math">\(x_t\)</span>:</p>
<p><span class="math">\[y_t = x_t + \eta_t \]</span></p>
<p>where <span class="math">\(\eta_t \sim N(0,\sigma^2)\)</span></p>
<h2 id="kalman-filtering">Kalman Filtering</h2>
<p>Since the model is linear we can compute the likelihood directly by means of a Kalman filter. There are various ways of going about this, and the paper provides some general details:</p>
<blockquote>
<p>The Kalman filter was initiated by assuming a wide prior distribution on the initial state centred around the first observation, <span class="math">\(x_1 \sim N( y_1, 10)\)</span>. For each model and data set the numerical maximisation (using the BFGS algorithm implemented in the optim function) was repeated for 50 random starting values to ensure that we found the global optimum</p>
</blockquote>
<p>Some useful detail here, but still a bit vague for our purposes, or are things we might have done differently.</p>
<ul>
<li><p>Doesn’t state which Kalman filter (their are a few algorithms and several packages, but the differences seem quite small: <a href="http://www.jstatsoft.org/v39/i02">this JSS paper</a> has a good overview.)</p></li>
<li><p>Not clear that we wouldn’t want to scale the prior variance by the data sample, e.g. <code>var(y)</code>, but since we’re on a log scale <code>10</code> is indeed pretty wide.</p></li>
<li><p><code>BFGS</code> doesn’t seem as robust as some alternatives; (e.g. gives a rather different result than Nelder-Meade or <code>StructTS()</code> model on the classic Nile data set example from the FKF package).</p></li>
<li><p>Also challenging are the “50 random starting values”, which does not tell us from what distribution they were drawn. Too wide a distribution will start to include values for which the likelihood cannot be evaluated, while too narrow serves little purpose. –Moreover it is unclear if this is really preferable to simply using fewer starting points and a more robust algorithm. For simplicity, we’ll ignore this and just choose justifiable starting conditions.– we’ll add this as well.</p></li>
</ul>
<blockquote>
<p>Four variants of the model defined by (1) and (2) were fitted to each data set; a full model with both uncertainty about population abundance and density dependence denoted by SSG (state space Gompertz), a model with uncertainty about population abundance, but no density dependence (c fixed to one) denoted SSRW (state space random walk), a model with density dependence, but no uncertainty about population abundance (r2 fixed to zero) denoted G (Gompertz) and a model with neither uncertainty about population abundance nor density dependence (c fixed to one and r2 fixed to zero) denoted RW (random walk)</p>
</blockquote>
<p>This is both clear and straight forward, we define each of the models as described. Note that we define the models here in the notation of FKF:</p>
<p><span class="math">\[\alpha_{t+1} = d_t + T_t \alpha_t H_t \eta_t\]</span></p>
<p><span class="math">\[y_t = c_t + Z_t \alpha_t + G_t \eta_t\]</span></p>
<p>Where</p>
<p><span class="math">\[\begin{align*}
c &amp;\to&amp; T_t \\
a &amp;\to&amp; d_t \\
\sigma^2 &amp;\to&amp; G_t&#39;G_t \\
\tau^2 &amp;\to&amp; H_t&#39;H_t 
\end{align*}\]</span></p>
<p>So here we define these models in R code just as described above. Using the <code>FKF</code> package we define each model by an optimization routine that returns the parameters that maximize the likelihood for the given model.</p>
<pre class="sourceCode r"><code class="sourceCode r">fit_ssg &lt;-<span class="st"> </span>function(y, 
                    <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">Tt =</span> <span class="dv">1</span>, 
                             <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>), <span class="dt">GGt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>)),
                    ...){
    o &lt;-<span class="st"> </span><span class="kw">optim</span>(init,
                 <span class="dt">fn =</span>  function(par, ...)
                   -<span class="kw">fkf</span>(<span class="dt">dt =</span> <span class="kw">matrix</span>(par[<span class="dv">1</span>]),
                        <span class="dt">Tt =</span> <span class="kw">matrix</span>(par[<span class="dv">2</span>]),
                        <span class="dt">HHt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">3</span>])), 
                        <span class="dt">GGt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">4</span>])), 
                        ...)$logLik,   
                 <span class="dt">a0 =</span> y[<span class="dv">1</span>], 
                 <span class="dt">P0 =</span> <span class="kw">matrix</span>(<span class="dv">10</span>), 
                 <span class="dt">ct =</span> <span class="kw">matrix</span>(<span class="dv">0</span>),
                 <span class="dt">Zt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>), 
                 <span class="dt">yt =</span> <span class="kw">rbind</span>(y), 
                 <span class="dt">check.input =</span> <span class="ot">FALSE</span>, 
                 ...)
  o$par[[<span class="st">&quot;HHt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;HHt&quot;</span>]])
  o$par[[<span class="st">&quot;GGt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;GGt&quot;</span>]])
  <span class="kw">c</span>(o, <span class="kw">list</span>(<span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">n =</span> <span class="kw">length</span>(y)))
}

fit_ssrw &lt;-<span class="st"> </span>function(y, 
                     <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt=</span><span class="kw">mean</span>(y), <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>), 
                              <span class="dt">GGt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>)), 
                     ...){
    o &lt;-<span class="st"> </span><span class="kw">optim</span>(init,
                 <span class="dt">fn =</span>  function(par, ...)
                   -<span class="kw">fkf</span>(<span class="dt">dt =</span> <span class="kw">matrix</span>(par[<span class="dv">1</span>]), <span class="dt">HHt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">2</span>])), 
                        <span class="dt">GGt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">3</span>])), ...)$logLik,   
                 <span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">P0 =</span> <span class="kw">matrix</span>(<span class="dv">10</span>), <span class="dt">ct =</span> <span class="kw">matrix</span>(<span class="dv">0</span>), <span class="dt">Tt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>),
                 <span class="dt">Zt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>), <span class="dt">yt =</span> <span class="kw">rbind</span>(y), <span class="dt">check.input =</span> <span class="ot">FALSE</span>, ...)
  o$par[[<span class="st">&quot;HHt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;HHt&quot;</span>]])
  o$par[[<span class="st">&quot;GGt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;GGt&quot;</span>]])
  <span class="kw">c</span>(o, <span class="kw">list</span>(<span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">n =</span> <span class="kw">length</span>(y)))
}

fit_g &lt;-<span class="st"> </span>function(y, <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">Tt=</span><span class="dv">1</span>, <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y))), ...){
  o &lt;-<span class="st"> </span><span class="kw">optim</span>(init,
                 <span class="dt">fn =</span>  function(par, ...)
                   -<span class="kw">fkf</span>(<span class="dt">dt =</span> <span class="kw">matrix</span>(par[<span class="dv">1</span>]), <span class="dt">Tt =</span> <span class="kw">matrix</span>(par[<span class="dv">2</span>]), 
                        <span class="dt">HHt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">3</span>])), ...)$logLik,   
                 <span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">P0 =</span> <span class="kw">matrix</span>(<span class="dv">10</span>), <span class="dt">ct =</span> <span class="kw">matrix</span>(<span class="dv">0</span>), <span class="dt">GGt =</span> <span class="kw">matrix</span>(<span class="dv">0</span>),
                 <span class="dt">Zt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>), <span class="dt">yt =</span> <span class="kw">rbind</span>(y), <span class="dt">check.input =</span> <span class="ot">FALSE</span>, ...)
  o$par[[<span class="st">&quot;HHt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;HHt&quot;</span>]])  
  <span class="kw">c</span>(o, <span class="kw">list</span>(<span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">n =</span> <span class="kw">length</span>(y)))
}

fit_rw &lt;-<span class="st"> </span>function(y, <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt=</span><span class="kw">mean</span>(y), <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y))), ...){
 o &lt;-<span class="st">  </span><span class="kw">optim</span>(init, 
                 <span class="dt">fn =</span>  function(par, ...)
                   -<span class="kw">fkf</span>(<span class="dt">dt =</span> <span class="kw">matrix</span>(par[<span class="dv">1</span>]), 
                        <span class="dt">HHt =</span> <span class="kw">matrix</span>(<span class="kw">exp</span>(par[<span class="dv">2</span>])), ...)$logLik,   
                 <span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">P0 =</span> <span class="kw">matrix</span>(<span class="dv">10</span>), <span class="dt">ct =</span> <span class="kw">matrix</span>(<span class="dv">0</span>),
                 <span class="dt">Tt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>), <span class="dt">GGt =</span> <span class="kw">matrix</span>(<span class="dv">0</span>), <span class="dt">Zt =</span> <span class="kw">matrix</span>(<span class="dv">1</span>),
                 <span class="dt">yt =</span> <span class="kw">rbind</span>(y), <span class="dt">check.input =</span> <span class="ot">FALSE</span>, ...)
  o$par[[<span class="st">&quot;HHt&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">exp</span>(o$par[[<span class="st">&quot;HHt&quot;</span>]])
  <span class="kw">c</span>(o, <span class="kw">list</span>(<span class="dt">a0 =</span> y[<span class="dv">1</span>], <span class="dt">n =</span> <span class="kw">length</span>(y)))
}</code></pre>
<p>Note that <code>fkf</code> will return finite (even “optimal”) log likelihoods for negative values of <code>HHt</code> and <code>GGt</code>, so we have log-transformed these parameters. Using <code>L-BFGS-B</code> with a <code>0</code> lower bound still causes <code>optim</code> to error with non-finite log-likelihoods. It isn’t clear how the authors dealt with this constraint, though <code>log</code>-transform trick has advantages and drawbacks.</p>
<p>Once we have defined the optimization routines to fit each model, we can define a summary function that runs each model on a given data set and collects the results into a <code>data.frame</code>. This could be made a bit more general and elegant as discussed later. We will also define this function such that it will fit each model <span class="math">\(N = 50\)</span> times and take the best fit, as the authors suggest for having a better chance of finding the global optimum. (We’ll look at the variation in MLE estimates in these models as footnote as well).</p>
<pre class="sourceCode r"><code class="sourceCode r">robust_fit &lt;-<span class="st"> </span>function(<span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;ssrw&quot;</span>, <span class="st">&quot;g&quot;</span>, <span class="st">&quot;rw&quot;</span>), y, <span class="dt">N =</span> <span class="dv">50</span>, <span class="dt">all =</span> <span class="ot">FALSE</span>, ...){
  
  ## Set the model and the mean initial condition
  m &lt;-<span class="st"> </span>switch(model,
              <span class="dt">ssg =</span> <span class="kw">list</span>(<span class="dt">fit =</span> fit_ssg, 
                         <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">Tt =</span> <span class="dv">1</span>, 
                                 <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>), <span class="dt">GGt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>))),
              <span class="dt">ssrw =</span> <span class="kw">list</span>(<span class="dt">fit =</span> fit_ssrw, 
                          <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>), 
                                   <span class="dt">GGt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>))),
              <span class="dt">g =</span> <span class="kw">list</span>(<span class="dt">fit =</span> fit_g, 
                       <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">Tt =</span> <span class="dv">1</span>, <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>))),
              <span class="dt">rw =</span> <span class="kw">list</span>(<span class="dt">fit =</span> fit_rw, 
                        <span class="dt">init =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="kw">mean</span>(y), <span class="dt">HHt =</span> <span class="kw">log</span>(<span class="kw">var</span>(y)/<span class="dv">2</span>))))  
  
  
  ## Create the inital conditions
  inits &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">sapply</span>(m$init, 
                      function(m) <span class="kw">rnorm</span>(N, m, <span class="kw">sqrt</span>(<span class="kw">abs</span>(m)) ) ))
  
  ## Attempt the requested fit or return NAs
  f &lt;-<span class="st"> </span>function(init){
    o &lt;-<span class="st"> </span><span class="kw">tryCatch</span>(
      m$<span class="kw">fit</span>(y, <span class="dt">init =</span> init), 
      <span class="dt">error =</span> function(e) <span class="kw">list</span>(<span class="dt">par =</span> <span class="kw">c</span>(<span class="dt">dt =</span> <span class="ot">NA</span>, <span class="dt">Tt=</span><span class="ot">NA</span>, <span class="dt">HHt =</span> <span class="ot">NA</span>, <span class="dt">GGt=</span> <span class="ot">NA</span>),
                               <span class="dt">value=</span><span class="ot">NA</span>, <span class="dt">convergence=</span><span class="dv">1</span>, <span class="dt">n=</span><span class="kw">length</span>(y), <span class="dt">a0=</span>y[<span class="dv">1</span>]))
    <span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">c</span>(o$par, <span class="dt">mloglik =</span> o$value, <span class="dt">converge =</span>
                   <span class="kw">as.numeric</span>(o$convergence), <span class="dt">n=</span>o$n, <span class="dt">a0=</span>o$a0)))
  }
  
  ## Apply the function to each initial condition, 
  inits %&gt;%<span class="st"> </span><span class="kw">rowwise</span>() %&gt;%<span class="st"> </span><span class="kw">do</span>(<span class="kw">f</span>(.)) -&gt;<span class="st"> </span>output
  
  if(!all) ## drop unconverged, and select only the best scoring run
    output %&gt;%<span class="st"> </span><span class="kw">filter</span>(converge ==<span class="st"> </span><span class="dv">0</span>) %&gt;%<span class="st"> </span><span class="kw">slice</span>(<span class="kw">which.min</span>(mloglik)) -&gt;<span class="st"> </span>output
  
  output
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">kalman &lt;-<span class="st"> </span>function(df, ...){
  y &lt;-<span class="st"> </span>df$logN
  ssg &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(<span class="st">&quot;ssg&quot;</span>, y, ...) 
  ssrw &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(<span class="st">&quot;ssrw&quot;</span>, y, ...) 
  g &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(<span class="st">&quot;g&quot;</span>, y, ...) 
  rw &lt;-<span class="st"> </span><span class="kw">robust_fit</span>(<span class="st">&quot;rw&quot;</span>, y, ...)
  <span class="kw">options</span>(<span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)
  <span class="kw">rbind</span>(<span class="kw">data.frame</span>(<span class="dt">model =</span><span class="st">&quot;ssg&quot;</span>, <span class="kw">gather</span>(ssg, parameter, value)),
        <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;ssrw&quot;</span>, <span class="kw">gather</span>(ssrw, parameter, value)),
        <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;g&quot;</span>, <span class="kw">gather</span>(g, parameter, value)),
        <span class="kw">data.frame</span>(<span class="dt">model =</span> <span class="st">&quot;rw&quot;</span>, <span class="kw">gather</span>(rw, parameter, value)))
                              
}</code></pre>
<p>Having defined a function that takes and returns a <code>data.frame</code>, <code>dplyr::do</code> gives us a consise syntax to apply this by group (recall <code>df</code> is already <code>group_by(MainID)</code>.) As the authors note, the robust fitting procedure is computationally intensive, though easily parallelized.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(
df %&gt;%<span class="st"> </span><span class="kw">do</span>(<span class="kw">kalman</span>(., <span class="dt">method =</span> <span class="st">&quot;BFGS&quot;</span>)) -&gt;<span class="st"> </span>fits
)</code></pre>
<pre><code>    user   system  elapsed 
4278.742  123.188 4402.113 </code></pre>
<hr />
<p>Unfortunately <code>dplyr</code> does not as yet directly support parallelization (despite the documentation of <code>dplyr::init_cluster()</code> describing parallel <code>dplyr::do()</code> use, this feature is not actually implemented yet). Most parallelization packages for R wrap around <code>apply</code> functions, and thus are not trivially adapted to the <code>dplyr</code> grammar. If many cores are available it may still be faster to devolve the <code>group_by()</code> <code>data.frame</code> into a list of data frames and then apply in parallel; e.g.:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># not run</span>
<span class="kw">library</span>(parallel)
<span class="kw">options</span>(<span class="dt">mc.cores =</span> <span class="kw">detectCores</span>())

## turn grouped data.frame to a list of data.frames by MainID
list_data &lt;-<span class="st"> </span><span class="kw">mclapply</span>(<span class="kw">unique</span>(df$MainID), function(id) <span class="kw">filter_</span>(df, <span class="dt">.dots =</span> ~MainID==id))

## Actually do the fitting in parallel
fits_list &lt;-<span class="st"> </span><span class="kw">mclapply</span>(list_data, kalman, <span class="dt">method=</span><span class="st">&quot;BFGS&quot;</span>)

## reshape outputs back to a data.frame
fits &lt;-<span class="st"> </span>reshape2::<span class="kw">melt</span>(fits_list, <span class="dt">id=</span><span class="kw">names</span>(fits_list[[<span class="dv">1</span>]])) %&gt;%<span class="st"> </span><span class="kw">rename</span>(<span class="dt">MainID =</span> L1) %&gt;%<span class="st"> </span><span class="kw">as_data_frame</span>()</code></pre>
<hr />
<p>We now have a nice table of parameter estimates and likelihoods by model for each data set:</p>
<pre class="sourceCode r"><code class="sourceCode r">fits</code></pre>
<pre><code>Source: local data frame [45,724 x 4]
Groups: MainID

   MainID model parameter         value
1       3   ssg        dt  3.467438e+00
2       3   ssg        Tt -1.335810e-01
3       3   ssg       HHt  6.383566e-02
4       3   ssg       GGt  1.766069e-01
5       3   ssg   mloglik  2.050357e+01
6       3   ssg  converge  0.000000e+00
7       3   ssg         n  2.700000e+01
8       3   ssg        a0  2.484907e+00
9       3  ssrw        dt  7.431098e-04
10      3  ssrw       HHt  9.975410e-10
..    ...   ...       ...           ...</code></pre>
<p>and here is our version then of Figure 1b, comparing the estimate of the density-dependence coefficent with and without the uncertainty in observations:</p>
<pre class="sourceCode r"><code class="sourceCode r">fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;g&quot;</span>), parameter ==<span class="st"> &quot;Tt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(model, value) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(g, ssg)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;c estimates&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/figure1b-1.png" />
</figure>
<p>Likewise we can compute a version of Figure 1a; which calculates the absolute value of the difference between the estimates of density-dependence with and without the uncertainty, and then plots how frequently we observe a difference larger than a given amount in the data. (The paper finds around 20% having a difference larger than 0.5)</p>
<pre class="sourceCode r"><code class="sourceCode r">fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;g&quot;</span>), parameter ==<span class="st"> &quot;Tt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(model, value) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">difference =</span> <span class="kw">abs</span>(g-ssg)) %&gt;%
<span class="st">  </span><span class="kw">select</span>(difference) -&gt;<span class="st"> </span>diffs
  
s &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">length=</span><span class="dv">100</span>)
difference &lt;-<span class="st"> </span><span class="kw">sapply</span>(s, function(s_i) <span class="kw">mean</span>(diffs$difference &gt;<span class="st"> </span>s_i))
<span class="kw">qplot</span>(s, difference) +<span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Difference bewteen estimates&quot;</span>) +<span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Proportion of data sets&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/figure1a-1.png" />
</figure>
<pre class="sourceCode r"><code class="sourceCode r">fits %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(model %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ssg&quot;</span>, <span class="st">&quot;ssrw&quot;</span>), parameter ==<span class="st"> &quot;GGt&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(model, value, MainID) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(model, value) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(ssg, ssrw)) +
<span class="st">  </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span><span class="dv">0</span>, <span class="dt">slope=</span><span class="dv">1</span>) +<span class="st"> </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;sigma^2 (obs error)&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/unnamed-chunk-12-1.png" />
</figure>
<hr />
<h2 id="aside-further-exploring-numerical-issues">Aside: further exploring numerical issues</h2>
<p>Numerical optimization can be tricky, particularly in this unsupervised manner. The robust (multiple) fitting strategy goes some ways to addressing this; though ideally one would at least show that the resulting estimates change little if N is increased further.</p>
<pre class="sourceCode r"><code class="sourceCode r">df %&gt;%<span class="st"> </span><span class="kw">filter</span>(MainID==<span class="dv">5</span>) %&gt;%
<span class="st">  </span><span class="kw">do</span>(<span class="kw">robust_fit</span>(<span class="st">&quot;ssg&quot;</span>,  <span class="dt">y=</span>.$logN, <span class="dt">all=</span><span class="ot">TRUE</span>)) %&gt;%
<span class="st">  </span><span class="kw">select</span>(dt, Tt, HHt, GGt, mloglik) %&gt;%
<span class="st">  </span>tidyr::<span class="kw">gather</span>(parameter, value, -MainID) -&gt;<span class="st"> </span>all

<span class="kw">ggplot</span>(all) +<span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(value)) +<span class="st"> </span><span class="kw">facet_wrap</span>(~parameter, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/unnamed-chunk-13-1.png" />
</figure>
<pre class="sourceCode r"><code class="sourceCode r">df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(MainID==<span class="dv">1998</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">do</span>(<span class="kw">robust_fit</span>(<span class="st">&quot;ssg&quot;</span>,  <span class="dt">y=</span>.$logN, <span class="dt">all=</span><span class="ot">TRUE</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(dt, Tt, HHt, GGt, mloglik) %&gt;%<span class="st"> </span>
<span class="st">  </span>tidyr::<span class="kw">gather</span>(parameter, value, -MainID) -&gt;<span class="st"> </span>all

<span class="kw">ggplot</span>(all) +<span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(value)) +<span class="st"> </span><span class="kw">facet_wrap</span>(~parameter, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/unnamed-chunk-14-1.png" />
</figure>
<p>Also compare also to the classic example used in most Kalman filter packages, the Nile river flows time series:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">robust_fit</span>(<span class="st">&quot;ssg&quot;</span>,  <span class="dt">y=</span>Nile, <span class="dt">all=</span><span class="ot">TRUE</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(dt, Tt, HHt, GGt, mloglik) %&gt;%
<span class="st">  </span>tidyr::<span class="kw">gather</span>(parameter, value) -&gt;<span class="st"> </span>all
<span class="kw">ggplot</span>(all) +<span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(value)) +<span class="st"> </span><span class="kw">facet_wrap</span>(~parameter, <span class="dt">scales=</span><span class="st">&quot;free&quot;</span>)</code></pre>
<figure>
<img src="/2015/assets/figures/posts/2015-04-06-gpdd-explore/unnamed-chunk-15-1.png" />
</figure>
<hr />
<h2 id="side-note-on-coding-strategy">Side note on coding strategy</h2>
<p><code>dplyr</code> makes the data filtering steps fast, consise, and clear. Dealing with model outputs here is actually far less straight forward than cleaning the raw data. For instance, I have collected the output of each model fit into it’s own row. The models have different numbers of parameters, so I must add the fixed parameters to avoid rows of different length; but clearly this does not generalize to the case where the different models can have arbitrarily different parameters.</p>
<p><a href="https://github.com/dgrtwo">David Robinson</a> has done an excellent job in starting to tackle this thorny problem in a package called <code>broom</code> with much the same elegance and care that Hadley has done with <code>dplyr</code>. David argues very persuasively that it makes more sense to summarize parameter estimates from each model fit in two columns - a column for parameter names and a column for values. He has now added support for <code>optim()</code> output to the <code>broom::tidy()</code> function, which does just that.</p>
<p>This doesn’t translate immediately to my use case here, since I need to keep track of the likelihood and convergence which are not captured by <code>broom::tidy()</code>. As these are scalar valued outputs of the model fit, instead of a vector like parameters, they are extracted and summarized in <code>broom::glance()</code> as a single row. An easy generalization would just be to <code>cbind</code> the outputs of <code>glance()</code> and <code>tidy()</code>; though David argues for a different approach in which we defer any manipulation of model output. Instead, he suggests an <code>expand.grid</code> over the names of the groups (models and datasets):</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># not run</span>

<span class="kw">expand.grid</span>(<span class="dt">model =</span> <span class="kw">names</span>(models),
            <span class="dt">dataset =</span> <span class="kw">names</span>(datasets)) %&gt;%
<span class="st">    </span><span class="kw">group_by</span>(model, dataset) %&gt;%
<span class="st">    </span><span class="kw">do</span>(<span class="dt">o =</span> <span class="kw">optim_func</span>(.$model, .$dataset)) -&gt;<span class="st"> </span>david</code></pre>
<p>Where <code>optim_func</code> uses the name of the model and name of the dataset to apply <code>optim()</code>, rather than passing the data explicitly. We can then use <code>glance</code> and <code>tidy</code> on the resulting output, though we would need to <code>inner_join</code> the results instead of <code>cbind</code>. This is indeed an elegant, more generic approach. Still, neither of us much like the need to defer the tidy step to the complex object at the end.</p>
<p>Here, I have ended up adopting the column-wise parameter, value, approach, though for a reason not just related to elegance. My <code>robust_fit()</code> error-handling seems to end up very occassionally with some kind of race conditions<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> that cause some of the sub-models to report an NA for one of their fixed parameters, instead of ommitting the parameter entirely. When adding the fixed value back in to keep rows of a uniform length, this meant I might get some rows with a duplicated column, such as a <code>GGt</code> column with value <code>NA</code> and another, appended column with the fixed value <code>0</code> in the <code>g</code> or <code>rw</code> models. The columnwise structure avoids this and prevents the code execution from failing.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I could only ever reproduce this by re-running large batch jobs – isolating the examples where error occurred and re-running had no effect, hence my worry about some race conditions between the error reporting. However, the stochastic initial conditions might also contribute to this, as I didn’t standardize seed over the parallelization; though in priciple any unusual initial conditions should only generate fit failures that are already handled in the error handling.<a href="#fnref1">↩</a></p></li>
</ol>
</section>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/04/06/gpdd-explore.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2015/03/26/ropensci-unconf-teaching-session.html">Ropensci Unconf Teaching Session</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 26 Mar 2015</p>

<article>
<div class="excerpt">
<h2 id="panel-on-effective-teaching-with-r">Panel on Effective teaching with R</h2>
<p>Panel:</p>
<ol type="1">
<li>Tracy Teal - Data Carpentry</li>
<li>Hadley Wickhan - undergrads at Rice, R master classes for RStudio</li>
<li>Mine, Prof Stats, Duke, also MOOC</li>
<li>Roger Peng Prof Biostats, John Hopkins</li>
<li>Jenny Bryan, Prof Stats, UBC.<br /></li>
<li>Ben Marwick, Prof Archaelogy</li>
</ol>
<p>How do you engage new users? (Or what doesn’t work?)</p>
<p>Hadley: Start with visualization. +1 Jenny Jenny: Making an HTML page with .Rmd (+1 Mine), scaling/aggregation Roger: these days, they come to me excited about R Mine: I have to convince social scientists to use computers at all. Visualization, faceting etc helps, Rmd helps.<br />Ben: Reproducible scripts, not click trails (Excel).</p>
<p>What’s the worst way to start?</p>
<ul>
<li>teaching data structures / programming first.</li>
</ul>
<p>teach loops, control structures?</p>
<ul>
<li>later / no. Mine teaches loops with index cards.</li>
<li>Hadley aims to to get people to re-invent lapply as a common pattern…</li>
</ul>
<p>Keeping people engaged? (Break-out session to develop reading lists, user groups)</p>
<ul>
<li>Mine data hack weekend. (PhD students mentoring, undergrads doing).<br /></li>
<li>Roger: capstone project. Track alumni (via linked-in, other ideas?)</li>
<li>Tracy: Pointing people to courses like Roger’s MOOC</li>
</ul>
<p>Engaging later-stage students?</p>
<ul>
<li>Working with own data and problems.</li>
</ul>
<p>R’s horrible gotchas (recycling, NA stuff, factor stuff, dropping columns/names)</p>
<ul>
<li>Hadley: 1) set the expectations that R has frustrations. 2) room / chance to fail safely, how to debug (google error).<br /></li>
<li>Roger: 10 examples of annoying things in R</li>
<li>Jenny: user str and fear factors.</li>
<li>Ben: getting help</li>
<li>Roger: students with programming experience need different kind of help.</li>
</ul>
<p>R &amp; Github?</p>
<ul>
<li>Hadley, Mine – nope. Hadley - I didn’t commit to teaching it. Don’t try it at the end.</li>
<li>Roger – it’s better (though students think git == github). Avoid why git is awesome, just teach it in a narrow sense!<br /></li>
<li>Jenny – intensive use of Github whole time, starting with it up front.<br /></li>
<li>Ben: not with undergrads, yes with grads. takes time.</li>
</ul>
<p>Markdown, Github – if you’re gonna do it, commit and do everything in it from the beginning.</p>
<p>Hadley: If something feels painful, do it more often. (git, R CMD check).</p>
<p>Writing functions: need to learn eventually, but it’s really hard to teach. Hadley’s book exercises for the reader. Over time course gets simpler.</p>
<p>When do you teach data cleaning?</p>
<p>Jenny: a data-cleaning script itself cannot be clean. It’s an advanced topic I teach it midway.<br />Jenny, Roger: includes teaching regex.</p>
<p>Find outside dataset mid-way, sudo-messy data.</p>
<p>Hadley: Hardest part is that students don’t know what the goal is, while I see it instantly. Takes a super long time to learn how to do this and to articulate this.</p>
<p>Data shouldn’t be too real, should be Disney-real (more real than reality). individual/personal they put in the time, so do a kaggle competition to clean data, top 3 winners get automatic A’s, opt out of final</p>
<p>Starting with spreadsheets and data entry!</p>
<p>Infrastructure for package building:</p>
<ul>
<li>takes time, possibly &gt; 30 min 1:1.</li>
<li>Mine: students run on cloud, I can replicate. but cannot run on own computer.</li>
<li>Roger: Better to live through the cli bs, once it’s done it’s done. VM’s not how the real world works. Hosting service for 1000s of people too expensive.</li>
<li>Jenny: pain is only when we need build environment</li>
<li><p>Ben: Use <em>local</em> Docker, replicates his own research. A slight taste of shell, but avoids CLI BS</p></li>
<li><p>install challenges is the opposite of a motivator / win. Luckily doesn’t bite early.</p></li>
</ul>
<p>Evaluate:</p>
<ul>
<li>peer review</li>
</ul>
<hr />
<p>Breakouts / products:</p>
<ol type="1">
<li>Listing follow-up resources</li>
<li>Iris data sets</li>
<li>dependencies &amp; scaling</li>
</ol>
<hr />
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2015/03/26/ropensci-unconf-teaching-session.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row socialicons">
  <div class="col-md-11 col-md-offset-1">
		<p> <a href="/2015/index.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/2015/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/2015/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
  </div> <!--end col-md-9 -->
</div> <!--end row -->




      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
